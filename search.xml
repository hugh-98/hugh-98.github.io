<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Redis入门</title>
      <link href="/2023/05/03/Redis/"/>
      <url>/2023/05/03/Redis/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.bilibili.com/video/BV1Rv41177Af">参考尚硅谷视频</a></p><hr><h2 id="NoSQL数据库简介">NoSQL数据库简介</h2><h3 id="技术的发展">技术的发展</h3><p>技术的分类：</p><p>1、 解决功能性的问题：Java、JSP、RDBMS(关系型数据库)、Tomcat、HTML、Linux、JDBC、SVN.</p><p>2、解决扩展性的问题：Struts、Spring、SpringMVC、Hibernate、Mybatis</p><p>3、<strong>解决性能的问题</strong>：<strong>NoSQL</strong>、Java线程、Hadoop、Nginx、MQ、ElasticSearch</p><h3 id="NoSQL数据库">NoSQL数据库</h3><h4 id="NoSQL数据库概述">NoSQL数据库概述</h4><p>NoSQL(NoSQL = <strong>Not Only SQL</strong> )，意即“不仅仅是SQL”，泛指<strong>非关系型的数据库</strong>。</p><p>NoSQL 不依赖业务逻辑方式存储，而<strong>以简单的key-value模式存储</strong>。因此大大的增加了数据库的扩展能力。</p><p>特点：</p><ul><li><p>不遵循SQL标准。</p></li><li><p>不支持ACID。即事务的原子性、隔离性、持久性、一致性。</p></li><li><p>远超于SQL的性能。</p></li></ul><h4 id="NoSQL适用场景">NoSQL适用场景</h4><ul><li><p>对数据高并发的读写</p></li><li><p>海量数据的读写</p></li><li><p>对数据高可扩展性的</p></li></ul><h4 id="NoSQL不适用场景">NoSQL不适用场景</h4><ul><li><p>需要事务支持</p></li><li><p>基于sql的结构化查询存储，处理复杂的关系,需要即席查询。</p></li><li><p>（用不着sql的和用了sql也不行的情况，请考虑用NoSql）</p></li></ul><h4 id="常见的NoSQL数据库">常见的NoSQL数据库</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923007.png" alt="image-20210620104235670"></p><h3 id="大数据时代的数据库">大数据时代的数据库</h3><h4 id="行式数据库">行式数据库</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923008.png" alt="image-20210620104632736"></p><h4 id="列式数据库">列式数据库</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923009.png" alt="image-20210620104658423"></p><h2 id="Redis">Redis</h2><p><a href="https://redis.io/">redis官网</a>    <a href="http://www.redis.cn/">redis中文官网</a></p><h3 id="Redis概述与特点">Redis概述与特点</h3><ul><li><p>Redis是一个<strong>开源的key-value</strong>存储系统。</p></li><li><p>和Memcached类似，它支持存储的value类型相对更多，包括<strong>string(字符串)、list(链表)、set(集合)、zset(sorted set --有序集合)和hash（哈希类型）</strong>。</p></li><li><p>这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是<strong>原子性</strong>的。</p></li><li><p>在此基础上，Redis支持各种不同方式的<strong>排序</strong>。</p></li><li><p>与memcached一样，为了保证效率，数据都是<strong>缓存在内存</strong>中。</p></li><li><p>区别的是Redis会<strong>周期性</strong>的把更新的<strong>数据写入磁盘</strong>或者把修改操作写入追加的记录文件。</p></li><li><p>并且在此基础上实现了<strong>master-slave(主从)同步</strong>。</p></li></ul><h4 id="Redis应用场景">Redis应用场景</h4><h5 id="配合关系型数据库做高速缓存">配合关系型数据库做高速缓存</h5><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923010.png" alt="image-20210620105439343"></p><h5 id="多样的数据结构存储持久化数据">多样的数据结构存储持久化数据</h5><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923011.png" alt="image-20210620105518007"></p><h3 id="Redis相关知识">Redis相关知识</h3><h4 id="redis启动方式">redis启动方式</h4><p>有两种启动方式：</p><ul><li>前台启动(不推荐)</li><li>后台启动(推荐，自己找教程)</li></ul><p>下面默认使用后台启动</p><p><code>redis-server  /myredis/redis.conf</code></p><h4 id="相关命令">相关命令</h4><ul><li><p>用客户端访问：<code>redis-cli</code></p></li><li><p>多个端口可以使用：<code>redis-cli -p 6379</code></p></li><li><p>redis关闭：<code>redis-cli shutdown</code>；也可以进入终端后再使用shutdown关闭</p></li><li><p>多实例关闭，指定端口管理：<code>redis-cli -p 6379</code></p></li></ul><h4 id="相关知识">相关知识</h4><p>​<strong>Redis默认16个数据库</strong>，类似数组下标从0开始，初始默认使用0号库。</p><p>​使用命令 <code>select &lt;dbid&gt;</code> 来切换数据库。如：select 8</p><p>​统一密码管理，所有库同样密码。</p><p>​<strong><code>dbsize</code> 查看当前数据库的key的数量</strong></p><p>​<strong><code>flushdb</code> 清空当前库</strong></p><p>​<strong><code>flushall</code> 通杀全部库</strong></p><p><strong>Redis是单线程+多路IO复用技术</strong></p><p>多路复用是指使用一个线程来检查多个文件描述符（Socket）的就绪状态，比如调用select和poll函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启动线程执行（比如使用线程池）。</p><p>memcache是多线程+锁</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923012.png" alt="image-20210620203425497"></p><h2 id="Redis常用数据类型">Redis常用数据类型</h2><p><strong>redis有五大基本数据类型</strong>：</p><ul><li><p><strong>字符串(String)</strong></p></li><li><p><strong>列表(List)</strong></p></li><li><p><strong>集合(Set)</strong></p></li><li><p><strong>哈希(Hash)</strong></p></li><li><p><strong>有序集合(Zset)</strong></p><p><strong>注意</strong>：这里说的类型是指value中的类型，而不是key的类型。</p></li></ul><h3 id="Redis键-key-常见命令">Redis键(key)  常见命令</h3><p>常见命令可见<a href="http://www.redis.cn/commands.html">官网</a></p><ul><li><p><code>keys *</code> ： 查看当前库所有key  (匹配：keys *1)</p></li><li><p><code>exists key</code>  ：判断某个key是否存在</p></li><li><p><code>type key</code>  ：查看你的key是什么类型</p></li><li><p><code>del key</code>  ：删除指定的key数据</p></li><li><p><code>unlink key</code>  根据value选择非阻塞删除</p><p>仅将keys从keyspace元数据中删除，真正的删除会在后续异步操作。</p></li><li><p><code>set key value</code> ： 设置某个key的值为value</p></li><li><p><code>expire key 10</code> ：  为给定的key设置过期时间为10秒钟</p></li><li><p><code>ttl key</code>  ：查看还有多少秒过期，-1表示永不过期，-2表示已过期</p></li><li><p><code>select</code>  ：命令切换数据库</p></li><li><p><code>dbsize</code>  查看当前数据库key的数量</p></li><li><p><code>flushdb</code>： 清空当前库</p></li><li><p><code>flushall</code>  ：清空全部库</p></li></ul><h3 id="字符串-String">字符串(String)</h3><p>String类型是二进制安全的。意味着Redis的string可以包含任何数据，比如jpg图片，或者序列化的对象。</p><p>String是Redis最基本的数据类型，一个Redis中字符串value最多可以是512M</p><h4 id="常用命令">常用命令</h4><ul><li><p><strong><code>set &lt;key&gt; &lt;value&gt;</code></strong> ：添加键值对。</p><ul><li>当数据库中这个key不存在时，可以将key-value添加到数据库</li><li>当数据库key存在时，可以将key-value添加到数据库，会将原来的value覆盖掉。</li></ul></li><li><p><strong><code>get &lt;key&gt;</code></strong> ：查询对应键值</p></li><li><p><strong><code>append &lt;key&gt; &lt;value&gt;</code></strong> ：将给定的value追加到原值的末尾，有返回值，返回值是value的长度。当数据库key不存在时，则会创建一个key-value并添加到数据库中</p></li><li><p><strong><code>strlen &lt;key&gt;</code></strong> ： 获取value的长度</p></li><li><p><strong><code>setnx &lt;key&gt; &lt;value&gt;</code></strong>  ：只有当key不存在时，才能设置成功，将key的值设置为value.</p></li><li><p><strong><code>incr &lt;key&gt;</code></strong> ： 将key中存储的数字值增1。只能对数字值操作，若为空，新增值为1</p></li><li><p><strong><code>decr &lt;key&gt;</code></strong> ：将key中存储的数字值减1。只能对数字值操作，若为空，新增值为-1</p></li><li><p><strong><code>incrby / decrby  &lt;key&gt; &lt;步长&gt;</code></strong> ：将key中存储的数字增减。自定义步长。</p></li></ul><p><strong>注意</strong>：</p><p>在使用上面incr / decr / incrby / decrby等操作时，具有原子性(不是关系型数据库事务中所谓的原子性)。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923013.png" alt="image-20210620213139407"></p><hr><p>思考题：</p><ol><li><p>Java中的i++操作是否是原子操作？</p><p>​<strong>不是</strong></p></li><li><p>Java程序中，i=0;两个线程分别对i进行++100次，值是多少？</p><p><strong>2~200</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923014.png" alt="image-20210620214335758"></p></li></ol><hr>- **`mset <key1> <value1> <key2> <value2> ...`**   ：同时设置一个或多个key-value对<ul><li><p><strong><code>mget &lt;key1&gt; &lt;value1&gt; &lt;key2&gt; &lt;value2&gt; ...</code></strong>  ： 同时获取一个或多个value</p></li><li><p><strong><code>msetnx &lt;key1&gt; &lt;value1&gt; &lt;key2&gt; &lt;value2&gt; ...</code></strong>  ：同时设置一个或多个key-value对，当且仅当所有给定key都不存在时。<strong>原子性，有一个失败则都失败</strong></p></li><li><p><strong><code>getrange &lt;key&gt; &lt;起始位置&gt; &lt;结束位置&gt;</code></strong>  ：获取值的范围，类似java中的substring用法。不过注意，这里范围是[起始位置，结束位置]</p></li><li><p><strong><code>setrange &lt;key&gt; &lt;起始位置&gt; &lt;value&gt;</code></strong>  ：用<value>覆写<key>所存储的字符串值，从&lt;起始位置&gt;开始(索引从0开始)</p></li><li><p><strong><code>setex &lt;key&gt; &lt;过期时间&gt; &lt;value&gt;</code></strong> ：设置键值的同时，设置过期时间，单位秒。</p></li><li><p><strong><code>getset &lt;key&gt; &lt;value&gt;</code></strong> ：以新换旧，设置了新值同时获得旧值</p></li></ul><h4 id="String底层的数据结构">String底层的数据结构</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923015.png" alt="image-20210620221212212"></p><h3 id="列表-List">列表(List)</h3><p>单键多值</p><p>Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。</p><p>它的<strong>底层实际是个双向链表</strong>，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。</p><h4 id="常用命令-2">常用命令</h4><ul><li><p><strong><code>lpush/rpush &lt;key&gt; &lt;value1&gt; &lt;value2&gt; &lt;value3&gt; ...</code></strong> ：从左边/右边插入一个或多个值。值的顺序，跟压栈类似</p></li><li><p><strong><code>lpop/rpop &lt;key&gt; [&lt;count&gt;]</code></strong>： 从左边/右边吐出一个值。值在键在，值无键亡。可选参数count，表示一次性吐出count个值。</p></li><li><p><strong><code>rpoplpush &lt;key1&gt; &lt;key2&gt;</code></strong>： 从<key1>列表右边吐出一个值，插到<key2>列表左边</p></li><li><p><strong><code>lrange &lt;key&gt; &lt;start&gt; &lt;stop&gt;</code></strong>  ：按照索引下标获得元素(从左到右)。stop若为-1，则表示stop到最后一个。范围是[start, stop]。</p></li><li><p><strong><code>lindex &lt;key&gt; &lt;index&gt;</code></strong> ：按照索引下标获得元素(从左到右)  索引从0开始</p></li><li><p><strong><code>llen &lt;key&gt;</code></strong>  ：获得列表长度</p></li><li><p><strong><code>linsert &lt;key&gt; before/after &lt;value&gt; &lt;newValue&gt;</code></strong> ：在<value>的前面/后面插入<newValue> 插入值</p></li><li><p><strong><code>lrem &lt;key&gt; &lt;n&gt; &lt;value&gt;</code></strong> ：从左边删除n个value(从左到右)</p></li><li><p><strong><code>lset &lt;key&gt; &lt;index&gt; &lt;value&gt;</code></strong> ：将列表key下标为index的值替换成value</p></li></ul><h4 id="List底层的数据结构">List底层的数据结构</h4><p>List的数据结构为快速链表quickList。</p><p>**首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是ziplist，也即是压缩列表。**它将所有的元素紧挨着一起存储，分配的是一块连续的内存。</p><p><strong>当数据量比较多的时候才会改成quicklist。</strong></p><p>因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是int类型的数据，结构上还需要两个额外的指针prev和next。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923016.png" alt="image-20210621191502104"></p><p>**Redis将链表和ziplist结合起来组成了quicklist,也就是将多个ziplist使用双向指针串起来使用。**这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。</p><h3 id="集合-Set">集合(Set)</h3><p>Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以<strong>自动排重</strong>的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。</p><p>Redis的<strong>Set是string类型的无序集合</strong>。<strong>它底层其实是一个value为null的hash表</strong>，所以添加，删除，查找的<strong>复杂度都是O(1)</strong>。</p><h4 id="常用命令-3">常用命令</h4><ul><li><p><strong><code>sadd &lt;key&gt; &lt;value1&gt; &lt;value2&gt; ...</code></strong> ：将一个或多个member元素加入到集合key中，已经存在的member元素将会被忽略。</p></li><li><p><strong><code>smembers &lt;key&gt;</code></strong> ：取出该集合的所有值</p></li><li><p><strong><code>sismember &lt;key&gt; &lt;value&gt;</code></strong>： 判断集合<key>是否为含有该<value>值，有1，没有0</p></li><li><p><strong><code>scard &lt;key&gt;</code></strong> ：返回该集合的元素个数</p></li><li><p><strong><code>srem &lt;key&gt; &lt;value1&gt; &lt;value2&gt; ...</code></strong>  ：删除集合中的某个元素</p></li><li><p><strong><code>spop &lt;key&gt;</code></strong>  ：随机从该集合中吐出一个值。会将元素从集合中删除。</p></li><li><p><strong><code>srandmember  &lt;key&gt; &lt;n&gt;</code></strong> ：随机从该集合中取出n个值。不会从集合中删除。</p></li><li><p><strong><code>smove &lt;source&gt; &lt;destination&gt; member</code></strong>：把member元素从一个集合中移动到另一个集合。</p></li><li><p><strong><code>sinter  &lt;key1&gt; &lt;key2&gt;</code></strong>  ：返回两个集合的交集元素。</p></li><li><p><strong><code>sunion &lt;key1&gt; &lt;key2&gt;</code></strong>：返回两个集合的并集元素</p></li><li><p><strong><code>sdiff &lt;key1&gt; &lt;key2&gt;</code></strong>  返回两个集合的差集元素(key1中的，不包含key2的)</p></li></ul><h4 id="数据结构">数据结构</h4><p><em>Set数据结构是dict字典</em>，字典是用<strong>哈希表</strong>实现的。</p><p>Java中HashSet的内部实现使用的是HashMap，只不过所有的value都指向同一个对象。Redis的set结构也是一样，它的内部也使用hash结构，所有的value都指向同一个内部值。</p><h3 id="哈希-Hash">哈希(Hash)</h3><p>Redis hash 是一个键值对集合。</p><p>Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。</p><p>类似Java里面的Map&lt;String,Object&gt;</p><p>用户ID为查找的key，存储的value用户对象包含姓名，年龄，生日等信息，如果用<strong>普通的key/value结构来存储,主要有以下2种存储方式</strong>：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923017.png" alt="image-20210621194319115"></p><p><strong>Redis Hash存储的方式：</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923018.png" alt="image-20210621194329774"></p><h4 id="常用命令-4">常用命令</h4><ul><li><p><strong><code>hset &lt;key&gt; &lt;field&gt; &lt;value&gt;</code></strong> ： 给<key>集合中的<field>键赋值<value></p></li><li><p><strong><code>hget &lt;key1&gt; &lt;field&gt;</code></strong>  ：从<key1>集合<field>取出value</p></li><li><p><strong><code>hmset &lt;key1&gt; &lt;field1&gt; &lt;value1&gt; &lt;field2&gt; &lt;value2&gt; ...</code></strong> ：批量设置hash的值</p></li><li><p><strong><code>hexists &lt;key1&gt; &lt;field&gt;</code></strong>： 查看哈希表key中，给定域field是否存在</p></li><li><p><strong><code>hkeys &lt;key&gt;</code></strong> ：列出该hash集合的所有field</p></li><li><p><strong><code>hvals &lt;key&gt;</code></strong> ：列出该hash集合的所有value</p></li><li><p><strong><code>hincrby &lt;key&gt; &lt;field&gt; &lt;increment&gt;</code></strong> ：为哈希表key中的域field的值加上增量<increment>。这个增量可以是负数</p></li><li><p><strong><code>hsetnx &lt;key&gt; &lt;field&gt; &lt;value&gt;</code></strong>：将哈希表key中的域field的值设置为value，当且仅当域field不存在。</p></li></ul><h4 id="数据结构-2">数据结构</h4><p>Hash类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。当field-value长度较短且个数较少时，使用ziplist，否则使用hashtable。</p><h3 id="有序集合Zset-sorted-set">有序集合Zset(sorted set)</h3><p>Redis有序集合zset与普通集合set非常相似，是一个没有重复元素的字符串集合。</p><p>不同之处是有序集合的每个成员都关联了一个<strong>评分（score）</strong>,这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了 。</p><p>因为元素是有序的, 所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。</p><p>访问有序集合的中间元素也是非常快的,因此你能够使用有序集合作为一个没有重复成员的智能列表。</p><h4 id="常用命令-5">常用命令</h4><ul><li><p><strong><code>zadd &lt;key&gt; &lt;score1&gt; &lt;value1&gt; &lt;score2&gt; &lt;value2&gt;</code></strong>： 将一个或多个member元素及其score值加入到有序集key当中。</p></li><li><p><strong><code>zrange &lt;key&gt; &lt;start&gt; &lt;stop&gt;  [WITHSCORES]</code></strong> ：返回有序集key中，下标在<start><stop>之间的元素。带WITHSCORES，可以让分数一起和值返回到结果集。</p></li><li><p><strong><code>zrangebyscore &lt;key&gt; &lt;min&gt; &lt;max&gt; [withscores] [limit offset count]</code></strong>  ：返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。</p></li><li><p><strong><code>zrevrangebyscore &lt;key&gt; &lt;max&gt; &lt;min&gt; [withscores] [limit offset count]</code></strong>  ：同上，改为从大到小排列。</p></li><li><p><strong><code>zincrby &lt;key&gt; &lt;increment&gt; &lt;value&gt;</code></strong>  ：为元素的score加上增量</p></li><li><p><strong><code>zrem &lt;key&gt; &lt;value&gt;</code></strong> ：删除该集合下，指定值的元素</p></li><li><p><strong><code>zcount &lt;key&gt; &lt;min&gt; &lt;max&gt;</code></strong>  ：统计该集合下，分数区间[min, max]内的元素个数</p></li><li><p><strong><code>zrank &lt;key&gt; &lt;value&gt;</code></strong> 返回该值在集合中的排名，从0开始。</p></li></ul><h4 id="数据结构-3">数据结构</h4><p>SortedSet(zset)是Redis提供的一个非常特别的数据结构，一方面它等价于Java的数据结构Map&lt;String, Double&gt;，可以给每一个元素value赋予一个权重score，另一方面它又类似于TreeSet，内部的元素会按照权重score进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表。</p><p>zset底层使用了两个数据结构</p><p>（1）<strong>hash</strong>，hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。</p><p>（2）<strong>跳跃表</strong>，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表。</p><h4 id="跳跃表-跳表">跳跃表(跳表)</h4><p>1、简介</p><p>有序集合在生活中比较常见，例如根据成绩对学生排名，根据得分对玩家排名等。对于有序集合的底层实现，可以用数组、平衡树、链表等。数组不便元素的插入、删除；平衡树或红黑树虽然效率高但结构复杂；链表查询需要遍历所有效率低。Redis采用的是跳跃表。跳跃表效率堪比红黑树，实现远比红黑树简单。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923019.png" alt="image-20210621210747819"></p><h2 id="Redis配置文件">Redis配置文件</h2><h3 id="Units-单位">Units 单位</h3><p>配置大小单位,开头定义了一些基本的度量单位，只支持bytes，不支持bit</p><p>大小写不敏感</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923021.png" alt="image-20210621211554604"></p><h3 id="INCLUDES-包含">INCLUDES 包含</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923022.png" alt="image-20210621211751072"></p><p>类似jsp中的include，多实例的情况可以把公用的配置文件提取出来</p><h3 id="网络相关配置">网络相关配置</h3><h4 id="bind">bind</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923023.png" alt="image-20210621211930440"></p><p>默认情况bind=127.0.0.1只能接受本机的访问请求</p><p>不写的情况下，无限制接受任何ip地址的访问</p><p><strong>生产环境肯定要写你应用服务器的地址；服务器是需要远程访问的，所以需要将其注释掉</strong></p><h4 id="protected-mode">protected-mode</h4><p>如果开启了protected-mode，那么在没有设定bind ip且没有设密码的情况下，Redis只允许接受本机的响应</p><p>可以将本机访问保护模式设置no</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923024.png" alt="image-20210621212148841"></p><h4 id="port">port</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923025.png" alt="image-20210621212432560"></p><h4 id="tcp-backlog">tcp-backlog</h4><p>设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。</p><p>在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。</p><p>注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值（128），所以需要确认增大/proc/sys/net/core/somaxconn和/proc/sys/net/ipv4/tcp_max_syn_backlog（128）两个值来达到想要的效果</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923026.png" alt="image-20210621212524679"></p><h4 id="timeout">timeout</h4><p>一个空闲的客户端维持多少秒会关闭，0表示关闭该功能。即永不关闭。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923027.png" alt="image-20210621212711422"></p><h4 id="tcp-keepalive">tcp-keepalive</h4><p>对访问客户端的一种心跳检测，每n秒检测一次。</p><p>单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923028.png" alt="image-20210621212824961"></p><h3 id="GENERAL-通用">GENERAL 通用</h3><h4 id="daemonize">daemonize</h4><p>是否为后台进程，设置为yes</p><p>守护进程，后台启动</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923029.png" alt="image-20210621213217407"></p><h4 id="pidfile">pidfile</h4><p>存放pid文件的位置，每个实例会产生一个不同的pid文件</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923030.png" alt="image-20210621213312327"></p><h4 id="loglevel">loglevel</h4><p>指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为<strong>notice</strong></p><p>四个级别根据使用阶段来选择，生产环境选择notice 或者warning</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923031.png" alt="image-20210621213411974"></p><h4 id="logfile">logfile</h4><p>日志文件名称，默认为空</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923032.png" alt="image-20210621213457550"></p><h4 id="databases-16">databases 16</h4><p>设定库的数量 默认16，默认数据库为0，可以使用SELECT <dbid>命令在连接上指定数据库id</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923033.png" alt="image-20210621213649334"></p><h3 id="SECURITY-安全">SECURITY 安全</h3><h4 id="设置密码">设置密码</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923034.png" alt="image-20210621213936414"></p><p>访问密码的查看、设置和取消</p><p>在命令中设置密码，只是临时的。重启redis服务器，密码就还原了。</p><p>永久设置，需要在配置文件中进行设置。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923035.png" alt="image-20210621213950031"></p><h3 id="LIMITS限制">LIMITS限制</h3><h4 id="maxclients">maxclients</h4><ul><li>设置redis同时可以与多少个客户端进行连接。</li><li>默认情况下为10000个客户端。</li><li>如果达到了此限制，redis则会拒绝新的连接请求，并且向这些连接请求方发出“max number of clients reached”以作回应。</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923036.png" alt="image-20210622185034620"></p><h4 id="maxmemory">maxmemory</h4><ul><li><p>建议<strong>必须设置</strong>，否则，将内存占满，造成服务器宕机</p></li><li><p>设置redis可以使用的内存量。一旦到达内存使用上限，redis将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。</p></li><li><p>如果redis无法根据移除规则来移除内存中的数据，或者设置了“不允许移除”，那么redis则会针对那些需要申请内存的指令返回错误信息，比如SET、LPUSH等。</p></li><li><p>但是对于无内存申请的指令，仍然会正常响应，比如GET等。如果你的redis是主redis（说明你的redis有从redis），那么在设置内存使用上限时，需要在系统中留出一些内存空间给同步队列缓存，只有在你设置的是“不移除”的情况下，才不用考虑这个因素。</p></li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923037.png" alt="image-20210622185249629"></p><h4 id="maxmemory-policy">maxmemory-policy</h4><ul><li><p>volatile-lru：使用LRU算法移除key，只对设置了过期时间的键；（最近最少使用）</p></li><li><p>allkeys-lru：在所有集合key中，使用LRU算法移除key</p></li><li><p>volatile-random：在过期集合中移除随机的key，只对设置了过期时间的键</p></li><li><p>allkeys-random：在所有集合key中，移除随机的key</p></li><li><p>volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key</p></li><li><p>noeviction：不进行移除。针对写操作，只是返回错误信息</p></li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923038.png" alt="image-20210622185540045"></p><h4 id="maxmemory-samples">maxmemory-samples</h4><ul><li><p>设置样本数量，LRU算法和最小TTL算法都并非是精确的算法，而是估算值，所以你可以设置样本的大小，redis默认会检查这么多个key并选择其中LRU的那个。</p></li><li><p>一般设置3到7的数字，数值越小样本越不准确，但性能消耗越小。</p></li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923039.png" alt="image-20210622185657989"></p><h2 id="Redis的发布和订阅">Redis的发布和订阅</h2><h3 id="什么是发布和订阅">什么是发布和订阅</h3><p>Redis 发布订阅 (pub/sub) 是<strong>一种消息通信模式</strong>：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。</p><p>Redis 客户端可以订阅任意数量的频道。</p><h3 id="Redis的发布和订阅-2">Redis的发布和订阅</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923040.png" alt="image-20210622190318906"></p><h3 id="发布订阅命令行实现">发布订阅命令行实现</h3><p>1、 打开一个客户端订阅channel1</p><p><strong>SUBSCRIBE  channel1</strong></p><p>2、打开另一个客户端，给channel1发布消息hello</p><p><strong>publish channel1 hello</strong></p><p>注：发布的消息没有持久化，如果在订阅的客户端收不到hello，只能收到订阅后发布的消息</p><h2 id="Redis-新数据类型">Redis 新数据类型</h2><h3 id="Bitmaps">Bitmaps</h3><h4 id="简介">简介</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923041.png" alt="image-20210622191126812"></p><h4 id="命令">命令</h4><ol><li><p><strong>setbit</strong></p><p>格式：<strong><code>setbit &lt;key&gt; &lt;offset&gt; &lt;value&gt;</code></strong>  设置Bitmaps中某个偏移量的值(0或1)</p></li><li><p><strong>getbit</strong></p><p>格式：<strong><code>getbit &lt;key&gt; &lt;offset&gt;</code></strong>  获取Bitmaps中某个偏移量的值</p></li><li><p><strong>bitcount</strong></p><p>格式：<strong><code>bitcount &lt;key&gt; [start end]</code></strong>  统计字符串从start字节到end字节比特值为1的数量。</p></li></ol><p>统计<strong>字符串被设置为1的bit数</strong>。一般情况下，给定的整个字符串都会被进行计数，通过指定额外的 start 或 end 参数，可以让计数只在特定的位上进行。start 和 end 参数的设置，都可以使用负数值：比如 -1 表示最后一个位，而 -2 表示倒数第二个位，start、end 是指bit组的字节的下标数，二者皆包含。</p><ol start="4"><li><p><strong>bitop</strong></p><p>格式：<strong><code>bitop and(or/not/xor) &lt;destkey&gt;  [key...]</code></strong>  bitop是一个复合操作，它可以做多个Bitmaps的and(交集)、or(并集)、not(非)、xor(异或) 操作并将结果保存在destkey中。</p></li></ol><h4 id="Bitmaps-与set对比">Bitmaps 与set对比</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923042.png" alt="image-20210622195405224"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923043.png" alt="image-20210622195415675"></p><h3 id="HyperLogLog">HyperLogLog</h3><h4 id="简介-2">简介</h4><p>在工作当中，我们经常会遇到与统计相关的功能需求，比如统计网站PV（PageView页面访问量）,可以使用Redis的incr、incrby轻松实现。</p><p>但像UV（UniqueVisitor，独立访客）、独立IP数、搜索记录数等需要去重和计数的问题如何解决？<strong>这种求集合中不重复元素个数的问题称为基数问题。</strong></p><p>解决基数问题有很多种方案：</p><p>（1）数据存储在MySQL表中，使用distinct count计算不重复个数</p><p>（2）使用Redis提供的hash、set、bitmaps等数据结构来处理</p><p>以上的方案结果精确，但随着数据不断增加，导致占用空间越来越大，对于非常大的数据集是不切实际的。</p><p>能否能够降低一定的精度来平衡存储空间？Redis推出了HyperLogLog</p><p>Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。</p><p>在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。</p><p>但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。</p><p>什么是基数?</p><p>比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。</p><h4 id="命令-2">命令</h4><ul><li><p><strong><code>pfadd &lt;key&gt; &lt;element&gt; [element ...]</code></strong> ：添加指定元素到HyperLogLog中</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923044.png" alt="image-20210622195945212"></p></li><li><p><strong><code>pfcount &lt;key&gt; [key ...]</code></strong>  ：计算HLL的近似基数，可以计算多个HLL，比如用HLL存储每天的UV，计算一周的UV可以使用7天的UV合并计算即可</p></li><li><p><strong><code>pfmerge &lt;destkey&gt; &lt;sourcekey&gt; [sourcekey ...]</code></strong> ：将一个或多个HLL合并后的结果存储在另一个HLL中，比如每月活跃用户可以使用每天的活跃用户来合并计算可得</p></li></ul><h3 id="Geospatial">Geospatial</h3><h4 id="简介-3">简介</h4><p>Redis 3.2 中增加了对GEO类型的支持。GEO，Geographic，地理信息的缩写。该类型，就是元素的2维坐标，在地图上就是经纬度。redis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度Hash等常见操作。</p><h4 id="命令-3">命令</h4><ul><li><p><strong><code>geoadd &lt;key&gt; &lt;longitude&gt; &lt;latitude&gt; &lt;member&gt; [longitude latitude member ...]</code></strong>  ：添加地理位置(经度，纬度，名称)</p><p>两极无法直接添加，一般会下载城市数据，直接通过 Java 程序一次性导入。</p><p>有效的经度从 -180 度到 180 度。有效的纬度从 -85.05112878 度到 85.05112878 度。</p><p>当坐标位置超出指定范围时，该命令将会返回一个错误。</p><p>已经添加的数据，是无法再次往里面添加的。</p></li><li><p><strong><code>geopos &lt;key&gt; &lt;member&gt; [member...]</code></strong> ： 获得指定地区的坐标值</p></li><li><p><strong><code>geodist &lt;key&gt; &lt;member1&gt; &lt;member2&gt;  [m|km|ft|mi ]</code></strong>   ：获取两个位置之间的直线距离，[m|km|ft|mi]表示的是距离单位，米、千米、英尺、英里    默认使用米作为单位</p></li><li><p>**<code>georadius &lt;key&gt; &lt;longitude&gt; &lt;latitude&gt; radius m|km|ft|mi </code> **  ：以给定的经纬度为中心，找出某一半径内的元素</p></li></ul><h2 id="Redis-Jedis-测试">Redis_Jedis_测试</h2><p>redis的一个客户端工具，可以通过Jedis可以让java来操作redis</p><h3 id="远程连接Redis">远程连接Redis</h3><p>如何使用Jedis访问远程服务器(阿里云)上的Redis：</p><ol><li>给服务器添加安全组规则，开放6379端口</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923045.png" alt="image-20210622211056487"></p><ol start="2"><li><p>修改服务器的防火墙规则，开放6379端口</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl start firewalld</span><br><span class="line">systemctl status firewalld</span><br><span class="line">firewall-cmd --zone=public --add-port=6379/tcp --permanent</span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure></li><li><p>修改redis的配置文件</p><p>3.1 protected修改为no</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923046.png" alt="image-20210622211502084"></p><p>3.2 注释掉bind</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923047.png" alt="image-20210622211633901"></p><p>3.3 设置密码 (可选)</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923048.png" alt="image-20210622211711542"></p></li><li><p>最好重启一下redis</p></li><li><p>在项目的pom文件中导入依赖</p></li></ol><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>redis.clients<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jedis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="6"><li>创建一个java文件测试是否连通</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JedisDemo1</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 创建Jedis对象</span></span><br><span class="line">        <span class="type">Jedis</span> <span class="variable">jedis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Jedis</span>(<span class="string">&quot;47.98.99.197&quot;</span>, <span class="number">6379</span>);</span><br><span class="line">        jedis.auth(<span class="string">&quot;123456&quot;</span>);</span><br><span class="line">        System.out.println(jedis.ping());</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="测试相关数据类型">测试相关数据类型</h3><h4 id="Jedis-API-key">Jedis-API key</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923049.png" alt="image-20210623152223062"></p><h4 id="Jedis-API-String">Jedis-API  String</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923050.png" alt="image-20210623152257011"></p><h4 id="Jedis-API-List">Jedis-API List</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923051.png" alt="image-20210623152421899"></p><h4 id="Jedis-API-Set">Jedis-API Set</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923052.png" alt="image-20210623165523051"></p><h4 id="Jedis-API-Hash">Jedis=API Hash</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923053.png" alt="image-20210623170013791"></p><h4 id="Jedis-API-zset">Jedis-API zset</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923054.png" alt="image-20210623174928193"></p><h2 id="Jedis应用实例">Jedis应用实例</h2><h3 id="完成一个手机验证码的功能">完成一个手机验证码的功能</h3><p>要求：</p><p>1、输入手机号，点击发送后随机生成6位数字码，2分钟有效</p><p>2、输入验证码，点击验证，返回成功或失败</p><p>3、每个手机号每天只能输入3次</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hdu.jedis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> hugh</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span> 2021-06-23 18:40</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PhoneCode</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">phone</span> <span class="operator">=</span> <span class="string">&quot;1234567890&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">code</span> <span class="operator">=</span> getCode();</span><br><span class="line">        System.out.println(code);</span><br><span class="line">        verifyCode(phone, code);</span><br><span class="line">        getRedisCode(phone, code);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.验证码校验功能</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">getRedisCode</span><span class="params">(String phone, String code)</span>&#123;</span><br><span class="line">        <span class="type">Jedis</span> <span class="variable">jedis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Jedis</span>(<span class="string">&quot;47.98.99.197&quot;</span>, <span class="number">6379</span>);</span><br><span class="line">        jedis.auth(<span class="string">&quot;123456&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">codeKey</span> <span class="operator">=</span> <span class="string">&quot;VerifyCode&quot;</span> + phone + <span class="string">&quot;:code&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">redisCode</span> <span class="operator">=</span> jedis.get(codeKey);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(redisCode.equals(code))&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;验证码正确&quot;</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;验证码错误&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        jedis.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 让每个手机每天只能发送三次，验证码放到redis中，设置过期时间</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">verifyCode</span><span class="params">(String phone, String code)</span>&#123;</span><br><span class="line">        <span class="type">Jedis</span> <span class="variable">jedis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Jedis</span>(<span class="string">&quot;47.98.99.197&quot;</span>, <span class="number">6379</span>);</span><br><span class="line">        jedis.auth(<span class="string">&quot;123456&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 手机发送次数key</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">countKey</span> <span class="operator">=</span> <span class="string">&quot;VerifyCode&quot;</span> + phone + <span class="string">&quot;:count&quot;</span>;</span><br><span class="line">        <span class="comment">// 验证码key</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">codeKey</span> <span class="operator">=</span> <span class="string">&quot;VerifyCode&quot;</span> + phone + <span class="string">&quot;:code&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">Boolean</span> <span class="variable">exists</span> <span class="operator">=</span> jedis.exists(countKey);</span><br><span class="line">        <span class="keyword">if</span>(!exists)&#123;</span><br><span class="line">            jedis.setex(countKey, <span class="number">3600</span> * <span class="number">24</span>,<span class="string">&quot;0&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        jedis.incr(countKey);</span><br><span class="line">        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> jedis.get(countKey);</span><br><span class="line">        <span class="keyword">if</span>(Integer.parseInt(s) &gt; <span class="number">3</span>)&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;您今天发送的验证码超过三次,请次日再发!&quot;</span>);</span><br><span class="line">            jedis.close();</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        jedis.setex(codeKey, <span class="number">2</span> * <span class="number">60</span>, code);</span><br><span class="line">        jedis.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 生成6位数字验证码</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">getCode</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="type">Random</span> <span class="variable">random</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Random</span>();</span><br><span class="line">        <span class="type">StringBuilder</span> <span class="variable">code</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">6</span>; i++)&#123;</span><br><span class="line">            <span class="comment">// 生成一位[0, 10)内的随机数</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">rand</span> <span class="operator">=</span> random.nextInt(<span class="number">10</span>);</span><br><span class="line">            code.append(rand);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> code.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Redis与SpringBoot整合">Redis与SpringBoot整合</h2><h3 id="整合步骤">整合步骤</h3><h4 id="在pom-xml文件中引入redis相关依赖">在pom.xml文件中引入redis相关依赖</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- redis --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-redis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="在application-properties配置文件中配置redis">在application.properties配置文件中配置redis</h4><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Redis服务器地址</span></span><br><span class="line"><span class="attr">spring.redis.host</span>=<span class="string">192.168.140.136</span></span><br><span class="line"><span class="comment">#Redis服务器密码</span></span><br><span class="line"><span class="attr">spring.redis.password</span>=<span class="string">123456</span></span><br><span class="line"><span class="comment">#Redis服务器用户。注意，若使用默认用户，则不用填写这行代码</span></span><br><span class="line"><span class="attr">sprint.redis.username</span>=<span class="string">user</span></span><br><span class="line"><span class="comment">#Redis服务器连接端口</span></span><br><span class="line"><span class="attr">spring.redis.port</span>=<span class="string">6379</span></span><br><span class="line"><span class="comment"># 以上四行配置，可以使用下面一行代码替换，二者等效</span></span><br><span class="line"><span class="attr">spring.redis.url</span>=<span class="string">redis://user:123456@192.168.140.136:6379</span></span><br><span class="line"><span class="comment">#若使用默认用户，则上面一行代码也可以写成这样：</span></span><br><span class="line"><span class="attr">spring.redis.url</span>=<span class="string">redis://123456@192.168.140.136:6379</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#Redis数据库索引（默认为0）</span></span><br><span class="line"><span class="attr">spring.redis.database</span>= <span class="string">0</span></span><br><span class="line"><span class="comment">#连接超时时间（毫秒）</span></span><br><span class="line"><span class="attr">spring.redis.timeout</span>=<span class="string">1800000</span></span><br><span class="line"><span class="comment">#连接池最大连接数（使用负值表示没有限制）</span></span><br><span class="line"><span class="attr">spring.redis.lettuce.pool.max-active</span>=<span class="string">20</span></span><br><span class="line"><span class="comment">#最大阻塞等待时间(负数表示没限制)</span></span><br><span class="line"><span class="attr">spring.redis.lettuce.pool.max-wait</span>=<span class="string">-1</span></span><br><span class="line"><span class="comment">#连接池中的最大空闲连接</span></span><br><span class="line"><span class="attr">spring.redis.lettuce.pool.max-idle</span>=<span class="string">5</span></span><br><span class="line"><span class="comment">#连接池中的最小空闲连接</span></span><br><span class="line"><span class="attr">spring.redis.lettuce.pool.min-idle</span>=<span class="string">0</span></span><br></pre></td></tr></table></figure><h4 id="添加redis配置类">添加redis配置类</h4><p>固定写法，不用记，但需懂代码怎么运行的</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@EnableCaching</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RedisConfig</span> <span class="keyword">extends</span> <span class="title class_">CachingConfigurerSupport</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> RedisTemplate&lt;String, Object&gt; <span class="title function_">redisTemplate</span><span class="params">(RedisConnectionFactory factory)</span> &#123;</span><br><span class="line">        RedisTemplate&lt;String, Object&gt; template = <span class="keyword">new</span> <span class="title class_">RedisTemplate</span>&lt;&gt;();</span><br><span class="line">        RedisSerializer&lt;String&gt; redisSerializer = <span class="keyword">new</span> <span class="title class_">StringRedisSerializer</span>();</span><br><span class="line">        <span class="type">Jackson2JsonRedisSerializer</span> <span class="variable">jackson2JsonRedisSerializer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Jackson2JsonRedisSerializer</span>(Object.class);</span><br><span class="line">        <span class="type">ObjectMapper</span> <span class="variable">om</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line">        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);</span><br><span class="line">        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);</span><br><span class="line">        jackson2JsonRedisSerializer.setObjectMapper(om);</span><br><span class="line">        template.setConnectionFactory(factory);</span><br><span class="line"><span class="comment">//key序列化方式</span></span><br><span class="line">        template.setKeySerializer(redisSerializer);</span><br><span class="line"><span class="comment">//value序列化</span></span><br><span class="line">        template.setValueSerializer(jackson2JsonRedisSerializer);</span><br><span class="line"><span class="comment">//value hashmap序列化</span></span><br><span class="line">        template.setHashValueSerializer(jackson2JsonRedisSerializer);</span><br><span class="line">        <span class="keyword">return</span> template;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> CacheManager <span class="title function_">cacheManager</span><span class="params">(RedisConnectionFactory factory)</span> &#123;</span><br><span class="line">        RedisSerializer&lt;String&gt; redisSerializer = <span class="keyword">new</span> <span class="title class_">StringRedisSerializer</span>();</span><br><span class="line">        <span class="type">Jackson2JsonRedisSerializer</span> <span class="variable">jackson2JsonRedisSerializer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Jackson2JsonRedisSerializer</span>(Object.class);</span><br><span class="line"><span class="comment">//解决查询缓存转换异常的问题</span></span><br><span class="line">        <span class="type">ObjectMapper</span> <span class="variable">om</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line">        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);</span><br><span class="line">        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);</span><br><span class="line">        jackson2JsonRedisSerializer.setObjectMapper(om);</span><br><span class="line"><span class="comment">// 配置序列化（解决乱码的问题）,过期时间600秒</span></span><br><span class="line">        <span class="type">RedisCacheConfiguration</span> <span class="variable">config</span> <span class="operator">=</span> RedisCacheConfiguration.defaultCacheConfig()</span><br><span class="line">                .entryTtl(Duration.ofSeconds(<span class="number">600</span>))              .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer))                .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer))</span><br><span class="line">                .disableCachingNullValues();</span><br><span class="line">        <span class="type">RedisCacheManager</span> <span class="variable">cacheManager</span> <span class="operator">=</span> RedisCacheManager.builder(factory)</span><br><span class="line">                .cacheDefaults(config)</span><br><span class="line">                .build();</span><br><span class="line">        <span class="keyword">return</span> cacheManager;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="测试一下">测试一下</h4><p>RedisTestController中添加测试方法</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/redisTest&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RedisTestController</span> &#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> RedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">testRedis</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">//设置值到redis</span></span><br><span class="line">        redisTemplate.opsForValue().set(<span class="string">&quot;name&quot;</span>,<span class="string">&quot;lucy&quot;</span>);</span><br><span class="line">        <span class="comment">//从redis获取值</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> (String)redisTemplate.opsForValue().get(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Redis-事务-锁机制-秒杀">Redis  事务   锁机制  秒杀</h2><h3 id="Redis的事务定义">Redis的事务定义</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923055.png" alt="image-20210623195127724"></p><p>Redis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p><p>Redis事务的主要作用就是串联多个命令防止别的命令插队。</p><h3 id="Multi、Exec、discard">Multi、Exec、discard</h3><ul><li><code>Multi</code>：标记一个事务块的开始</li><li><code>Exec</code>：执行所有事务块内的命令</li><li><code>Discard</code>：取消事务，放弃执行事务块内的所有命令</li></ul><p>从输入Multi命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入Exec后，Redis会将之前的命令队列中的命令依次执行。</p><p>组队的过程中可以通过discard来放弃组队</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923056.png" alt="image-20210623200001896"></p><h3 id="事务的错误处理">事务的错误处理</h3><ul><li><strong>组队阶段</strong>如果某个命令出现了报告错误，<strong>执行时</strong>整个的所有队列都会被取消。</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923057.png" alt="image-20210623203217188"></p><ul><li>如果<strong>执行阶段某个命令报出了错误</strong>，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。</li></ul><h3 id="为什么要做成事务">为什么要做成事务</h3><p>想想一个场景：有很多人有你的账户,同时去参加双十一抢购</p><h3 id="事务冲突的问题">事务冲突的问题</h3><h4 id="例子">例子</h4><p>一个请求想给金额减8000</p><p>一个请求想给金额减5000</p><p>一个请求想给金额减1000</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923058.png" alt="image-20210623204439820"></p><h4 id="悲观锁">悲观锁</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923059.png" alt="image-20210623204548636"></p><p><strong>悲观锁(Pessimistic Lock)</strong>, 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以<strong>每次在拿数据的时候都会上锁</strong>，这样别人想拿这个数据就会block直到它拿到锁。<strong>传统的关系型数据库里边就用到了很多这种锁机制</strong>，比如<strong>行锁</strong>，<strong>表锁</strong>等，<strong>读锁</strong>，<strong>写锁</strong>等，都是在做操作之前先上锁。</p><h4 id="乐观锁">乐观锁</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923060.png" alt="image-20210623204646169"></p><p><strong>乐观锁(Optimistic Lock),</strong> 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是<strong>在更新的时候会判断</strong>一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。<strong>乐观锁适用于多读的应用类型，这样可以提高吞吐量</strong>。Redis就是利用这种check-and-set机制实现事务的。</p><h4 id="WATCH-key-key-…">WATCH key [key …]</h4><p>在执行multi之前，先执行watch key1 [key2],可以监视一个(或多个) key ，如果在事务<strong>执行之前这个(或这些) key被其他命令所改动，那么事务将被打断。</strong></p><h4 id="unwatch">unwatch</h4><p>取消 WATCH 命令对所有 key 的监视。</p><p>如果在执行 WATCH 命令之后，EXEC 命令或DISCARD 命令先被执行了的话，那么就不需要再执行UNWATCH 了。</p><h3 id="Redis事务三特性">Redis事务三特性</h3><ul><li>**单独的隔离操作 **</li></ul><p>事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p><ul><li>**没有隔离级别的概念 **</li></ul><p>队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行</p><ul><li>**不保证原子性 **</li></ul><p>事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚</p><h2 id="Redis-事务-秒杀案例">Redis 事务  秒杀案例</h2><h3 id="解决计数器和人员记录的事务操作">解决计数器和人员记录的事务操作</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923061.png" alt="image-20210624122259426"></p><h3 id="Redis事务——秒杀并发模拟">Redis事务——秒杀并发模拟</h3><h4 id="秒杀过程代码">秒杀过程代码</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//秒杀过程</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">doSecKill</span><span class="params">(String uid,String prodid)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">//1 uid和prodid非空判断</span></span><br><span class="line">    <span class="keyword">if</span>(uid == <span class="literal">null</span> || prodid == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2 连接redis</span></span><br><span class="line">    <span class="comment">//Jedis jedis = new Jedis(&quot;192.168.44.168&quot;,6379);</span></span><br><span class="line">    <span class="comment">//通过连接池得到jedis对象</span></span><br><span class="line">    <span class="type">JedisPool</span> <span class="variable">jedisPoolInstance</span> <span class="operator">=</span> JedisPoolUtil.getJedisPoolInstance();</span><br><span class="line">    <span class="type">Jedis</span> <span class="variable">jedis</span> <span class="operator">=</span> jedisPoolInstance.getResource();</span><br><span class="line">    jedis.auth(<span class="string">&quot;123456&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3 拼接key</span></span><br><span class="line">    <span class="comment">// 3.1 库存key</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">kcKey</span> <span class="operator">=</span> <span class="string">&quot;sk:&quot;</span>+prodid+<span class="string">&quot;:qt&quot;</span>;</span><br><span class="line">    <span class="comment">// 3.2 秒杀成功用户key</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">userKey</span> <span class="operator">=</span> <span class="string">&quot;sk:&quot;</span>+prodid+<span class="string">&quot;:user&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//监视库存, 增加乐观锁</span></span><br><span class="line">    jedis.watch(kcKey);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4 获取库存，如果库存null，秒杀还没有开始</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">kc</span> <span class="operator">=</span> jedis.get(kcKey);</span><br><span class="line">    <span class="keyword">if</span>(kc == <span class="literal">null</span>) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;秒杀还没有开始，请等待&quot;</span>);</span><br><span class="line">        jedis.close();</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5 判断用户是否重复秒杀操作</span></span><br><span class="line">    <span class="keyword">if</span>(jedis.sismember(userKey, uid)) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;已经秒杀成功了，不能重复秒杀&quot;</span>);</span><br><span class="line">        jedis.close();</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//6 判断如果商品数量，库存数量小于1，秒杀结束</span></span><br><span class="line">    <span class="keyword">if</span>(Integer.parseInt(kc)&lt;=<span class="number">0</span>) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;秒杀已经结束了&quot;</span>);</span><br><span class="line">        jedis.close();</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//7 秒杀过程</span></span><br><span class="line">    <span class="comment">//使用事务</span></span><br><span class="line">    <span class="type">Transaction</span> <span class="variable">multi</span> <span class="operator">=</span> jedis.multi();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//组队操作</span></span><br><span class="line">    multi.decr(kcKey);</span><br><span class="line">    multi.sadd(userKey,uid);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//执行</span></span><br><span class="line">    List&lt;Object&gt; results = multi.exec();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(results == <span class="literal">null</span> || results.size()==<span class="number">0</span>) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;秒杀失败了....&quot;</span>);</span><br><span class="line">        jedis.close();</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//7.1 库存-1</span></span><br><span class="line">    <span class="comment">//jedis.decr(kcKey);</span></span><br><span class="line">    <span class="comment">//7.2 把秒杀成功用户添加清单里面</span></span><br><span class="line">    <span class="comment">//jedis.sadd(userKey,uid);</span></span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;秒杀成功了..&quot;</span>);</span><br><span class="line">    jedis.close();</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="使用工具ab模拟测试">使用工具ab模拟测试</h4><p>CentOS6 默认安装</p><p>CentOS7需要手动安装</p><p>联网：<code>yum install httpd-tools</code></p><h4 id="通过ab测试">通过ab测试</h4><p>安装好httpd-tools后，在命令行输入<strong>ab --help</strong> 可以查看ab的用法</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923062.png" alt="image-20210625162935509"></p><h3 id="超卖问题">超卖问题</h3><p>超卖问题：东西已经卖完了，但还有人能抢购成功</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923063.png" alt="image-20210626165636888"></p><h4 id="使用乐观锁并使用事务">使用乐观锁并使用事务</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//监视库存</span></span><br><span class="line">jedis.watch(kcKey);</span><br><span class="line"></span><br><span class="line"><span class="comment">//4 获取库存，如果库存null，秒杀还没有开始</span></span><br><span class="line"><span class="type">String</span> <span class="variable">kc</span> <span class="operator">=</span> jedis.get(kcKey);</span><br><span class="line"><span class="keyword">if</span>(kc == <span class="literal">null</span>) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;秒杀还没有开始，请等待&quot;</span>);</span><br><span class="line">    jedis.close();</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5 判断用户是否重复秒杀操作</span></span><br><span class="line"><span class="keyword">if</span>(jedis.sismember(userKey, uid)) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;已经秒杀成功了，不能重复秒杀&quot;</span>);</span><br><span class="line">    jedis.close();</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//6 判断如果商品数量，库存数量小于1，秒杀结束</span></span><br><span class="line"><span class="keyword">if</span>(Integer.parseInt(kc)&lt;=<span class="number">0</span>) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;秒杀已经结束了&quot;</span>);</span><br><span class="line">    jedis.close();</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//7 秒杀过程</span></span><br><span class="line"><span class="comment">//使用事务</span></span><br><span class="line"><span class="type">Transaction</span> <span class="variable">multi</span> <span class="operator">=</span> jedis.multi();</span><br><span class="line"></span><br><span class="line"><span class="comment">//组队操作</span></span><br><span class="line">multi.decr(kcKey);</span><br><span class="line">multi.sadd(userKey,uid);</span><br><span class="line"></span><br><span class="line"><span class="comment">//执行</span></span><br><span class="line">List&lt;Object&gt; results = multi.exec();</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(results == <span class="literal">null</span> || results.size()==<span class="number">0</span>) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;秒杀失败了....&quot;</span>);</span><br><span class="line">    jedis.close();</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="连接超时问题">连接超时问题</h3><p>连接超时问题，可以通过连接池来解决</p><h4 id="连接池">连接池</h4><p>节省每次连接redis服务带来的消耗，把连接好的实例反复利用。</p><p>通过参数管理连接的行为</p><p>代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JedisPoolUtil</span> &#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> <span class="type">JedisPool</span> <span class="variable">jedisPool</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="title function_">JedisPoolUtil</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> JedisPool <span class="title function_">getJedisPoolInstance</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="literal">null</span> == jedisPool) &#123;</span><br><span class="line"><span class="keyword">synchronized</span> (JedisPoolUtil.class) &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="literal">null</span> == jedisPool) &#123;</span><br><span class="line"><span class="type">JedisPoolConfig</span> <span class="variable">poolConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JedisPoolConfig</span>();</span><br><span class="line"></span><br><span class="line">poolConfig.setMaxTotal(<span class="number">200</span>);</span><br><span class="line">poolConfig.setMaxIdle(<span class="number">32</span>);</span><br><span class="line">poolConfig.setMaxWaitMillis(<span class="number">100</span>*<span class="number">1000</span>);</span><br><span class="line">poolConfig.setBlockWhenExhausted(<span class="literal">true</span>);</span><br><span class="line">poolConfig.setTestOnBorrow(<span class="literal">true</span>);  <span class="comment">// ping  PONG</span></span><br><span class="line"></span><br><span class="line">jedisPool = <span class="keyword">new</span> <span class="title class_">JedisPool</span>(poolConfig, <span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">6379</span>, <span class="number">6000</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> jedisPool;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">release</span><span class="params">(JedisPool jedisPool, Jedis jedis)</span> &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="literal">null</span> != jedis) &#123;</span><br><span class="line">jedisPool.returnResource(jedis);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>连接池参数</p><ul><li><p><code>MaxTotal</code>：控制一个pool可分配多少个jedis实例，通过pool.getResource()来获取；如果赋值为-1，则表示不限制；如果pool已经分配了MaxTotal个jedis实例，则此时pool的状态为exhausted。</p></li><li><p><code>maxIdle</code>：控制一个pool最多有多少个状态为idle(空闲)的jedis实例；</p></li><li><p><code>MaxWaitMillis</code>：表示当borrow一个jedis实例时，最大的等待毫秒数，如果超过等待时间，则直接抛JedisConnectionException；</p></li><li><p><code>testOnBorrow</code>：获得一个jedis实例的时候是否检查连接可用性（ping()）；如果为true，则得到的jedis实例均是可用的；</p></li></ul><h3 id="库存遗留问题">库存遗留问题</h3><p><strong>乐观锁会造成库存遗留问题</strong></p><p>假设有500个商品，有2000人去抢购。</p><p>由于乐观锁的存在，若有多个人同时抢购，则会存在“一个人抢购成功，其余人失败”的问题，导致库存遗留问题。</p><p>比如，这里可能存在2000个人抢购，则会导致一个人抢购成功，其余人抢购失败，导致遗留499件商品未卖出。</p><h4 id="LUA脚本">LUA脚本</h4><p>可以使用LUA脚本来解决库存遗留问题</p><p>Lua 是一个小巧的<a href="http://baike.baidu.com/item/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80">脚本语言</a>，Lua脚本可以很容易的被C/C++ 代码调用，也可以反过来调用C/C++的函数，Lua并没有提供强大的库，一个完整的Lua解释器不过200k，所以Lua不适合作为开发独立应用程序的语言，而是作为嵌入式脚本语言。</p><p>很多应用程序、游戏使用LUA作为自己的嵌入式脚本语言，以此来实现可配置性、可扩展性。</p><p>这其中包括魔兽争霸地图、魔兽世界、博德之门、愤怒的小鸟等众多游戏插件或外挂。</p><p><a href="https://www.w3cschool.cn/lua/">https://www.w3cschool.cn/lua/</a></p><h4 id="LUA脚本在Redis中的优势">LUA脚本在Redis中的优势</h4><p>将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数。提升性能。</p><p>LUA脚本是类似redis事务，有一定的原子性，不会被其他命令插队，可以完成一些redis事务性的操作。</p><p>但是注意redis的lua脚本功能，只有在Redis 2.6以上的版本才可以使用。</p><p>利用lua脚本淘汰用户，解决超卖问题。</p><p>redis 2.6版本以后，通过lua脚本解决<strong>争抢问题</strong>，实际上是<strong>redis</strong> <strong>利用其单线程的特性，用任务队列的方式解决多任务并发问题</strong>。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923064.png" alt="image-20210626172224981"></p><p><strong>LUA脚本如下：</strong></p><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 定义两个变量，第一个用户id，第二个商品id</span></span><br><span class="line"><span class="keyword">local</span> userid=KEYS[<span class="number">1</span>]; </span><br><span class="line"><span class="keyword">local</span> prodid=KEYS[<span class="number">2</span>];</span><br><span class="line"><span class="comment">-- 拼接两个key</span></span><br><span class="line"><span class="keyword">local</span> qtkey=<span class="string">&quot;sk:&quot;</span>..prodid..<span class="string">&quot;:qt&quot;</span>;</span><br><span class="line"><span class="keyword">local</span> usersKey=<span class="string">&quot;sk:&quot;</span>..prodid.<span class="string">&quot;:usr&#x27;; </span></span><br><span class="line"><span class="string">-- redis.call调用redis中的命令</span></span><br><span class="line"><span class="string">local userExists=redis.call(&quot;</span>sismember<span class="string">&quot;,usersKey,userid);</span></span><br><span class="line"><span class="string">-- 如果用户存在，则return 2，表示已经秒杀过了</span></span><br><span class="line"><span class="string">if tonumber(userExists)==1 then </span></span><br><span class="line"><span class="string">  return 2;</span></span><br><span class="line"><span class="string">end</span></span><br><span class="line"><span class="string">local num= redis.call(&quot;</span>get<span class="string">&quot; ,qtkey);</span></span><br><span class="line"><span class="string">-- 若库存为0，return 0，表示秒杀结束</span></span><br><span class="line"><span class="string">if tonumber(num)&lt;=0 then </span></span><br><span class="line"><span class="string">  return 0; </span></span><br><span class="line"><span class="string">else </span></span><br><span class="line"><span class="string">  redis.call(&quot;</span>decr<span class="string">&quot;,qtkey);</span></span><br><span class="line"><span class="string">  redis.call(&quot;</span>sadd<span class="string">&quot;,usersKey,userid);</span></span><br><span class="line"><span class="string">end</span></span><br><span class="line"><span class="string">-- 秒杀成功</span></span><br><span class="line"><span class="string">return 1;</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure><h4 id="使用LUA解决库存遗留问题">使用LUA解决库存遗留问题</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 两段LUA脚本</span></span><br><span class="line"><span class="keyword">static</span> <span class="type">String</span> <span class="variable">secKillScript</span> <span class="operator">=</span><span class="string">&quot;local userid=KEYS[1];\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;local prodid=KEYS[2];\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;local qtkey=&#x27;sk:&#x27;..prodid..\&quot;:qt\&quot;;\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;local usersKey=&#x27;sk:&#x27;..prodid..\&quot;:usr\&quot;;\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;local userExists=redis.call(\&quot;sismember\&quot;,usersKey,userid);\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;if tonumber(userExists)==1 then \r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;   return 2;\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;end\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;local num= redis.call(\&quot;get\&quot; ,qtkey);\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;if tonumber(num)&lt;=0 then \r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;   return 0;\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;else \r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;   redis.call(\&quot;decr\&quot;,qtkey);\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;   redis.call(\&quot;sadd\&quot;,usersKey,userid);\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;end\r\n&quot;</span> + </span><br><span class="line">    <span class="string">&quot;return 1&quot;</span> ;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="type">String</span> <span class="variable">secKillScript2</span> <span class="operator">=</span> </span><br><span class="line">    <span class="string">&quot;local userExists=redis.call(\&quot;sismember\&quot;,\&quot;&#123;sk&#125;:0101:usr\&quot;,userid);\r\n&quot;</span> +</span><br><span class="line">    <span class="string">&quot; return 1&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 秒杀过程</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">doSecKill</span><span class="params">(String uid,String prodid)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"><span class="comment">// 从连接池中获取redis连接</span></span><br><span class="line">    <span class="type">JedisPool</span> <span class="variable">jedispool</span> <span class="operator">=</span>  JedisPoolUtil.getJedisPoolInstance();</span><br><span class="line">    Jedis jedis=jedispool.getResource();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过scriptLoad()加载LUA脚本</span></span><br><span class="line">    String sha1=  jedis.scriptLoad(secKillScript);</span><br><span class="line">    <span class="comment">// evalsha()</span></span><br><span class="line">    <span class="comment">// 参数 sha1，通过scriptLoad生成的sha1校验码</span></span><br><span class="line">    <span class="comment">// 参数 2，用于指定键名参数的个数</span></span><br><span class="line">    <span class="comment">// 参数 uid，在脚本中的KEYS[1]</span></span><br><span class="line">    <span class="comment">// 参数 prodid, 在脚本中的KEYS[2]</span></span><br><span class="line">    Object result= jedis.evalsha(sha1, <span class="number">2</span>, uid,prodid);</span><br><span class="line"></span><br><span class="line">    String reString=String.valueOf(result);</span><br><span class="line">    <span class="keyword">if</span> (<span class="string">&quot;0&quot;</span>.equals( reString )  ) &#123;</span><br><span class="line">        System.err.println(<span class="string">&quot;已抢空！！&quot;</span>);</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="string">&quot;1&quot;</span>.equals( reString )  )  &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;抢购成功！！！！&quot;</span>);</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="string">&quot;2&quot;</span>.equals( reString )  )  &#123;</span><br><span class="line">        System.err.println(<span class="string">&quot;该用户已抢过！！&quot;</span>);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        System.err.println(<span class="string">&quot;抢购异常！！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    jedis.close();</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Redis持久化之RDB">Redis持久化之RDB</h2><h3 id="总体介绍">总体介绍</h3><p>RDB = Redis DataBase</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923065.png" alt="image-20210626192819665"></p><p>Redis提供2个不同形式的持久化方式</p><ul><li>RDB (Redis DataBase)</li><li>AOF (Append Only File)</li></ul><h3 id="RDB-Redis-DataBase">RDB(Redis DataBase)</h3><h4 id="官网介绍">官网介绍</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923066.png" alt="image-20210626192954109"></p><h4 id="什么是RDB">什么是RDB</h4><p>RDB:  在<strong>指定的时间间隔</strong>内将内存中的数据集快照写入磁盘， 也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里</p><h4 id="备份是如何执行的">备份是如何执行的</h4><p>Redis会单独创建（fork）一个子进程来进行持久化，会先将数据<strong>写入到 一个临时文件中</strong>，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能。</p><p>如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。</p><p><strong>RDB的缺点是最后一次持久化后的数据可能丢失</strong>。</p><h4 id="Fork">Fork</h4><ul><li>Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程</li><li>在Linux程序中，fork()会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，Linux中引入了“<strong>写时复制技术</strong>”</li><li><strong>一般情况父进程和子进程会共用同一段物理内存</strong>，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。</li></ul><h4 id="RDB持久化流程">RDB持久化流程</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923067.png" alt="image-20210626204947348"></p><h4 id="dump-rdb文件">dump.rdb文件</h4><p>在redis.conf中配置文件名称dbfilename，默认为dump.rdb</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923068.png" alt="image-20210626205055418"></p><h4 id="配置位置">配置位置</h4><p>rdb文件的保存路径，也可以修改。默认为Redis启动时命令行所在的目录下</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923069.png" alt="image-20210626205124748"></p><h4 id="如何触发RDB快照；保持策略">如何触发RDB快照；保持策略</h4><h5 id="配置文件中默认的快照配置">配置文件中默认的快照配置</h5><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923070.png" alt="image-20210626203918414"></p><h5 id="命令save-VS-bgsave">命令save VS bgsave</h5><ul><li><p><code>save</code> ：save时只管保存，其它不管  全部阻塞。手动保存。不建议。</p><p>该命令会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成为止。</p></li><li><p><code>bgsave</code>：Redis会在后台<strong>异步进行快照操作</strong>， 快照同时还可以响应客户端请求。</p></li></ul><p>可以通过lastsave 命令获取最后一次成功执行快照的时间</p><p><strong>save与bgsave对比：</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923071.png" alt="image-20210627104857719"></p><h5 id="flushall-命令">flushall 命令</h5><p>执行flushall命令，也会产生dump.rdb文件，但里面是空的，无意义</p><h5 id="Save">Save</h5><p>格式：<code>save 秒钟 写操作次数</code></p><p>RDB是整个内存的压缩过的Snapshot，RDB的数据结构，可以配置复合的快照触发条件，</p><p>默认是1分钟内改了1万次，或5分钟内改了10次，或15分钟内改了1次。</p><p>禁用</p><p>不设置save指令，或者给save传入空字符串</p><h5 id="stop-writes-on-bgsave-error">stop-writes-on-bgsave-error</h5><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923072.png" alt="image-20210626210400859"></p><p>当Redis无法写入磁盘的话(比如磁盘满了)，直接关掉Redis的写操作。推荐yes.默认为yes.</p><p><strong>当启用了RDB且最后一次后台保存数据失败，Redis是否停止接收数据。</strong></p><h5 id="rdbcompression-压缩文件">rdbcompression  压缩文件</h5><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923073.png" alt="image-20210626210541655"></p><p><strong>对于存储到磁盘中的快照，可以设置是否进行压缩存储</strong>。如果是的话，redis会采用LZF算法进行压缩。</p><p>如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能。推荐yes.默认yes.</p><h5 id="rdbchecksum-检查完整性">rdbchecksum   检查完整性</h5><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923074.png" alt="image-20210626210653989"></p><p>在存储快照后，还可以让redis使用CRC64算法来进行数据校验，</p><p>但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能</p><p>推荐yes.默认yes</p><h5 id="rdb备份">rdb备份</h5><p>先通过config get dir 查询rdb文件的目录</p><p>将*.rdb的文件拷贝到别的地方</p><p>rdb的恢复</p><ul><li><p>关闭Redis</p></li><li><p>先把备份的文件拷贝到工作目录下 cp dump2.rdb dump.rdb</p></li><li><p>启动Redis, 备份数据会直接加载</p></li></ul><h4 id="RDB优势与劣势">RDB优势与劣势</h4><p><strong>优势</strong></p><ul><li><p>适合大规模的数据恢复</p></li><li><p>对数据完整性和一致性要求不高的时候更适合使用</p></li><li><p>节省磁盘空间</p></li><li><p>恢复速度快</p></li></ul><p><strong>劣势</strong></p><ul><li><p>Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑</p></li><li><p>虽然Redis在fork时使用了<strong>写时拷贝技术</strong>,但是如果数据庞大时还是比较消耗性能。</p></li><li><p>在备份周期在一定间隔时间做一次备份，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。</p></li></ul><h4 id="如何停止">如何停止</h4><p>动态停止RDB：redis-cli config set save “” #save后给空值，表示禁用保存策略</p><h4 id="RDB小结">RDB小结</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923075.png" alt="image-20210627105446260"></p><h2 id="Redis持久化之AOF">Redis持久化之AOF</h2><h3 id="AOF-Append-Only-File">AOF(Append Only File)</h3><h4 id="AOF是什么">AOF是什么</h4><p>以<strong>日志</strong>的形式来记录每个写操作（增量保存），将Redis执行过的所有写指令记录下来(<strong>读操作不记录</strong>)， <strong>只许追加文件但不可以改写文件</strong>，redis启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作</p><h4 id="AOF持久化流程">AOF持久化流程</h4><p>（1）客户端的请求写命令会被append追加到AOF缓冲区内；</p><p>（2）AOF缓冲区根据**AOF持久化策略[always,everysec,no]**将操作sync同步到磁盘的AOF文件中；</p><p>（3）AOF文件大小超过重写策略或手动重写时，会对AOF文件rewrite重写，压缩AOF文件容量；</p><p>（4）Redis服务重启时，会重新load加载AOF文件中的写操作达到数据恢复的目的；</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923076.png" alt="image-20210627111101086"></p><h4 id="AOF默认不开启">AOF默认不开启</h4><p>可以在redis.conf中配置文件名称，默认为 appendonly.aof</p><p><strong>AOF文件的保存路径，同RDB的路径一致。</strong></p><p>AOF默认不开启，若要开启，则将redis.conf中的appendonly no 改成yes</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923077.png" alt="image-20210627111813836"></p><h4 id="AOF和RDB同时开启，redis听谁的？">AOF和RDB同时开启，redis听谁的？</h4><p>AOF和RDB同时开启，系统默认取AOF的数据（数据不会存在丢失）</p><h4 id="AOF启动-修复-恢复">AOF启动/修复/恢复</h4><ul><li><p>AOF的备份机制和性能虽然和RDB不同, 但是备份和恢复的操作同RDB一样，都是拷贝备份文件，需要恢复时再拷贝到Redis工作目录下，启动系统即加载。</p></li><li><p>正常恢复</p><ul><li>在redis.conf中修改默认的appendonly no,改为yes</li><li>将有数据的aof文件复制一份保存到对应目录(查看目录：config get dir)</li><li>恢复：重启redis，然后重新加载</li></ul></li><li><p>异常恢复</p><ul><li><p>在redis.conf中修改默认的appendonly no,改为yes</p></li><li><p>如遇到AOF文件损坏，通过以下命令恢复：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/usr/local/redis-6.2.4/bin/redis-check-aof --fix appendonly.aof</span><br></pre></td></tr></table></figure></li><li><p>备份被写坏的AOF文件</p></li><li><p>恢复：重启redis，然后重新加载</p></li></ul></li></ul><h4 id="AOF同步频率-持久化策略-设置">AOF同步频率(持久化策略)设置</h4><ul><li><strong>appendfsync always</strong>  始终同步，每次Redis的写入都会立刻记入日志；性能较差，但数据完整性比较好</li><li><strong>appendfsync everysec</strong>  每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢掉</li><li><strong>appendfsync no</strong>  redis不主动进行同步，把同步时机交给操作系统</li></ul><h4 id="Rewrite压缩">Rewrite压缩</h4><p>(1)<strong>Rewrite是什么?</strong></p><p>AOF采用文件追加方式，文件会越来越大。为避免出现此种情况，新增了重写机制, 当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩， 只保留可以恢复数据的最小指令集.可以使用命令bgrewriteaof</p><p>(2) <strong>重写原理，如何实现重写?</strong></p><p>AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)，redis4.0版本后的重写，是指上就是把rdb 的快照，以二级制的形式附在新的aof头部，作为已有的历史数据，替换掉原来的流水账操作。</p><p><strong>no-appendfsync-on-rewrite</strong>：</p><p>如果 no-appendfsync-on-rewrite=yes ,不写入aof文件只写入缓存，用户请求不会阻塞，但是在这段时间如果宕机会丢失这段时间的缓存数据。（降低数据安全性，提高性能）</p><p>如果 no-appendfsync-on-rewrite=no, 还是会把数据往磁盘里刷，但是遇到重写操作，可能会发生阻塞。（数据安全，但是性能降低）</p><p><strong>触发机制，何时重写?</strong></p><p>Redis会记录上次重写时的AOF大小，<strong>默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发</strong></p><p>重写虽然可以节约大量磁盘空间，减少恢复时间。但是每次重写还是有一定的负担的，因此<strong>设定Redis要满足一定条件才会进行重写</strong>。</p><p>auto-aof-rewrite-percentage：设置重写的基准值，文件达到100%时开始重写（文件是原来重写后文件的2倍时触发）</p><p>auto-aof-rewrite-min-size：设置重写的基准值，最小文件64MB。达到这个值开始重写。</p><p>例如：文件达到70MB开始重写，降到50MB，下次什么时候开始重写？100MB</p><p>系统载入时或者上次重写完毕时，Redis会记录此时AOF大小，设为<strong>base_size</strong>,</p><p>如果**Redis的AOF当前大小&gt;= base_size +base_size*100% (默认)且当前大小&gt;=64mb(默认)**的情况下，Redis会对AOF进行重写。</p><p>(3) <strong>重写流程</strong></p><p>（1）bgrewriteaof触发重写，判断是否当前有bgsave或bgrewriteaof在运行，如果有，则等待该命令结束后再继续执行。</p><p>（2）主进程fork出子进程执行重写操作，保证主进程不会阻塞。</p><p>（3）子进程遍历redis内存中数据到临时文件，客户端的写请求同时写入aof_buf缓冲区和aof_rewrite_buf重写缓冲区保证原AOF文件完整以及新AOF文件生成期间的新的数据修改动作不会丢失。</p><p>（4）1).子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。2).主进程把aof_rewrite_buf中的数据写入到新的AOF文件。</p><p>（5）使用新的AOF文件覆盖旧的AOF文件，完成AOF重写。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923078.png" alt="image-20210627123119543"></p><h4 id="优势">优势</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923079.png" alt="image-20210627123238207"></p><ul><li><p>备份机制更稳健，丢失数据概率更低。</p></li><li><p>可读的日志文本，通过操作AOF稳健，可以处理误操作。</p></li></ul><h4 id="劣势">劣势</h4><ul><li><p>比起RDB占用更多的磁盘空间。</p></li><li><p>恢复备份速度要慢。</p></li><li><p>每次读写都同步的话，有一定的性能压力。</p></li><li><p>存在个别Bug，造成恢复不能。</p></li></ul><h4 id="小总结">小总结</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923080.png" alt="image-20210627123412679"></p><h3 id="总结">总结</h3><h4 id="RDB和AOF用哪个好？">RDB和AOF用哪个好？</h4><ul><li><p>官方推荐两个都启用。</p></li><li><p>如果对数据不敏感，可以选单独用RDB。</p></li><li><p>不建议单独用 AOF，因为可能会出现Bug。</p></li><li><p>如果只是做纯内存缓存，可以都不用。</p></li></ul><h4 id="官网建议">官网建议</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923081.png" alt="image-20210627135736806"></p><ul><li><p>RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储</p></li><li><p>AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.</p></li><li><p>Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大</p></li><li><p>只做缓存：如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式.</p></li><li><p>同时开启两种持久化方式</p></li><li><p>在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据, 因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整.</p></li><li><p>RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？</p></li><li><p>建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)， 快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。</p></li></ul><p><strong>性能建议</strong></p><p>因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。</p><p>如果使用AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。</p><p>代价,一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。</p><p>只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。</p><p>默认超过原大小100%大小时重写可以改到适当的数值。</p><h2 id="Redis-主从复制">Redis  主从复制</h2><h3 id="什么是主从复制">什么是主从复制</h3><p>主机数据更新后根据配置和策略， 自动同步到备机的<strong>master/slaver机制</strong>，<strong>Master以写为主，Slave以读为主</strong></p><p>Master就是主，Slave就是从</p><h3 id="主从复制可以干嘛">主从复制可以干嘛</h3><ul><li><p>读写分离，性能扩展</p></li><li><p>容灾快速恢复</p></li></ul><p>主从复制中，可以有多个从服务器，但只能有一台主服务器</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923082.png" alt="image-20210627140452878"></p><h3 id="搭建一主多从">搭建一主多从</h3><p>由于目前本人只有一台主机，所以为模拟一主多从的情况，在一台主机上配置三台redis服务器。搭建后的效果图如下：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923083.png" alt="image-20210627194317127"></p><p><strong>配置三台redis服务器：</strong></p><ol><li><p>为了方便，创建一个新目录/myredis，并进入该目录下</p></li><li><p>将原来的配置文件redis.conf复制一份到/myredis目录下</p></li><li><p>在/myredis目录下，新建redis6379.conf，填写以下内容</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">include /myredis/redis.conf</span><br><span class="line">pidfile /var/run/redis_6379.pid</span><br><span class="line">port 6379</span><br><span class="line">dbfilename dump6379.rdb</span><br></pre></td></tr></table></figure></li><li><p>在/myredis目录下，新建redis6380.conf，填写以下内容</p><p><strong>注意：由于本人的redis设置了密码，所以在从Redis服务器的配置文件redis6380.conf中需要加入最后一行 masterauth + 主redis服务器的密码。若无密码可以不加</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">include /myredis/redis.conf</span><br><span class="line">pidfile /var/run/redis_6379.pid</span><br><span class="line">port 6379</span><br><span class="line">dbfilename dump6379.rdb</span><br><span class="line">masterauth 123456</span><br></pre></td></tr></table></figure></li><li><p>在/myredis目录下，新建redis6381.conf，填写以下内容</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">include /myredis/redis.conf</span><br><span class="line">pidfile /var/run/redis_6379.pid</span><br><span class="line">port 6379</span><br><span class="line">dbfilename dump6379.rdb</span><br><span class="line">masterauth 123456</span><br></pre></td></tr></table></figure></li><li><p>启动三台redis服务器</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis-server redis6379.conf</span><br><span class="line">redis-server redis6380.conf</span><br><span class="line">redis-server redis6381.conf</span><br></pre></td></tr></table></figure></li><li><p>查看系统进程，看看三台服务器是否启动</p></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923084.png" alt="image-20210627195304447"></p><ol start="8"><li><p>使用  <strong>info replication</strong>  命令查看三台服务器运行情况</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923085.png" alt="image-20210627195409853"></p></li><li><p>配置从Redis服务器(不用配置主Redis服务器)</p><p>使用命令  <strong><code>slaveof &lt;ip&gt; &lt;port&gt;</code></strong></p><ul><li>在6380和6381服务器上分别执行:  slaveof 127.0.0.1 6379</li></ul></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923086.png" alt="image-20210627195843264"></p><ol start="10"><li>再次查看三台Redis服务器运行情况</li></ol><ul><li>主Redis服务器6379</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923087.png" alt="image-20210627200403441"></p><ul><li>从Redis服务器6380</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923088.png" alt="image-20210627200604552"></p><ul><li>从Redis服务器6381</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923089.png" alt="image-20210627200648173"></p><p><strong>至此，已搭建好一主二从的主从复制关系</strong></p><hr><p>在主Redis上写入一个数据</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923090.png" alt="image-20210627200909026"></p><p>可以在两个从Redis上查看到</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923091.png" alt="image-20210627200938538"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923092.png" alt="image-20210627200953305"></p><p>在从Redis上只能做读操作，而不能做写操作，不然会报错</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923093.png" alt="image-20210627201100275"></p><h3 id="常用3招">常用3招</h3><h4 id="一主两从的一些特点">一主两从的一些特点</h4><ol><li><p>当从服务器挂掉后，若再重启，则不再属于原来的从服务器，而是独立成单独的一个主服务器。</p></li><li><p>slave1、slave2是从头开始复制还是从切入点开始复制?比如从k4进来，那之前的k1,k2,k3是否也可以复制？</p><p>—— <strong>是从头开始复制</strong></p></li><li><p>从机是否可以写？set可否？</p><p>——<strong>不能写</strong></p></li><li><p>主机shutdown后情况如何？从机是上位还是原地待命？</p><p>——主服务器挂掉后，从服务器依旧显示为从服务器，即原地待命。若主服务器重新启动，则其依旧是主服务器</p></li></ol><h4 id="薪火相传">薪火相传</h4><p>上一个Slave可以是下一个slave的Master，Slave同样可以接收其他 slaves的连接和同步请求，那么该slave作为了链条中下一个的master, 可以有效减轻master的写压力,去中心化降低风险。</p><p>用 slaveof <ip> <port> 中途变更转向:会清除之前的数据，重新建立拷贝最新的</p><p>风险是一旦某个slave宕机，后面的slave都没法备份</p><p>主机挂了，从机还是从机，无法写数据了</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923094.png" alt="image-20210627205459110"></p><h4 id="反客为主">反客为主</h4><p>当一个master宕机后，后面的slave可以立刻升为master，其后面的slave不用做任何修改。</p><p>用  <strong>slaveof no one</strong>   将从机变为主机。</p><h3 id="主从复制原理">主从复制原理</h3><p>粗略的原理：</p><ol><li><p>从服务器连上主服务器后，向主服务器发送进行数据同步消息</p></li><li><p>主服务器接到从服务器发送过来的同步消息后，把主服务器数据进行持久化(放入rdb文件)，并把rdb文件发送给从服务器，从服务器拿到rdb进行读取</p></li><li><p>每次主服务器进行写操作之后，和从服务器进行数据同步</p></li></ol><p>详细的原理</p><ul><li><p>Slave启动成功连接到master后会发送一个sync命令</p></li><li><p>Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令， 在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步</p></li><li><p>全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。</p></li><li><p>增量复制：Master继续将新的所有收集到的修改命令依次传给slave,完成同步</p></li><li><p>但是只要是重新连接master,一次完全同步（全量复制)将被自动执行</p></li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923095.png" alt="image-20210627202617156"></p><h3 id="哨兵模式-sentinel">哨兵模式(sentinel)</h3><h4 id="哨兵模式是什么">哨兵模式是什么</h4><p><strong>反客为主的自动版</strong>，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库</p><h4 id="使用步骤">使用步骤</h4><ol><li><p>调整为一主两从模式，6379带着6380、6381</p></li><li><p>在自定义的/myredis目录下新建sentinel.conf文件，名字绝不能错</p></li><li><p>配置哨兵，在sentinel.conf中写入：</p><p>若mymaster中有密码，则需加入最后一行</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sentinel monitor mymaster 127.0.0.1 6379 1</span><br><span class="line">sentinel auth-pass mymaster 123456</span><br></pre></td></tr></table></figure><p>其中mymaster为监控对象起的服务器名称(自定义)， 1 为至少有多少个哨兵同意迁移的数量。</p></li><li><p>启动哨兵</p></li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis-sentinel  /myredis/sentinel.conf</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923096.png" alt="image-20210627212326521"></p><ol start="5"><li>当主机挂掉后，从机选举中产生新的主机</li></ol><p>(大概10秒左右可以看到哨兵窗口日志，切换了新的主机)</p><p>哪个从机会被选举为主机呢？**根据优先级别：slave-priority **</p><p>原主机重启后会变为从机。</p><p>当原主机挂掉后，哨兵会监控到：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923097.png" alt="image-20210627212621594"></p><h4 id="复制延时-缺陷">复制延时(缺陷)</h4><p>由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以<strong>从Master同步到Slave机器有一定的延迟</strong>，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。</p><h4 id="故障恢复">故障恢复</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923098.png" alt="image-20210627213848971"></p><p>优先级在redis.conf中默认：replica-priority 100，值越小优先级越高</p><p>偏移量是指获得原主机数据最全的</p><p>每个redis实例启动后都会随机生成一个40位的runid</p><h4 id="主从复制-Java">主从复制(Java)</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> JedisSentinelPool jedisSentinelPool=<span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span>  Jedis <span class="title function_">getJedisFromSentinel</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(jedisSentinelPool==<span class="literal">null</span>)&#123;</span><br><span class="line">        Set&lt;String&gt; sentinelSet=<span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line">        sentinelSet.add(<span class="string">&quot;192.168.11.103:26379&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">JedisPoolConfig</span> <span class="variable">jedisPoolConfig</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">JedisPoolConfig</span>();</span><br><span class="line">        jedisPoolConfig.setMaxTotal(<span class="number">10</span>); <span class="comment">//最大可用连接数</span></span><br><span class="line">        jedisPoolConfig.setMaxIdle(<span class="number">5</span>); <span class="comment">//最大闲置连接数</span></span><br><span class="line">        jedisPoolConfig.setMinIdle(<span class="number">5</span>); <span class="comment">//最小闲置连接数</span></span><br><span class="line">        jedisPoolConfig.setBlockWhenExhausted(<span class="literal">true</span>); <span class="comment">//连接耗尽是否等待</span></span><br><span class="line">        jedisPoolConfig.setMaxWaitMillis(<span class="number">2000</span>); <span class="comment">//等待时间</span></span><br><span class="line">        jedisPoolConfig.setTestOnBorrow(<span class="literal">true</span>); <span class="comment">//取连接的时候进行一下测试 ping pong</span></span><br><span class="line"></span><br><span class="line">        jedisSentinelPool=<span class="keyword">new</span> <span class="title class_">JedisSentinelPool</span>(<span class="string">&quot;mymaster&quot;</span>,sentinelSet,jedisPoolConfig);</span><br><span class="line">        <span class="keyword">return</span> jedisSentinelPool.getResource();</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> jedisSentinelPool.getResource();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Redis-集群">Redis 集群</h2><h3 id="Redis容易出现的问题">Redis容易出现的问题</h3><p>容量不够，redis如何进行扩容？</p><p>并发写操作， redis如何分摊？</p><p>另外，主从模式，薪火相传模式，主机宕机，导致ip地址发生变化，应用程序中配置需要修改对应的主机地址、端口等信息。</p><p>之前通过代理主机来解决，但是redis3.0中提供了解决方案。就是<strong>无中心化集群配置</strong>。</p><p><strong>无中心化集群</strong>： 任何一台服务器都能作为集群的入口</p><h3 id="什么是集群">什么是集群</h3><p><strong>Redis 集群实现了对Redis的水平扩容</strong>，即启动N个redis节点，将整个数据库分布存储在这N个节点中，每个节点存储总数据的1/N。</p><p>Redis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。</p><h3 id="模拟搭建集群">模拟搭建集群</h3><p>正常情况下，一台服务器中只有一个Redis，每个Redis都是占用服务器的6379端口。由于本人只有一台服务器，所以为了模拟搭建集群，会在这台服务器中开启多个Redis，占用多个端口。</p><p>制作步骤如下：</p><h4 id="制作六个实例，6379，6380，6381，6389，6390，6391">制作六个实例，6379，6380，6381，6389，6390，6391</h4><p>每个实例需要配置以下基本信息：</p><p>开启daemonize yes</p><p>Pid文件名字</p><p>指定端口</p><p>Log文件名字</p><p>Dump.rdb名字</p><p>Appendonly 关掉或者换名字</p><h4 id="Redis-cluster配置修改">Redis cluster配置修改</h4><p>为上述六个实例，创建六个配置文件分别为redis6379.conf、redis6380.conf、redis6381.conf、redis6389.conf、redis6390.conf、redis6391.conf。</p><p>并为配置文件添加如下信息(注，以6379为例，端口号自己改成对应的)：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923099.png" alt="image-20210628200617927"></p><p>cluster-enabled yes  打开集群模式</p><p>cluster-config-file nodes-6379.conf 设定节点配置文件名</p><p>cluster-node-timeout 15000  设定节点失联时间，超过该时间（毫秒），集群自动进行主从切换。</p><p><strong>注意：若Redis中有密码，还需要再配置文件中添加一行&quot;masterauth + 密码&quot;</strong>，比如  masterauth 123456</p><h4 id="启动6个redis服务">启动6个redis服务</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923100.png" alt="image-20210628202409666"></p><h4 id="将六个节点合成一个集群">将六个节点合成一个集群</h4><p>组合之前，请确保所有Redis实例启动后，nodes-xxxx.conf文件都生成正常</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923101.png" alt="image-20210628202601393"></p><ol><li>然后先进入Redis的安装目录中，本人的安装目录是/usr/local/redis6.2.4</li><li>然后进入安装目录的src目录下，找到redis-cli。(由于本人将redis-cli移动到了/usr/local/redis6.2.4/bin目录下，所以不进入src中，改为进入bin中)</li><li>使用以下命令(<strong>此处不要用127.0.0.1， 请用真实IP地址</strong>)：</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis-cli --cluster create --cluster-replicas 1 192.168.11.101:6379 192.168.11.101:6380 192.168.11.101:6381 192.168.11.101:6389 192.168.11.101:6390 192.168.11.101:6391</span><br></pre></td></tr></table></figure><p>–cluster-replicas 1 表示采用最简单的方式配置集群，一台主机，一台从机，正好三组。</p><p><strong>注意，此处本人写的是以下命令才成功</strong>，这里-a 123456是验证Redis的密码</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis-cli -a 123456 --cluster create --cluster-replicas 1 127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6389 127.0.0.1:6390 127.0.0.1:6391</span><br></pre></td></tr></table></figure><p>成功后，需要确认系统自动进行主从分配的状态</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923102.png" alt="image-20210628211903901"></p><p>yes后，配置成功</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923103.png" alt="image-20210628212013201"></p><p><strong>至此，完成集群搭建</strong></p><hr><h3 id="集群连接登录">集群连接登录</h3><p><strong>搭建集群前</strong>，连接redis，都是使用普通方式登录</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis-cli -p 6379</span><br></pre></td></tr></table></figure><p>而<strong>搭建集群后</strong>，需要使用如下命令连接(无密码情况)</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis-cli -c -p 6379</span><br></pre></td></tr></table></figure><p>若redis中都有密码，则使用以下命令：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis-cli -c -p 6379 -a 123456</span><br></pre></td></tr></table></figure><h3 id="通过cluster-nodes-命令查看集群信息">通过cluster nodes 命令查看集群信息</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923104.png" alt="image-20210628212830603"></p><p>也可以通过 cluster info  命令查看集群信息</p><h3 id="redis-cluster-如何分配这六个节点？">redis cluster 如何分配这六个节点？</h3><p>一个集群至少要有三个主节点。</p><p>选项 --cluster-replicas 1 表示我们希望为集群中的每个主节点创建一个从节点。</p><p>分配原则尽量保证每个主数据库运行在不同的IP地址，每个从库和主库不在一个IP地址上。</p><p>保证它们不在同一个IP地址，可以保证当一台主机挂掉时，其他的redis依旧可以使用。</p><h3 id="什么是slots">什么是slots</h3><p>之前，在成功搭建集群时，会出现一句消息&quot;All 16384 slots covered.&quot;</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923105.png" alt="image-20210629135934292"></p><p>slot  表示插槽</p><p>一个Redis集群包含16384个插槽(hash slot)，数据库中的每个键都属于这16384个插槽的其中一个。</p><p>集群使用公式 <strong>CRC16(key)  % 16384</strong>  来计算key属于哪个槽，其中CRC16(key)语句用于计算键key的CRC16校验和。</p><p>集群中的每个节点负责处理一部分插槽。 举个例子， 如果一个集群可以有主节点， 其中：</p><p>节点 A 负责处理 0 号至 5460 号插槽。</p><p>节点 B 负责处理 5461 号至 10922 号插槽。</p><p>节点 C 负责处理 10923 号至 16383 号插槽。</p><h3 id="在集群中录入值">在集群中录入值</h3><p>在redis-cli每次录入、查询键值，redis都会计算出该key应该送往的插槽，如果不是该客户端对应服务器的插槽，redis会报错，并告知应前往的redis实例地址和端口。</p><p>redis-cli客户端提供了  <strong>–c 参数实现自动重定向</strong>。</p><p>如 redis-cli -c –p 6379 登入后，再录入、查询键值对可以自动重定向。</p><p>例如，下面set一个值后，redis计算出k1应该送往的插槽为12706，告知应前往6381端口的redis实例，并自动切换到6381端口的redis实例(自动重定向)，并将键值存入其中。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923106.png" alt="image-20210629141715862"></p><p><strong>不在一个slot下的键值，是不能使用mget, mset等多键操作的</strong>。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923107.png" alt="image-20210629142242787"></p><p>若想进行多键操作，可以通过{}来定义组的概念，从而使key中{}内相同内容的键值对放到一个slot中去。<strong>注意，{}中的内容可以自定义</strong>，{}中是组名。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923108.png" alt="image-20210629142631116"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923109.png" alt="image-20210629142727967"></p><h3 id="计算一个key的插槽值">计算一个key的插槽值</h3><p>若想计算一个key的插槽值，可以使用以下命令：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cluster keyslot key</span><br></pre></td></tr></table></figure><p>如：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923110.png" alt="image-20210629142925706"></p><h3 id="计算某个插槽中有多少个值">计算某个插槽中有多少个值</h3><p>若要计算某个插槽slot里面存有多少个值，可以使用以下命令：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cluster countkeysinslot [插槽号]</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923111.png" alt="image-20210629143149584"></p><p><strong>注意：只能看到当前执行命令的Redis的插槽中有多少个值，无法看到其他redis的插槽</strong></p><h3 id="查询集群中的值">查询集群中的值</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cluster getkeysinslot  &lt;slot&gt; &lt;count&gt;</span><br></pre></td></tr></table></figure><p>返回count个slot插槽中的键</p><h3 id="故障恢复-2">故障恢复</h3><p>当主机挂掉后，从机可以自动升为主机</p><p>举例：</p><ol><li>将6379端口的Redis主机shutdown</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923112.png" alt="image-20210629150012248"></p><ol start="2"><li>登陆6380端口的Redis主机查看集群状态</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923113.png" alt="image-20210629150147528"></p><p>​可以看到6379主机挂掉后，6389的从机马上升为主机</p><p>​<strong>若6379的Redis重新启动后，会作为6389的Redis的从机</strong></p><p>如果<strong>某一段插槽的主从都挂掉</strong>，而cluster-require-full-coverage 为yes ，那么 ，整个集群都挂掉</p><p>如果某一段插槽的主从都挂掉，而cluster-require-full-coverage 为no ，那么，该插槽数据全都不能使用，也无法存储。</p><p>redis.conf中的参数 cluster-require-full-coverage</p><h3 id="集群的Jedis开发">集群的Jedis开发</h3><p>即使连接的不是主机，集群会自动切换主机存储。主机写，从机读。</p><p>无中心化主从集群。无论从哪台主机写的数据，其他主机上都能读到数据。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JedisClusterTest</span> &#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123; </span><br><span class="line">      </span><br><span class="line">     Set&lt;HostAndPort&gt;set =<span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;HostAndPort&gt;();</span><br><span class="line">     <span class="comment">// 这里添加集群的入口，可以写集群任意入口,也可以放入多个入口</span></span><br><span class="line">     set.add(<span class="keyword">new</span> <span class="title class_">HostAndPort</span>(<span class="string">&quot;192.168.31.211&quot;</span>,<span class="number">6379</span>));</span><br><span class="line">      </span><br><span class="line">     JedisCluster jedisCluster=<span class="keyword">new</span> <span class="title class_">JedisCluster</span>(set);</span><br><span class="line">     jedisCluster.set(<span class="string">&quot;k1&quot;</span>, <span class="string">&quot;v1&quot;</span>);</span><br><span class="line">     System.out.println(jedisCluster.get(<span class="string">&quot;k1&quot;</span>));</span><br><span class="line">     jedisCluster.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Redis集群的好处">Redis集群的好处</h3><ul><li>实现扩容</li><li>分摊压力</li><li>无中心配置相对简单</li></ul><h3 id="Redis集群的不足">Redis集群的不足</h3><ul><li>多键操作是不被支持的</li><li>多键的Redis事务是不被支持的。lua脚本不被支持</li><li>由于集群方案出现较晚，很多公司已经采用了其他的集群方案，而代理或者客户端分片的方案想要迁移至redis cluster，需要整体迁移而不是逐步过渡，复杂度较大。</li></ul><h2 id="Redis应用问题解决">Redis应用问题解决</h2><p>本章讲解Redis在使用过程中可能遇到的问题，以及其解决方法。</p><h3 id="缓存穿透">缓存穿透</h3><h4 id="问题描述">问题描述</h4><p><strong>缓存穿透</strong>是指<strong>缓存和数据库中都没有的数据</strong>，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。</p><p><strong>查询缓存中没有的数据，从而导致大量请求直接访问数据库，导致压力过大。</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923114.png" alt="image-20210629153938197"></p><p>缓存穿透有以下几个现象：</p><ul><li>应用服务器压力突然变大。</li><li>Redis命中率降低</li><li>缓存中查不到数据，就会一直查询数据库,导致数据库压力增大，容易造成数据库崩溃。</li></ul><h4 id="解决方案">解决方案</h4><p>（1）**对空值缓存：**如果一个查询返回的数据为空（不管是数据是否不存在），我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟</p><p>（2） <strong>设置可访问的名单（白名单）：</strong></p><p>使用bitmaps类型定义一个可以访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmap里面的id进行比较，如果访问id不在bitmaps里面，进行拦截，不允许访问。</p><p>（3）<strong>采用布隆过滤器</strong>：(布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量(位图)和一系列随机映射函数（哈希函数）。</p><p>底层是bitmaps</p><p>布隆过滤器可以用于检索一个元素是否在一个集合中。它的<strong>优点</strong>是空间效率和查询时间都远远超过一般的算法，<strong>缺点</strong>是有一定的误识别率和删除困难。)</p><p>将所有可能存在的数据哈希到一个足够大的bitmaps中，一个一定不存在的数据会被 这个bitmaps拦截掉，从而避免了对底层存储系统的查询压力。</p><p>（4）**进行实时监控：**当发现Redis的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务</p><h3 id="缓存击穿">缓存击穿</h3><h4 id="问题描述-2">问题描述</h4><p><strong>缓存击穿</strong>是指<strong>缓存中没有但数据库中有</strong>的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923115.png" alt="image-20210629161240448"></p><p>缓存击穿一般有几个现象：</p><ul><li>数据库访问压力瞬时增加</li><li>redis里面没有出现大量key过期</li><li>redis正常运行</li></ul><p>可能原因：</p><ul><li>redis某个key过期了，且正好有大量访问使用这个key</li></ul><h4 id="解决方案-2">解决方案</h4><p>（1）<strong>预先设置热门数据</strong>：在redis高峰访问之前，把一些热门数据提前存入到redis里面，加大这些热门数据key的时长</p><p>（2）<strong>实时调整</strong>：现场监控哪些数据热门，实时调整key的过期时长</p><p>（3）<strong>使用锁</strong>：</p><p>​（1）就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db。</p><p>​（2）先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX）去set一个mutex key</p><p>​（3）当操作返回成功时，再进行load db的操作，并回设缓存,最后删除mutex key；</p><p>​（4）当操作返回失败，证明有线程在load db，当前线程睡眠一段时间再重试整个get缓存的方法。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923117.png" alt="image-20210629164328492"></p><h3 id="缓存雪崩">缓存雪崩</h3><h4 id="问题描述-3">问题描述</h4><p><strong>缓存雪崩是指缓存中数据大批量到过期时间</strong>，而查询数据量巨大，引起数据库压力过大甚至down机。</p><p>和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p><p>缓存雪崩的可能出现的现象：</p><ul><li>数据库压力变大，造成服务器崩溃</li></ul><h4 id="解决方案-3">解决方案</h4><p>（1）**构建多级缓存架构：**nginx缓存 + redis缓存 +其他缓存（ehcache等）</p><p>（2）<strong>使用锁或队列：</strong></p><p>用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。<strong>不适用高并发情况</strong></p><p>（3）<strong>设置过期标志更新缓存：</strong></p><p>记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际key的缓存。</p><p>（4）<strong>将缓存失效时间分散开：</strong></p><p>比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。</p><h3 id="分布式锁">分布式锁</h3><h4 id="问题描述-4">问题描述</h4><p>随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使<strong>原单机部署情况下的并发控制锁策略失效</strong>，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是<strong>分布式锁要解决的问题</strong>！</p><p>分布式锁主流的实现方案：</p><ol><li><p>基于数据库实现分布式锁</p></li><li><p>基于缓存（Redis等）</p></li><li><p>基于Zookeeper</p></li></ol><p>每一种分布式锁解决方案都有各自的优缺点：</p><ol><li><p>性能：redis最高</p></li><li><p>可靠性：zookeeper最高</p></li></ol><p>这里，我们就基于redis实现分布式锁。</p><h4 id="解决方案：使用redis实现分布式锁">解决方案：使用redis实现分布式锁</h4><ol><li><p>使用<strong>setnx</strong>命令</p><p>可以<strong>通过setnx上锁</strong>，若要解锁则使用del删除即可。</p></li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">setnx  &lt;key&gt;  &lt;value&gt;</span><br><span class="line"></span><br><span class="line">del  &lt;key&gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923118.png" alt="image-20210629193718749"></p><p>若上锁后一直不解锁(比如忘记释放)，则可以<strong>通过设置过期时间来将其解锁</strong>：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">expire  &lt;key&gt;  &lt;second&gt;</span><br></pre></td></tr></table></figure><p>但可能存在问题，setnx命令和expire命令不是原子操作。比如上锁之后突然出现异常(如突然断电)，那么无法设置过期时间，导致一直未释放。</p><p>如何解决？可以通过以下命令解决</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set &lt;key&gt; &lt;value&gt; nx ex &lt;second&gt;</span><br></pre></td></tr></table></figure><p>其中，nx 效果等同 setnx；</p><p>​ex 效果等同expire</p><p>在Java中可以编写代码使用分布式锁</p><p>setIfAbsent(<key>, <value>): 设置锁</p><p>或  setIfAbsent(<key>, <value>, <time>, &lt;时间单位&gt;)，设置锁，且设置了失效时间</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;testLock&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testLock</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">//1获取锁，setne, 记住setIfAbsent()</span></span><br><span class="line">    <span class="type">Boolean</span> <span class="variable">lock</span> <span class="operator">=</span> redisTemplate.opsForValue().setIfAbsent(<span class="string">&quot;lock&quot;</span>, <span class="string">&quot;111&quot;</span>);</span><br><span class="line">    <span class="comment">//2获取锁成功、查询num的值</span></span><br><span class="line">    <span class="keyword">if</span>(lock)&#123;</span><br><span class="line">        <span class="type">Object</span> <span class="variable">value</span> <span class="operator">=</span> redisTemplate.opsForValue().get(<span class="string">&quot;num&quot;</span>);</span><br><span class="line">        <span class="comment">//2.1判断num为空return</span></span><br><span class="line">        <span class="keyword">if</span>(StringUtils.isEmpty(value))&#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//2.2有值就转成成int</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">num</span> <span class="operator">=</span> Integer.parseInt(value+<span class="string">&quot;&quot;</span>);</span><br><span class="line">        <span class="comment">//2.3把redis的num加1</span></span><br><span class="line">        redisTemplate.opsForValue().set(<span class="string">&quot;num&quot;</span>, ++num);</span><br><span class="line">        <span class="comment">//2.4释放锁，del</span></span><br><span class="line">        redisTemplate.delete(<span class="string">&quot;lock&quot;</span>);</span><br><span class="line"></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="comment">//3获取锁失败、每隔0.1秒再获取</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">100</span>);</span><br><span class="line">            testLock();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>目前还是存在问题：可能会释放其他服务器的锁。</strong></p><p>举例：</p><p>如果业务逻辑的执行时间是7s。执行流程如下</p><ol><li><p>index1业务逻辑没执行完，3秒后锁被自动释放。</p></li><li><p>index2获取到锁，执行业务逻辑，3秒后锁被自动释放。</p></li><li><p>index3获取到锁，执行业务逻辑</p></li><li><p>index1业务逻辑执行完成，开始调用del释放锁，这时释放的是index3的锁，导致index3的业务只执行1s就被别人释放。</p></li></ol><p>最终等于没锁的情况。</p><p><strong>解决</strong>：setnx获取锁时，<strong>设置一个指定的唯一值</strong>（例如：uuid）；释放前获取这个值，判断是否自己的锁</p><p>解决方案如下一小节。</p><h4 id="优化之UUID防误删">优化之UUID防误删</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923119.png" alt="image-20210630092117858"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923120.png" alt="image-20210630092124464"></p><p><strong>目前还是存在问题：删除操作缺乏原子性</strong>。</p><p>举例：</p><ol><li><p>index1执行删除时，查询到的lock值确实和uuid相等</p><p>uuid=v1</p><p>set(lock,uuid)；   <img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923121.png" alt="image-20210630095213757"></p></li><li><p>index1执行删除前，lock刚好过期时间已到，被redis自动释放</p><p>在redis中没有了lock，没有了锁。</p></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923122.png" alt="image-20210630095250900"></p><ol start="3"><li><p>index2获取了lock</p><p>​index2线程获取到了cpu的资源，开始执行方法</p><p>​uuid=v2</p><p>​set(lock,uuid)；</p></li><li><p>index1执行删除，此时会把index2的lock删除</p><p>​index1 因为已经在方法中了，所以不需要重新上锁。index1有执行的权限。index1已经比较完成了，这个时候，开始执行</p></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923123.png" alt="image-20210630095337728"></p><p>​删除的index2的锁！</p><p>解决方案见下一小节。</p><h4 id="优化之LUA脚本保证删除的原子性">优化之LUA脚本保证删除的原子性</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;testLockLua&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testLockLua</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//1 声明一个uuid ,将做为一个value 放入我们的key所对应的值中</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">uuid</span> <span class="operator">=</span> UUID.randomUUID().toString();</span><br><span class="line">    <span class="comment">//2 定义一个锁：lua 脚本可以使用同一把锁，来实现删除！</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">skuId</span> <span class="operator">=</span> <span class="string">&quot;25&quot;</span>; <span class="comment">// 访问skuId 为25号的商品 100008348542</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">locKey</span> <span class="operator">=</span> <span class="string">&quot;lock:&quot;</span> + skuId; <span class="comment">// 锁住的是每个商品的数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 获取锁</span></span><br><span class="line">    <span class="type">Boolean</span> <span class="variable">lock</span> <span class="operator">=</span> redisTemplate.opsForValue().setIfAbsent(locKey, uuid, <span class="number">3</span>, TimeUnit.SECONDS);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第一种： lock 与过期时间中间不写任何的代码。</span></span><br><span class="line">    <span class="comment">// redisTemplate.expire(&quot;lock&quot;,10, TimeUnit.SECONDS);//设置过期时间</span></span><br><span class="line">    <span class="comment">// 如果true</span></span><br><span class="line">    <span class="keyword">if</span> (lock) &#123;</span><br><span class="line">        <span class="comment">// 执行的业务逻辑开始</span></span><br><span class="line">        <span class="comment">// 获取缓存中的num 数据</span></span><br><span class="line">        <span class="type">Object</span> <span class="variable">value</span> <span class="operator">=</span> redisTemplate.opsForValue().get(<span class="string">&quot;num&quot;</span>);</span><br><span class="line">        <span class="comment">// 如果是空直接返回</span></span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isEmpty(value)) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 不是空 如果说在这出现了异常！ 那么delete 就删除失败！ 也就是说锁永远存在！</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">num</span> <span class="operator">=</span> Integer.parseInt(value + <span class="string">&quot;&quot;</span>);</span><br><span class="line">        <span class="comment">// 使num 每次+1 放入缓存</span></span><br><span class="line">        redisTemplate.opsForValue().set(<span class="string">&quot;num&quot;</span>, String.valueOf(++num));</span><br><span class="line">        <span class="comment">/*使用lua脚本来锁*/</span></span><br><span class="line">        <span class="comment">// 定义lua 脚本</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">script</span> <span class="operator">=</span> <span class="string">&quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;</span>;</span><br><span class="line">        <span class="comment">// 使用redis执行lua执行</span></span><br><span class="line">        DefaultRedisScript&lt;Long&gt; redisScript = <span class="keyword">new</span> <span class="title class_">DefaultRedisScript</span>&lt;&gt;();</span><br><span class="line">        redisScript.setScriptText(script);</span><br><span class="line">        <span class="comment">// 设置一下返回值类型 为Long</span></span><br><span class="line">        <span class="comment">// 因为删除判断的时候，返回的0,给其封装为数据类型。如果不封装那么默认返回String 类型，</span></span><br><span class="line">        <span class="comment">// 那么返回字符串与0 会有发生错误。</span></span><br><span class="line">        redisScript.setResultType(Long.class);</span><br><span class="line">        <span class="comment">// 第一个要是script 脚本 ，第二个需要判断的key，第三个就是key所对应的值。</span></span><br><span class="line">        redisTemplate.execute(redisScript, Arrays.asList(locKey), uuid);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 其他线程等待</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 睡眠</span></span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            <span class="comment">// 睡醒了之后，调用方法。</span></span><br><span class="line">            testLockLua();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Lua脚本详解：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923124.png" alt="image-20210630095955705"></p><h4 id="总结-2">总结</h4><p>1、加锁</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1. 从redis中获取锁,set k1 v1 px 20000 nx</span></span><br><span class="line"><span class="type">String</span> <span class="variable">uuid</span> <span class="operator">=</span> UUID.randomUUID().toString();</span><br><span class="line"><span class="type">Boolean</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="built_in">this</span>.redisTemplate.opsForValue()</span><br><span class="line">      .setIfAbsent(<span class="string">&quot;lock&quot;</span>, uuid, <span class="number">2</span>, TimeUnit.SECONDS);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2、使用lua释放锁</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 2. 释放锁 del</span></span><br><span class="line"><span class="type">String</span> <span class="variable">script</span> <span class="operator">=</span> <span class="string">&quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;</span>;</span><br><span class="line"><span class="comment">// 设置lua脚本返回的数据类型</span></span><br><span class="line">DefaultRedisScript&lt;Long&gt; redisScript = <span class="keyword">new</span> <span class="title class_">DefaultRedisScript</span>&lt;&gt;();</span><br><span class="line"><span class="comment">// 设置lua脚本返回类型为Long</span></span><br><span class="line">redisScript.setResultType(Long.class);</span><br><span class="line">redisScript.setScriptText(script);</span><br><span class="line">redisTemplate.execute(redisScript, Arrays.asList(<span class="string">&quot;lock&quot;</span>),uuid);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>3、重试</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Thread.sleep(<span class="number">500</span>);</span><br><span class="line">testLock();</span><br></pre></td></tr></table></figure><p>为了确保分布式锁可用，我们至少要确保锁的实现同时<strong>满足以下四个条件</strong>：</p><ul><li><p>互斥性。在任意时刻，只有一个客户端能持有锁。</p></li><li><p>不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。</p></li><li><p>解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。</p></li><li><p>加锁和解锁必须具有原子性。</p></li></ul><h2 id="Redis6-0-新功能">Redis6.0 新功能</h2><h3 id="ACL">ACL</h3><h4 id="简介-4">简介</h4><p>Redis ACL是Access Control List（访问控制列表）的缩写，该功能允许根据可以执行的命令和可以访问的键来限制某些连接。</p><p>在Redis 5版本之前，Redis 安全规则只有密码控制 还有通过rename 来调整高危命令比如 flushdb ， KEYS* ， shutdown 等。Redis 6 则提供ACL的功能对用户进行更细粒度的权限控制 ：</p><p>（1）接入权限:用户名和密码</p><p>（2）可以执行的命令</p><p>（3）可以操作的 KEY</p><p>参考官网：<a href="https://redis.io/topics/acl">https://redis.io/topics/acl</a></p><h4 id="命令-4">命令</h4><p>1、使用 acl list命令展现用户权限列表</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923125.png" alt="image-20210630103654399"></p><p>…省略了</p><h3 id="IO多线程">IO多线程</h3><h4 id="简介-5">简介</h4><p>Redis6终于支撑多线程了，告别单线程了吗？</p><p>IO多线程其实指<strong>客户端交互部分</strong>的<strong>网络IO</strong>交互处理模块<strong>多线程</strong>，而非<strong>执行命令多线程</strong>。Redis6执行命令依然是单线程。</p><h4 id="原理架构">原理架构</h4><p>Redis 6 加入多线程,但跟 Memcached 这种从 IO处理到数据访问多线程的实现模式有些差异。Redis 的多线程部分<strong>只是用来处理网络数据的读写和协议解析</strong>，执行命令仍然是单线程。之所以这么设计是不想因为多线程而变得复杂，需要去控制 key、lua、事务，LPUSH/LPOP 等等的并发问题。整体的设计大体如下:</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923126.png" alt="image-20210630131051413"></p><p>另外，多线程IO默认也是不开启的，需要在配置文件中配置</p><p>io-threads-do-reads yes</p><p>io-threads 4</p><h3 id="工具支持Cluster">工具支持Cluster</h3><p>之前老版Redis想要搭集群需要单独安装ruby环境，Redis 5 将 redis-trib.rb 的功能集成到 redis-cli 。另外官方 redis-benchmark 工具开始支持 cluster 模式了，通过多线程的方式对多个分片进行压测。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305031923127.png" alt="image-20210630132952224"></p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git常用命令</title>
      <link href="/2023/04/27/Git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2023/04/27/Git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<table><thead><tr><th>命令</th><th>作用</th></tr></thead><tbody><tr><td><code>git clone</code></td><td>工程克隆</td></tr><tr><td><code>git diff</code></td><td>查看工作区的修改内容</td></tr><tr><td><code>git status</code></td><td>查看工作区文件状态</td></tr><tr><td><code>git add</code>/<code>git rm</code>/<code>git mv</code></td><td>新增/删除/移动文件到暂存区</td></tr><tr><td><code>git commit</code></td><td>提交更改的文件</td></tr><tr><td><code>git push</code></td><td>推送到远端仓库</td></tr><tr><td><code>git log</code></td><td>查看当前分支上的提交日志</td></tr><tr><td><code>git branch</code></td><td>列出本地分支</td></tr><tr><td><code>git branch</code> / <code>git checkout -b</code></td><td>新建分支</td></tr><tr><td><code>git branch -d</code></td><td>删除分支</td></tr><tr><td><code>git checkout</code></td><td>切换分支</td></tr><tr><td><code>git pull</code></td><td>更新分支</td></tr><tr><td><code>git merge</code></td><td>合并分支</td></tr><tr><td><code>git reset</code></td><td>强制回退到历史节点</td></tr><tr><td><code>git checkout</code></td><td>回退本地所有修改而未提交的</td></tr><tr><td><code>git merge</code>/<code>git rebase</code></td><td>合并目标分支内容到当前分支</td></tr></tbody></table><p>推荐学习git的网站：<a href="https://learngitbranching.js.org/">https://learngitbranching.js.org/</a></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus+Grafana监控入门</title>
      <link href="/2023/04/25/Prometheus+Grafana/"/>
      <url>/2023/04/25/Prometheus+Grafana/</url>
      
        <content type="html"><![CDATA[<p>参考尚硅谷<a href="https://www.bilibili.com/video/BV1HT4y1Z7vR">B站视频</a></p><p>本次课程涉及的组件主要有：</p><ul><li>Prometheus：作为指标采集工具</li><li>Grafana：用于可视化收集的数据</li><li>睿象云：作为告警平台（不讲）</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030795.png" alt="image-20230425104104045"></p><h2 id="Prometheus介绍">Prometheus介绍</h2><p>Prometheus官网地址：<a href="https://prometheus.io/">https://prometheus.io/</a></p><h3 id="什么是Prometheus">什么是Prometheus</h3><blockquote><p>官网介绍如下：</p><p><a href="https://github.com/prometheus">Prometheus</a> is an open-source systems monitoring and alerting toolkit originally built at <a href="https://soundcloud.com/">SoundCloud</a>. Since its inception in 2012, many companies and organizations have adopted Prometheus, and the project has a very active developer and user <a href="https://prometheus.io/community">community</a>. It is now a standalone open source project and maintained independently of any company. To emphasize this, and to clarify the project’s governance structure, Prometheus joined the <a href="https://cncf.io/">Cloud Native Computing Foundation</a> in 2016 as the second hosted project, after <a href="http://kubernetes.io/">Kubernetes</a>.</p><p>Prometheus collects and stores its metrics as time series data, i.e. metrics information is stored with the timestamp at which it was recorded, alongside optional key-value pairs called labels.</p></blockquote><ul><li>Prometheus是一个开源的系统监控和告警工具包，于2012年开始研发，2015年发布早期版本</li><li>Prometheus是一个独立的开源项目，独立于任何公司进行维护。于2016年加入云原生计算基金会，成为继Kubernetes之后的第二个托管项目</li><li>Prometheus以时间序列数据的形式收集并存储指标，即指标信息与记录的时间戳一起存储，并可选key-value键值对作为标签。</li></ul><h3 id="特点">特点</h3><p>Prometheus是一个开源的完整监控解决方案，其对传统监控系统的测试和告警模型进行了彻底的颠覆，形成了基于<strong>中央化</strong>的规则计算、同意分析和告警的新模型。相比于传统监控系统，Prometheus具有以下优点：</p><h4 id="易于管理">易于管理</h4><ul><li>Prometheus核心部分只有一个单独的<strong>二进制文件</strong>，不存在任何的第三方依赖（数据库、缓存等）。唯一需要的就是本地磁盘，因此不会有潜在级联故障的风险。</li><li>Prometheus<strong>基于<code>pull</code>模型</strong>的架构方式，可以在任何地方（本地电脑、开发环境、测试环境）搭建我们的监控系统。</li><li>对于一些复杂的情况，还可以使用**Prometheus服务发现（Service Discovery）**的能力动态管理监控目标。</li></ul><h4 id="监控服务的内部运行状态">监控服务的内部运行状态</h4><p>Prometheus鼓励用户监控服务的内部状态，基于Prometheus丰富的Client库，用户可以轻松的在应用程序中添加对Prometheus的支持，从而让用户可以获取服务和应用内部真正的运行状态。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030796.png" alt="image-20230426094643955"></p><h4 id="强大的数据模型">强大的数据模型</h4><p>所有采集的监控数据均以指标（metric）的形式保存在**内置的时间序列数据库（TSDB）**中。所有的样本除了基本的指标名称以外，还包含一组用于描述该样本特征的标签。</p><p>标签样式如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">http_request_status&#123;</span><br><span class="line">    code=&#x27;200&#x27;,</span><br><span class="line">    content_path=&#x27;/api/path&#x27;,</span><br><span class="line">    environment=&#x27;produment&#x27;</span><br><span class="line">&#125; =&gt;</span><br><span class="line">[value1@timestamp1,value2@timestamp2...]</span><br><span class="line"></span><br><span class="line">http_request_status&#123; # 指标名称</span><br><span class="line">    code=&#x27;200&#x27;, # 维度的标签</span><br><span class="line">    content_path=&#x27;/api/path2&#x27;,</span><br><span class="line">    environment=&#x27;produment&#x27;</span><br><span class="line">&#125; =&gt;</span><br><span class="line">[value1@timestamp1,value2@timestamp2...] # 存储的样本值</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>每一条时间序列由指标名称（Metrics Name）以及一组标签（Labels）唯一标识。每条时间序列按照时间的先后顺序存储一系列的样本值。</p><ul><li><code>http_request_status</code>：指标名称（Metrics Name）</li><li><code>&#123;code='200',content_path='/api/path',environment='produment'&#125;</code>：表示维度的标签，基于这些Labels我们可以方便的对监控数据进行聚合，过滤，裁剪</li><li><code>[value1@timestamp1,value2@timestamp2...]</code>：按照时间的先后顺序，存储的样本值</li></ul><h4 id="强大的查询语言PromQL">强大的查询语言PromQL</h4><p>Prometheus内置了一个强大的<strong>数据查询语言PromQL</strong>。<strong>通过PromQL可以实现对监控数据的查询、聚合</strong>。同时PromQL也被应用于数据可视化(如Grafana)以及告警当中。</p><p>通过PromQL可以轻松回答类似于以下问题：</p><ul><li>在过去一段时间中95%应用延迟时间的分布范围？</li><li>预测在4小时后，磁盘空间占用大致会是什么情况？</li><li>CPU占用率前5位的服务有哪些？（过滤）</li></ul><h4 id="高效">高效</h4><p>对于监控系统而言，大量的监控任务必然导致有大量的数据产生。而Prometheus可以高效地处理这些数据，对于单一Prometheus Server实例而言它可以处理：</p><ul><li><strong>数以百万的监控指标</strong></li><li><strong>每秒处理数十万的数据点</strong></li></ul><h4 id="可扩展">可扩展</h4><p>可以在每个数据中心、每个团队运行独立的Prometheus Sevrer。<strong>Prometheus对于联邦集群的支持，可以让多个Prometheus实例产生一个逻辑集群</strong>，当单实例Prometheus Server处理的任务量过大时，<strong>通过使用功能分区（sharding）+联邦集群（federation）可以对其进行扩展</strong>。</p><h4 id="易于集成">易于集成</h4><ul><li><p>使用Prometheus可以快速搭建监控服务，并且<strong>可以非常方便地在应用程序中进行集成</strong>。目前支持：<code>Java</code>，<code>JMX</code>，<code>Python</code>，<code>Go</code>，<code>Ruby</code>，<code>.Net</code>，<code>Node.js</code> 等等语言的客户端SDK，基于这些SDK可以快速让应用程序纳入到Prometheus的监控当中，或者开发自己的监控数据收集程序。</p></li><li><p>同时<strong>这些客户端收集的监控数据，不仅仅支持Prometheus，还能支持Graphite这些其他的监控工具</strong>。</p></li><li><p>同时<strong>Prometheus还支持与其他的监控系统进行集成</strong>：Graphite,Statsd,Collected,Scollector,muini,Nagios等。<strong>Prometheus社区还提供了大量第三方实现的监控数据采集支持</strong>：JMX, CloudWatch, EC2, MySQL, PostgresSQL, Haskell, Bash, SNMP, Consul, Haproxy, Mesos, Bind, CouchDB, Django, Memcached, RabbitMQ, Redis, RethinkDB, Rsyslog 等等。</p></li></ul><h4 id="可视化">可视化</h4><ul><li>Prometheus Server中自带的Prometheus UI，可以方便地直接对数据进行查询，并且支持直接以图形化的形式展示数据。同时Prometheus还提供了一个独立的基于Ruby On Rails的Dashboard解决方案Promdash。</li><li>最新的Grafana可视化工具也已经提供了完整的Prometheus支持，基于Grafana可以创建更加精美的监控图标。</li><li>基于Prometheus提供的API 还可以实现自己的监控可视化UI。</li></ul><h4 id="开放性">开放性</h4><p>通常来说当我们需要监控一个应用程序时，一般需要该应用程序提供对相应监控系统协议的支持，因此应用程序会与所选择的监控系统进行绑定。为了减少这种绑定所带来的限制，对于决策者而言要么你就直接在应用中集成该监控系统的支持，要么就在外部创建单独的服务来适配不同的监控系统。</p><p>而对于Prometheus来说，<strong>使用Prometheus的client library的输出格式不止支持Prometheus的格式化数据，也可以输出支持其它监控系统的格式化数据</strong>，比如Graphite。因此你甚至可以在不使用Prometheus的情况下，采用Prometheus的client library来让你的应用程序支持监控数据采集。</p><h3 id="Prometheus架构">Prometheus架构</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030797.png" alt="image-20230426154733485"></p><h4 id="Prometheus生态圈组件">Prometheus生态圈组件</h4><ul><li><code>Prometheus Server</code>：主服务器，负责收集和存储时间序列数据</li><li><code>client libraies</code>：应用程序代码插桩，将监控指标嵌入到被监控应用程序中</li><li><code>Pushgateway</code>：推送网关，为支持short-lived作业提供一个推送网关</li><li><code>exporter</code>：专门为一些应用开发的数据摄取组件一exporter，例如：HAProxy、StatsD、Graphite等等。</li><li><code>Alertmanager</code>：专门用于处理alert的组件</li></ul><h4 id="架构理解">架构理解</h4><p>Prometheus既然设计为一个维度存储模型，可以把它理解为一个OLAP系统。</p><ol><li><strong>存储计算层</strong></li></ol><ul><li>Prometheus Server，里面包含了存储引擎和计算引擎。</li><li>Retrieval组件为取数组件，它会主动从Pushgateway或者Exporter拉取指标数据。</li><li>Service discovery，可以动态发现要监控的目标。</li><li>TSDB，数据核心存储与查询。</li><li>HTTP server，对外提供HTTP服务。</li></ul><ol start="2"><li><strong>采集层</strong></li></ol><p>采集层分为两类，一类是生命周期较短的作业，还有一类是生命周期较长的作业。</p><ul><li>短作业：直接通过API，在退出时将指标推送给Pushgateway</li><li>长作业：Retrieval组件直接从Job或者Exporter拉取数据。</li></ul><ol start="3"><li><strong>应用层</strong></li></ol><p>应用层主要分为两种，一种是AlertManager，另一种是数据可视化。</p><ul><li><p>AlertManager</p><p>Prometheus本身有一套告警系统，它对接Pagerduty，是一套付费的监控报警系统。可实现短信报警、5分钟无人ack打电话通知、仍然无人ack，通知值班人员Manager.…Emial，发送邮件…</p></li><li><p>数据可视化</p><ul><li>Prometheus build-in WebUl</li><li>Grafana</li><li>其他基于API开发的客户端</li></ul></li></ul><h2 id="Prometheus及其组件的安装">Prometheus及其组件的安装</h2><p>下载地址：<a href="https://prometheus.io/download/">https://prometheus.io/download/</a></p><p>在官网中提供了很多组件供下载：</p><ul><li>prometheus：核心主服务</li><li>alertmanager：告警系统</li><li>blackbox_exporter</li><li>consul_exporter</li><li>graphite_exporter</li><li>memcached_exporter</li><li>mysqld_exporter</li><li>node_exporter</li><li>promlens</li><li>pushgateway</li><li>statsd_exporter</li><li>以及一些第三方组件…</li></ul><hr/><p>在本文，主要下载并安装<code>prometheus</code>、<code>node_exporter</code>、<code>pushgateway</code>、<code>alertmanager</code></p><ul><li><a href="https://github.com/prometheus/prometheus/releases/download/v2.43.0/prometheus-2.43.0.linux-amd64.tar.gz">prometheus-2.43.0.linux-amd64.tar.gz</a></li><li><a href="https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz">node_exporter-1.5.0.linux-amd64.tar.gz</a></li><li><a href="https://github.com/prometheus/pushgateway/releases/download/v1.5.1/pushgateway-1.5.1.linux-amd64.tar.gz">pushgateway-1.5.1.linux-amd64.tar.gz</a></li><li><a href="https://github.com/prometheus/alertmanager/releases/download/v0.25.0/alertmanager-0.25.0.linux-amd64.tar.gz">alertmanager-0.25.0.linux-amd64.tar.gz</a></li></ul><hr/><p>安装环境：</p><table><thead><tr><th>虚拟机的hostname</th><th>IP地址</th></tr></thead><tbody><tr><td>centos_02</td><td>192.168.179.131</td></tr><tr><td>centos_03</td><td>192.168.179.132</td></tr><tr><td>centos_04</td><td>192.168.179.133</td></tr></tbody></table><p>其中：将prometheus主服务、pushgateway与alertmanager组件只安装于centos_02中。</p><h3 id="安装Prometheus">安装Prometheus</h3><p>Prometheus基于Golang编写，编译后的软件包，不依赖于任何的第三方依赖。只需要下载对应平台的二进制包，解压并且添加基本的配置即可正常启动Prometheus Server。</p><ol><li>在虚拟机的<code>/opt/software</code>目录中下载安装包</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/prometheus/prometheus/releases/download/v2.43.0/prometheus-2.43.0.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><ol start="2"><li>解压安装包，将其解压到<code>/opt/module</code>目录下；并修改目录名</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf prometheus-2.43.0.linux-amd64.tar.gz -C /opt/module</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/opt/module目录下，修改目录名</span></span><br><span class="line">mv prometheus-2.43.0.linux-amd64 prometheus-2.43.0</span><br></pre></td></tr></table></figure><ol start="3"><li>修改配置文件<code>prometheus.yml</code></li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 prometheus-2.43.0]# vim prometheus.yml</span><br></pre></td></tr></table></figure><p>默认配置如下：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030798.png" alt="image-20230426191631454"></p><p>​在该配置文件中的<code>scrape_configs</code>配置项下添加如下配置：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">A scrape configuration containing exactly one endpoint to scrape:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Here it<span class="string">&#x27;s Prometheus itself.</span></span></span><br><span class="line">scrape_configs:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash"><span class="string">The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.</span></span></span><br><span class="line">  - job_name: &quot;prometheus&quot;</span><br><span class="line"></span><br><span class="line">    # metrics_path defaults to &#x27;/metrics&#x27;</span><br><span class="line">    # scheme defaults to &#x27;http&#x27;.</span><br><span class="line"></span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&quot;centos_02:9090&quot;]</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash"><span class="string">添加 pushgateway 监控配置</span></span></span><br><span class="line">  - job_name: &quot;pushgateway&quot;</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#x27;centos_02:9091&#x27;]</span><br><span class="line">      labels:</span><br><span class="line">        instance: pushgateway</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash"><span class="string">添加 Node Exporter 监控配置</span></span></span><br><span class="line">  - job_name: &#x27;node exporter&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#x27;centos_02:9100&#x27;, &#x27;centos_03:9100&#x27;, &#x27;centos_04:9100&#x27;]</span><br></pre></td></tr></table></figure><p>配置说明：</p><ol><li><strong>global配置块</strong>：控制Prometheus服务器的全局配置<ul><li><code>scrape_interval</code>：配置拉取数据的时间间隔，默认为1分钟</li><li><code>evaluation_interval</code>：规则验证（生产alert）的时间间隔，默认1分钟</li></ul></li><li><strong>rule_files配置块</strong>：规则配置文件</li><li><strong>scrape_configs配置块</strong>：配置采集目标相关，prometheus监视的目标。Prometheus自身的运行信息可以通过HTTP访问，所以Prometheus可以监控自己的运行数据。<ul><li><code>job_name</code>：监控作业的名称</li><li><code>static_configs</code>：表示静态目标配置，就是固定从某个target拉取数据</li><li><code>targets</code>：指定监控的目标，即从哪拉取数据。Prometheus会从<code>http://centos_02:9090/metrics</code>上拉取数据。</li></ul></li></ol><p>Prometheus是<strong>可以在运行时自动加载配置</strong>的。启动时需要添加：<code>--web.enable-lifecycle</code></p><h3 id="安装pushgateway">安装pushgateway</h3><p>Prometheus在正常情况下是采用拉模式从产生metric的作业或者exporter(比如专门监控主机的NodeExporter)拉取监控数据。但是我们若要监控的是Flink on YARN作业，想要让Prometheus自动发现作业的提交、结束以及自动拉取数据显然是比较困难的。PushGateway就是一个中转组件，通过配置Flink on YARN作业将metric推到PushGateway，Prometheus再从PushGateway拉取就可以了。</p><hr/><ol><li>在虚拟机的<code>/opt/software</code>目录中下载安装包</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/prometheus/pushgateway/releases/download/v1.5.1/pushgateway-1.5.1.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><ol start="2"><li>解压安装包，将其解压到<code>/opt/module</code>目录下；并修改目录名</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf pushgateway-1.5.1.linux-amd64.tar.gz -C /opt/module/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/opt/module目录下，修改目录名</span></span><br><span class="line">mv pushgateway-1.5.1.linux-amd64 pushgateway-1.5.1</span><br></pre></td></tr></table></figure><h3 id="安装Alertmanager（选择性安装）">安装Alertmanager（选择性安装）</h3><ol><li>在虚拟机的<code>/opt/software</code>目录中下载安装包</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/prometheus/alertmanager/releases/download/v0.25.0/alertmanager-0.25.0.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><ol start="2"><li>解压安装包，将其解压到<code>/opt/module</code>目录下；并修改目录名</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf alertmanager-0.25.0.linux-amd64.tar.gz -C /opt/module</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/opt/module目录下，修改目录名</span></span><br><span class="line">mv alertmanager-0.25.0.linux-amd64 alertmanager-0.25.0</span><br></pre></td></tr></table></figure><p>默认配置文件<code>alertmanager.yml</code>如下：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">route:</span></span><br><span class="line">  <span class="attr">group_by:</span> [<span class="string">&#x27;alertname&#x27;</span>]</span><br><span class="line">  <span class="attr">group_wait:</span> <span class="string">30s</span></span><br><span class="line">  <span class="attr">group_interval:</span> <span class="string">5m</span></span><br><span class="line">  <span class="attr">repeat_interval:</span> <span class="string">1h</span></span><br><span class="line">  <span class="attr">receiver:</span> <span class="string">&#x27;web.hook&#x27;</span></span><br><span class="line"><span class="attr">receivers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&#x27;web.hook&#x27;</span></span><br><span class="line">    <span class="attr">webhook_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">url:</span> <span class="string">&#x27;http://127.0.0.1:5001/&#x27;</span></span><br><span class="line"><span class="attr">inhibit_rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_match:</span></span><br><span class="line">      <span class="attr">severity:</span> <span class="string">&#x27;critical&#x27;</span></span><br><span class="line">    <span class="attr">target_match:</span></span><br><span class="line">      <span class="attr">severity:</span> <span class="string">&#x27;warning&#x27;</span></span><br><span class="line">    <span class="attr">equal:</span> [<span class="string">&#x27;alertname&#x27;</span>, <span class="string">&#x27;dev&#x27;</span>, <span class="string">&#x27;instance&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="安装Node-Exporter（选择性安装）">安装Node Exporter（选择性安装）</h3><p>在Prometheus的架构设计中，Prometheus Server主要负责数据的收集，存储并且对外提供数据查询支持，而实际的监控样本数据的收集则是由Exporter完成。因此为了能够监控到某些东西，如主机的CPU使用率，我们需要使用到Exporter。Prometheus周期性的从Exporter暴露的HTTP服务地址(通常是/metrics)拉取监控样本数据。</p><p>Exporter可以是一个相对开放的概念，其可以是一个独立运行的程序独立于监控目标以外，也可以是直接内置在监控目标中。只要能够向Prometheus提供标准格式的监控样本数据即可。</p><p><strong>为了能够采集到主机的运行指标如CPU,内存，磁盘等信息。我们可以使用Node Exporter</strong>。Node Exporter同样采用Golang编写，并且不存在任何的第三方依赖，只需要下载，解压即可运行。</p><hr/><ol><li>在虚拟机的<code>/opt/software</code>目录中下载安装包</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><ol start="2"><li>解压安装包，将其解压到<code>/opt/module</code>目录下；并修改目录名</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf node_exporter-1.5.0.linux-amd64.tar.gz -C /opt/module</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/opt/module目录下，修改目录名</span></span><br><span class="line">mv node_exporter-1.5.0.linux-amd64 node_exporter-1.5.0</span><br></pre></td></tr></table></figure><ol start="3"><li>启动并通过页面查看是否成功</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动node_exporter</span></span><br><span class="line">./node_exporter</span><br></pre></td></tr></table></figure><p>​在浏览器中输入：<code>http://192.168.179.131:9100/metrics</code>，可以看到当前 node exporter 获得到的centos_02上的所有监控数据。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030799.png" alt="image-20230426202453789"></p><h3 id="监控多节点">监控多节点</h3><p>根据上述安装步骤，将<code>node_exporter</code>安装到centos_02、centos_03、centos_04中</p><p>后台运行node_exporter的命令：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 node_exporter-1.5.0]# nohup ./node_exporter --web.listen-address=:9100 &amp;</span><br></pre></td></tr></table></figure><p>其中9100为端口号，也可以自定义。</p><hr/><p>若要用prometheus拉取监控的数据，则在prometheus.yml中需配置对应的目标。之前在安装Prometheus时已经配置过了，如下：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030800.png" alt="image-20230426204534822"></p><hr/><h3 id="设置node-exporter为开机自启">设置node_exporter为开机自启</h3><p>网上应该有多种方法。这里只写一种。</p><ol><li><strong>创建service文件</strong></li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先创建文件</span></span><br><span class="line">sudo vim /usr/lib/systemd/system/node_exporter.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">写入以下内容</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=node_export</span><br><span class="line">Documentation=https://github.com/prometheus/node_exporter</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/opt/module/node_exporter-1.5.0/node_exporter --web.listen-address=0.0.0.0:9100</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="2"><li>设置为开机自启动。（注：当前目录需在与<code>node_exporter.service</code>同级目录下）</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 system]# systemctl enable node_exporter.service</span><br></pre></td></tr></table></figure><p>通过上述设置，可以将node_exporter设置为一个服务，通过以下命令可以进行服务管理：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动</span></span><br><span class="line">systemctl start node_exporter.service</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">停止</span></span><br><span class="line">systemctl stop node_exporter.service</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启</span></span><br><span class="line">systemctl restart node_exporter.service</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看服务状态</span></span><br><span class="line">systemctl status node_exporter.service</span><br></pre></td></tr></table></figure><h3 id="启动Prometheus-Server、Pushgateway和Alertmanager">启动Prometheus Server、Pushgateway和Alertmanager</h3><h4 id="启动Prometheus-Server">启动Prometheus Server</h4><ol><li><strong>启动Prometheus</strong></li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/module/prometheus-2.43.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动</span></span><br><span class="line">nohup ./prometheus --config.file=prometheus.yml &gt; ./prometheus.log 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看是否启动</span></span><br><span class="line">ps -ef | grep prometheus</span><br></pre></td></tr></table></figure><p>启动成功：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030801.png" alt="image-20230427101533663"></p><p>也可以在浏览器中输入<code>http://192.168.179.131:9090/</code>，打开界面：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030802.png" alt="image-20230427105819321"></p><p>进入如下界面：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030803.png" alt="image-20230427110457572"></p><blockquote><p>若node exporter显示down状态，</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030804.png" alt="image-20230427110530764"></p><p>则可以在浏览器所在的电脑上找到<code>hosts</code>文件，<strong>将对应虚拟机的IP地址和hostname做好映射</strong>，如下：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030805.png" alt="image-20230427110725839"></p></blockquote><h4 id="启动pushgateway">启动pushgateway</h4><p>在centos_02中：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/module/pushgateway-1.5.1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动</span></span><br><span class="line">nohup ./pushgateway --web.listen-address :9091 &gt; ./pushgateway.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>再次从浏览器中输入<code>http://centos_02:9090/</code>去查看Prometheus的targets界面：</p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030806.png" alt="image-20230427135931492" style="zoom:67%;" /><h4 id="启动alertmanager">启动alertmanager</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/module/alertmanager-0.25.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动</span></span><br><span class="line">nohup ./alertmanager --config.file=alertmanager.yml &gt; ./alertmanager.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h3 id="时间不同步导致的问题">时间不同步导致的问题</h3><p>若浏览器所在系统的时间与prometheus服务器的时间 <strong>不同步</strong>，则访问<code>http://centos_02:9090/</code>时会出现如下警告：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030808.png" alt="image-20230427152544217"></p><p><strong>解决方法</strong>：</p><ol><li>在服务器中执行如下命令：</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ntpdate ntp.aliyun.com</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030809.png" alt="image-20230427152651449"></p><p>就能查到数据了。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030810.png" alt="image-20230427152729649"></p><p>若此处警告消失，但还是无法显示数据，则在prometheus服务器中做如下步骤：</p><ol start="0"><li><p>可以先查询<code>prometheus.log</code>，看看里面哪里报错。</p></li><li><p>kill掉prometheus服务</p></li><li><p>删除<code>prometheus</code>安装目录下的<code>data</code>文件夹</p></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030811.png" alt="image-20230427152849561"></p><ol start="3"><li>重新启动prometheus</li></ol><h2 id="PromQL介绍">PromQL介绍</h2><p>Prometheus通过指标名称(metrics name)以及对应的一组标签(labelset)唯一定义一条时间序列。指标名称反映了监控样本的基本标识，而label则在这个基本特征上为采集到的数据提供了多种特征维度。用户可以基于这些特征维度<strong>过滤，聚合，统计</strong>从而产生新的计算后的一条时间序列。<strong>PromQL是Prometheus内置的数据查询语言</strong>，其提供对时间序列数据丰富的查询，聚合以及逻辑运算能力的支持。并且被广泛应用在Prometheus的日常应用当中，包括对数据查询、可视化、告警处理当中。可以这么说，PromQL是Prometheus所有应用场景的基础，理解和掌握PromQL是Prometheus入门的第一课。</p><h3 id="基本用法">基本用法</h3><p>基于上述对prometheus及其组件的安装，本文通过使用prometheus，来简单使用PromQL，不做过多讲解。</p><h4 id="查询时间序列">查询时间序列</h4><p>当Prometheus通过Exporter采集到相应的监控指标样本数据后，我们就可以通过PromQL对监控样本数据进行查询。</p><p>当我们直接使用监控指标名称查询时，可以<strong>查询该指标下的所有时间序列</strong>。如：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prometheus_http_requests_total</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">等同于以下命令</span></span><br><span class="line">prometheus_http_requests_total&#123;&#125;</span><br></pre></td></tr></table></figure><p>该表达式会返回指标名称为<code>prometheus_http_requests_total</code>的所有时间序列：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;code=&quot;200&quot;, handler=&quot;/-/ready&quot;, instance=&quot;centos_02:9090&quot;, job=&quot;prometheus&quot;&#125;</span><br><span class="line"></span><br><span class="line">prometheus_http_requests_total&#123;code=&quot;200&quot;, handler=&quot;/api/v1/label/:name/values&quot;, instance=&quot;centos_02:9090&quot;, job=&quot;prometheus&quot;&#125;</span><br><span class="line"></span><br><span class="line">prometheus_http_requests_total&#123;code=&quot;200&quot;, handler=&quot;/api/v1/metadata&quot;, instance=&quot;centos_02:9090&quot;, job=&quot;prometheus&quot;&#125;</span><br></pre></td></tr></table></figure><p>上述指标是将所有和prometheus http相关的请求都统计出来，统计请求次数</p><p>查询界面如下：</p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030812.png" alt="image-20230427160807392" style="zoom: 67%;" /><p>PromQL还<strong>支持用户根据时间序列的标签匹配模式来对时间序列进行过滤</strong>，目前主要支持两种匹配模式：<strong>完全匹配</strong>和<strong>正则匹配</strong>。</p><ul><li><strong>PromQL支持使用<code>=</code>和<code>!=</code>两种完全匹配模式</strong>：<ul><li>通过使用<code>label=value</code>可以选择那些标签满足表达式定义的时间序列；</li><li>反之使用<code>label!=value</code>则可以根据标签匹配排除时间序列；</li></ul></li></ul><p>例如，如果我们只需要查询所有<code>prometheus_http requests_total</code>时间序列中满足标签<code>instance</code>为<code>localhost::9090</code>的时间序列，则可以使用如下表达式：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;instance=&quot;localhost:9090&quot;&#125;</span><br></pre></td></tr></table></figure><p>反之，使用<code>instance!=&quot;localhost:9090&quot;</code>则可以排除这些时i间序列：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;instance!=&quot;localhost:9090&quot;&#125;</span><br></pre></td></tr></table></figure><ul><li>PromQL还可以支持使用正则表达式作为匹配条件，多个表达式之间使用<code>|</code>进行分离：<ul><li>使用<code>label=~regx</code>表示选择那些标签符合正则表达式定义的时间序列；</li><li>反之，使用<code>label!~regx</code>进行排除；</li></ul></li></ul><p>例如，如果想查询多个环境下的时间序列序列可以使用如下表达式：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;environment=~&quot;staging|testing|development&quot;,method!=&quot;GET&quot;&#125;</span><br></pre></td></tr></table></figure><p>排除用法：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;environment!~&quot;staging|testing|development&quot;,method!=&quot;GET&quot;&#125;</span><br></pre></td></tr></table></figure><h4 id="范围查询">范围查询</h4><p>直接通过类似于PromQL表达式<code>prometheus_http_requests_total</code>查询时间序列时，<strong>返回值中只会包含该时间序列中的最新的一个样本值</strong>，这样的返回结果我们称之为<strong>瞬时向量</strong>。而相应的这样的表达式称之为<strong>瞬时向量表达式</strong>。</p><p>而如果我们<strong>想过去一段时间范围内的样本数据</strong>时，我们则需要使用<strong>区间向量表达式</strong>。<strong>区间向量表达式和瞬时向量表达式之间的差异在于在区间向量表达式中我们需要定义时间选择的范围，时间范围通过时间范围选择器进行定义</strong>。</p><p>例如，通过以下表达式可以选择最近5分钟内的所有样本数据：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;&#125;[5m]</span><br></pre></td></tr></table></figure><p>该表达式将会返回查询到的时间序列中最近5分钟的所有样本数据：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prometheus_http_requests_total&#123;code=&quot;200&quot;, handler=&quot;/metrics&quot;, instance=&quot;centos_02:9090&quot;, job=&quot;prometheus&quot;&#125;=[</span><br><span class="line">231 @1682583567.916</span><br><span class="line">232 @1682583582.929</span><br><span class="line">233 @1682583597.916</span><br><span class="line">234 @1682583612.916</span><br><span class="line">235 @1682583627.923</span><br><span class="line">]</span><br></pre></td></tr></table></figure><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030813.png" alt="image-20230427162217915" style="zoom:50%;" /><p>通过区间向量表达式查询到的结果我们称为<strong>区间向量</strong>。</p><p>除了使用表示分钟以外，PromQL的时间范围选择器支持其它时间单位：</p><ul><li><code>s</code>：秒</li><li><code>m</code>：分钟</li><li><code>h</code>：小时</li><li><code>d</code>：天</li><li><code>w</code>：周</li><li><code>y</code>：年</li></ul><h4 id="时间位移操作">时间位移操作</h4><p><strong>在瞬时向量表达式或者区间向量表达式中，都是以当前时间为基准</strong>：</p><ul><li><code>prometheus_http_requests total&#123;&#125;</code>：瞬时向量表达式，选择当前最新的数据</li><li><code>prometheus_http_requests total&#123;&#125;[5m]</code>：区间向量表达式，选择以当前时间为基准，5分钟内的数据</li></ul><p>而如果我们想查询，5分钟前的瞬时样本数据，或昨天一天的区间内的样本数据呢？这个时候我们就可以使用位移操作，<strong>位移操作的关键字为<code>offset</code></strong>。可以使用<code>offset</code>时间位移操作：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询5分钟前的瞬时向量</span></span><br><span class="line">prometheus_http_requests_total&#123;&#125; offset 5m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询昨天一天的区间向量</span></span><br><span class="line">prometheus_http_requests_total&#123;&#125;[1d] offset 1d</span><br></pre></td></tr></table></figure><h4 id="使用聚合操作">使用聚合操作</h4><p>一般来说，如果描述样本特征的标签（label）在并非唯一的情况下，通过PromQL查询数据，会返回多条满足这些特征维度的时间序列。而<strong>PromQL提供的聚合操作可以用来对这些时间序列进行处理，形成一条新的时间序列</strong>：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询所有http请求的总数量</span></span><br><span class="line">sum(prometheus_http_requests_total)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">按照mode计算主机CPU的平均使用时间</span></span><br><span class="line">avg(node_cpu_seconds_total) by (mode)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">按照主机查询各个主机的CPU使用率</span></span><br><span class="line">sum(sum(irate(node_cpu_seconds_total&#123;mode!=&#x27;idle&#x27;&#125;[5m])) / sum(irate(node_cpu_seconds_total[5m]))) by (instance)</span><br></pre></td></tr></table></figure><h4 id="标量和字符串">标量和字符串</h4><p>除了使用瞬时向量表达式和区间向量表达式以外，PromQL还直接支持用户使用标量（Scalar）和字符串（String）。</p><ul><li><strong>标量(Scalar)：一个浮点型的数字值</strong></li></ul><p>标量只有一个数字，没有时序。例如：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">10</span><br></pre></td></tr></table></figure><p>需要注意的是，当使用表达式<code>count(prometheus_http_requests_total)</code>，返回的数据类型，依然是瞬时向量。用户可以通过内置函数<code>scalar()</code>将单个瞬时向量转换为标量。</p><ul><li><strong>字符串（String）：一个简单的字符串值</strong></li></ul><p>直接使用字符串，作为PromQL表达式，则会直接返回字符串。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&quot;this is a string&quot;</span><br><span class="line">&#x27;these are unescaped: \n \\ \t&#x27;</span><br><span class="line">`these are not unescaped: \n &#x27; &quot; \t`</span><br></pre></td></tr></table></figure><p>从中可以看出，字符串中可以使用转义字符<code>\</code></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030814.png" alt="image-20230427170818280"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030815.png" alt="image-20230427170754215"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030816.png" alt="image-20230427170840030"></p><h4 id="合法的PromQL表达式">合法的PromQL表达式</h4><p>所有的PromQL表达式都<strong>必须至少包含一个指标名称</strong>（例如<code>http_request_total</code>），或者一个<strong>不会匹配到空字符串</strong>的标签过滤器（例如<code>&#123;code=&quot;200&quot;&#125;</code>）。</p><p>因此以下两种方式，均为合法的表达式：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prometheus_http_requests_total# 合法</span><br><span class="line">prometheus_http_requests_total&#123;&#125;# 合法</span><br><span class="line">&#123;method=&quot;get&quot;&#125;# 合法</span><br></pre></td></tr></table></figure><p>而如下表达式，则不合法：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;job=~&quot;.*&quot;&#125;# 不合法</span><br></pre></td></tr></table></figure><p>同时，除了使用<code>&#123;label=value&#125;</code>的形式以外，我们还可以使用内置的<code>__name__</code>标签来指定监控指标名称：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;__name__=~&quot;prometheus_http_requests_total&quot;&#125;# 合法</span><br><span class="line">&#123;__name__=~&quot;node_disk_written_bytes_total|node_disk_read_bytes_total&quot;&#125;# 合法</span><br></pre></td></tr></table></figure><h3 id="PromQL操作符">PromQL操作符</h3><p>使用PromQL除了能够方便的按照查询和过滤时间序列以外，PromQL<strong>还支持丰富的操作符</strong>，用户可以使用这些操作符对进一步的对事件序列进行二次加工。这些操作符包括：<strong>数学运算符</strong>，<strong>逻辑运算符</strong>，<strong>布尔运算符</strong>等等。</p><h4 id="数学运算">数学运算</h4><ul><li><code>+</code>：加法</li><li><code>-</code>：减法</li><li><code>*</code>：乘法</li><li><code>/</code>：除法</li><li><code>%</code>：求余</li><li><code>^</code>：幂运算</li></ul><h4 id="布尔运算">布尔运算</h4><ul><li><p>Prometheus支持以下布尔运算如下：</p><ul><li><code>==</code>：相等</li><li><code>!-</code>：不相等</li><li><code>&gt;</code>：大于</li><li><code>&lt;</code>：小于</li><li><code>&gt;=</code>：大于等于</li><li><code>&lt;=</code>：小于等于</li></ul></li><li><p>使用bool修饰符改变布尔运算符的行为</p></li></ul><p><strong>布尔运算符的默认行为是对时序数据进行过滤</strong>。而<strong>在其它的情况下我们可能需要的是真正的布尔结果</strong>。例如，只需要知道当前模块的HTTP请求量是否&gt;=1000，如果大于等于1000则返回1(true)否则返回0(false)。这时可以使用bool修饰符改变布尔运算的默认行为。</p><p>例如：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prometheus_http_requests_total &gt; bool 1000</span><br></pre></td></tr></table></figure><p>使用bool修改符后，布尔运算不会对时间序列进行过滤，而是直接依次瞬时向量中的各个样本数据与标量的比较结果0或者1。从而形成一条新的时间序列。</p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030817.png" alt="image-20230427194249002" style="zoom:80%;" /><p>同时需要注意的是，如果是在两个标量之间使用布尔运算，则必须使用bool修饰符：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">2 == bool 2# 结果为1</span><br></pre></td></tr></table></figure><h4 id="使用集合运算符">使用集合运算符</h4><p>使用瞬时向量表达式能够获取到一个包含多个时间序列的集合，我们称为<strong>瞬时向量</strong>。通过集合运算，<strong>可以在两个瞬时向量与瞬时向量之间进行相应的集合操作</strong>。</p><p>目前，Prometheus支持以下集合运算符：</p><ul><li><code>and</code>：并且</li><li><code>or</code>：或者</li><li><code>unless</code>：排除</li></ul><p>vector1 and vector2：会产生一个由vector1的元素组成的新的向量。<strong>该向量包含vector1中完全匹配vector2中的元素组成</strong>。（相当于 与门）</p><p>vector1 or vector2：会产生一个新的向量，<strong>该向量包含vector1中所有的样本数据以及vector2中没有与vector1匹配到的样本数据</strong>。（相当于 或门）</p><p>vector1 unless vector2：会产生一个新的向量，新向量中的元素由vector1中没有与vector2匹配的元素组成。</p><h4 id="操作符优先级">操作符优先级</h4><p>对于复杂类型的表达式，需要了解运算操作的运行优先级。例如，查询主机的CPU使用率，可以使用表达式：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">100 * (1 - avg(irate(node_cpu_seconds_total&#123;mode=&#x27;idle&#x27;&#125;[5m])) by(job))</span><br></pre></td></tr></table></figure><p>其中**<code>irate</code>是PromQL中的内置函数，用于计算区间向量中时间序列每秒的即时增长率**。</p><p>在PromQL操作符中优先级由高到低依次为：</p><ul><li><code>^</code></li><li><code>*</code>，<code>/</code>，<code>%</code></li><li><code>+</code>，<code>-</code></li><li><code>==</code>，<code>!=</code>，<code>&lt;=</code>，<code>=</code>，<code>&gt;</code>，…</li><li><code>and</code>，<code>unless</code></li><li><code>or</code></li></ul><h4 id="PromQL聚合操作">PromQL聚合操作</h4><p>Prometheus还提供了下列内置的<strong>聚合操作符</strong>，这些操作符作用域瞬时向量。<strong>可以将瞬时表达式返回的样本数据进行聚合，形成一个新的时间序列</strong>。</p><ul><li><code>sum</code>：求和</li><li><code>min</code>：最小值</li><li><code>max</code>：最大值</li><li><code>avg</code>：平均值</li><li><code>stddev</code>：标准差</li><li><code>stdvar</code>：标准差异</li><li><code>count</code>：计数</li><li><code>count_values</code>：对value进行计数</li><li><code>bottomk</code>：后n条时序</li><li><code>topk</code>：前n条时序</li><li><code>quantile</code>：分布统计</li></ul><p>使用聚合操作的语法如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;aggr-op&gt;([parameter,] &lt;vector expression&gt;) [without|by (&lt;label list&gt;)]</span><br></pre></td></tr></table></figure><p>其中只有<code>count_values</code>，<code>quantile</code>，<code>topk</code>，<code>bottomk</code>支持参数（parameter）。</p><p>without用于从计算结果中移除列举的标签，而保留其它标签。</p><p>by则正好相反，结果向量中只保留列出的标签，其余标签则移除。通过without和by可以按照样本的问题对数据进行聚合。</p><p>例如：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sum(prometheus_http_requests_total) without (instance)</span><br></pre></td></tr></table></figure><p>等价于</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sum(prometheus_http_requests_total) by (code,handler,job,method)</span><br></pre></td></tr></table></figure><p>如果只需要计算整个应用的HTTP请求总量，可以直接使用表达式：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sum(prometheus_http_requests_total)</span><br></pre></td></tr></table></figure><p><code>count_values</code>用于时间序列中每一个样本值出现的次数。<code>count_values</code>会为每一个唯一的样本值输出一个时间序列，并且每一个时间序列包含一个额外的标签。</p><p>例如：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">count_values(&quot;count&quot;, prometheus_http_requests_total)</span><br></pre></td></tr></table></figure><p><code>topk</code>和<code>bottomk</code>则用于对样本值进行排序，返回当前样本值前n位，或者后n位的时间序列。</p><p>获取HTTP请求数前5位的时序样本数据，可以使用表达式：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">topk(5, prometheus_http_requests_total)</span><br></pre></td></tr></table></figure><p><code>quantile</code>用于计算当前样本数据值的分布情况<code>quantile(p, express))</code>，其中0≤p≤1。</p><p>例如，当p为0.5时，即表示找到当前样本数据中的中位数：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">quantile(0.5, prometheus_http_requests_total)</span><br></pre></td></tr></table></figure><h2 id="Prometheus-和-Grafana-集成">Prometheus 和 Grafana 集成</h2><p>grafana是一款采用Go语言编写的开源应用，主要用于大规模指标数据的可视化展现，是网络架构和应用分析中最流行的时序数据展示工具，目前已经支持绝大部分常用的时序数据库。</p><p>grafana官网：<a href="https://grafana.com/">https://grafana.com/</a></p><p>grafana下载地址：<a href="https://grafana.com/grafana/download?pg=get&amp;plcmt=selfmanaged-box1-cta1">https://grafana.com/grafana/download?pg=get&amp;plcmt=selfmanaged-box1-cta1</a></p><h3 id="下载安装Grafana">下载安装Grafana</h3><ol><li>下载Grafana</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 software]# wget https://dl.grafana.com/enterprise/release/grafana-enterprise-9.5.1.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><ol start="2"><li>解压到指定目录</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 software]# tar -zxvf grafana-enterprise-9.5.1.linux-amd64.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure><h3 id="启动Grafana">启动Grafana</h3><ol><li>后台启动Grafana</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/module/grafana-9.5.1</span><br><span class="line"></span><br><span class="line">nohup ./bin/grafana-server web &gt; ./grafana.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><ol start="2"><li>检查是否启动成功</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ps -ef | grep grafana</span><br></pre></td></tr></table></figure><ol start="3"><li>打开浏览器，访问<code>http://centos_02:3000/</code>。默认用户和密码为：<code>admin</code></li></ol><p>展示页面如下：</p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030818.png" alt="image-20230502161137192" style="zoom: 80%;" /><h3 id="添加数据源-Prometheus">添加数据源 Prometheus</h3><ol><li>点击<code>Your connections</code>按钮</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030819.png" alt="image-20230502161450170"></p><ol start="2"><li>点击添加数据源</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030820.png" alt="image-20230502161529669"></p><ol start="3"><li>选择 Prometheus</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030821.png" alt="image-20230502161623622"></p><ol start="4"><li>配置Prometheus Server地址</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030822.png" alt="image-20230502161807017"></p><p>并点击下方的 Save&amp;test</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030823.png" alt="image-20230502161845617"></p><p>若出现以下界面，则说明已成功获取数据源。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030824.png" alt="image-20230502161933365"></p><blockquote><p>注：在获取数据源之前，要保证数据源在正常工作。</p></blockquote><h3 id="手动创建仪表盘Dashboard">手动创建仪表盘Dashboard</h3><ol><li>点击<code>Dashboard</code></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030825.png" alt="image-20230502162302600"></p><ol start="2"><li>创建Dashboard</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030826.png" alt="image-20230502162355790"></p><ol start="3"><li>点击添加</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030827.png" alt="image-20230502162501755"></p><ol start="4"><li>查询具体某个指标的配置如下：</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030828.png" alt="image-20230502162923146"></p><blockquote><p>注：也可以导入其他人的仪表盘，直接使用别人的模板</p></blockquote><h3 id="Grafana官方的Dashboard模板">Grafana官方的Dashboard模板</h3><p>官方模板：<a href="https://grafana.com/grafana/dashboards/?plcmt=footer">https://grafana.com/grafana/dashboards/?plcmt=footer</a></p><p>界面如下：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030829.png" alt="image-20230502182751067"></p><p>点击某个具体的模板，从中可以看到，可以通过ID或者下载其JSON文件来获得这个Dashboard!</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030830.png" alt="image-20230502183145611"></p><hr/><p>导入模板演示：</p><ol><li>浏览器访问<code>http://centos_02:3000/dashboards</code>，进入Grafana服务器的Dashboards中。点击Import按钮</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030831.png" alt="image-20230502183537471"></p><ol start="2"><li>主要有两种导入方式，如下：</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030832.png" alt="image-20230502183615607"></p><ol start="3"><li>此处选择直接导入Grafana官网推荐的模板的ID</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030833.png" alt="image-20230502183711459"></p><ol start="4"><li>选择模板需要的数据源</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030834.png" alt="image-20230502183739373"></p><ol start="5"><li>导入成功后可以看到相应的dashboard</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030835.png" alt="image-20230502183815669"></p>]]></content>
      
      
      <categories>
          
          <category> 监控域 </category>
          
          <category> Prometheus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
            <tag> Grafana </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>office软件</title>
      <link href="/2023/04/19/office%E8%BD%AF%E4%BB%B6/"/>
      <url>/2023/04/19/office%E8%BD%AF%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<p>如何安装并激活Office？</p><p>推荐使用<a href="https://otp.landian.vip/zh-cn/">Office Tool Plus</a>，它是一个强大且实用的Office部署工具。</p><p>教程可以参考：</p><ul><li><a href="https://www.coolhub.top/archives/42">https://www.coolhub.top/archives/42</a></li><li><a href="https://www.coolhub.top/archives/11">https://www.coolhub.top/archives/11</a></li><li><a href="https://www.coolhub.top/archives/14">https://www.coolhub.top/archives/14</a></li></ul><p>通过参考教程，使用Office Tool Plus，即可使用Office三件套（Word、Excel、PPT）以及Visio等办公与画图软件。</p><p>强烈推荐！</p>]]></content>
      
      
      <categories>
          
          <category> 软件推荐 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件推荐 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka集成SpringBoot</title>
      <link href="/2023/04/07/Kafka%E9%9B%86%E6%88%90SpringBoot/"/>
      <url>/2023/04/07/Kafka%E9%9B%86%E6%88%90SpringBoot/</url>
      
        <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在本文，我们将使用SpringBoot与Kafka构建一个简单的生产者与消费者。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030209.png" alt="image-20230423095250261"></p><p>使用的环境如下：</p><ul><li><p>IDEA</p></li><li><p>SpringBoot</p></li><li><p>Kafka集群</p></li><li><p>三台虚拟机</p><table><thead><tr><th>hostname</th><th>IP</th></tr></thead><tbody><tr><td>centos_02</td><td>192.168.179.131</td></tr><tr><td>centos_03</td><td>192.168.179.132</td></tr><tr><td>centos_04</td><td>192.168.179.133</td></tr></tbody></table></li></ul><h2 id="IDEA搭建项目">IDEA搭建项目</h2><ol><li>利用Spring初始化器创建一个项目</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202305022030210.png" alt="image-20230423100538916"></p><ol start="2"><li>pom.xml中依赖的版本信息</li></ol><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">relativePath</span>/&gt;</span> <span class="comment">&lt;!-- lookup parent from repository --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">optional</span>&gt;</span>true<span class="tag">&lt;/<span class="name">optional</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="生产者代码">生产者代码</h2><ol><li>配置文件 <code>application.properties</code>，添加生产者相关信息</li></ol><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 连接kafka集群</span></span><br><span class="line"><span class="attr">spring.kafka.bootstrap-servers</span>=<span class="string">192.168.179.131:9092,192.168.179.132:9092</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># key与val的序列化</span></span><br><span class="line"><span class="attr">spring.kafka.producer.key-serializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="attr">spring.kafka.producer.value-serializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="2"><li>生产者代码</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.springboot.springkafka.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.KafkaTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMethod;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> hugh</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span> 2023-04-23 16:27</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProducerController</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    KafkaTemplate&lt;String, String&gt; kafka;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping(method = RequestMethod.GET, value = &quot;/send&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">data</span><span class="params">(String msg)</span> &#123;</span><br><span class="line">        <span class="comment">// 通过kafka发送数据</span></span><br><span class="line">        kafka.send(<span class="string">&quot;first&quot;</span>, msg);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;ok&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>写生产者代码主要注意使用：</p><ul><li><code>KafkaTemplate</code>类</li><li><code>kafka.send()</code>方法</li></ul></blockquote><h2 id="消费者代码">消费者代码</h2><ol><li>配置文件<code>application.properties</code></li></ol><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 连接kafka集群</span></span><br><span class="line"><span class="attr">spring.kafka.bootstrap-servers</span>=<span class="string">192.168.179.131:9092,192.168.179.132:9092</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># key与value的反序列化器</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.key-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.value-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 指定消费组的group_id</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.group-id</span>=<span class="string">hugh</span></span><br></pre></td></tr></table></figure><ol start="2"><li>消费者代码</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaConsumer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &quot;first&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">consumerTopic</span><span class="params">(String msg)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;收到的信息是: &quot;</span> + msg);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>写消费者代码时主要注意使用：</p><ul><li><code>@KafkaListener</code>注解，将其放在方法上，并指定主题，即可监听并接受指定主题的消息。</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
          <category> SpringBoot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka-Kraft模式</title>
      <link href="/2023/04/05/Kafka-Kraft%E6%A8%A1%E5%BC%8F/"/>
      <url>/2023/04/05/Kafka-Kraft%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>目前，Kafka在使用的过程当中，会出现一些问题。由于重度依赖Zookeeper集群，当Zookeeper集群性能发生抖动时，Kafka的性能也会收到很大的影响。因此，在Kafka发展的过程当中，为了解决这个问题，提供Kraft模式，来取消Kafka对Zookeeper的依赖。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304071056976.png" alt="Kafka官网对Kraft的介绍"></p><p>从上述可以看出：在KRaft模式中，可以通过设置<code>process.roles</code>属性来将<code>Kafka</code>服务器配置为<code>controller</code>或<code>broker</code>，或者二者都是。</p><h2 id="Kafka-Kraft架构">Kafka-Kraft架构</h2><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304071101067.png" alt="image-20230407110050561"></p><ul><li>左图为Kafka现有架构，元数据在zookeeper中，运行时动态选举controller，由controller进行Kaka集群管理。</li><li>右图为kraft模式架构，不再依赖zookeeper集群，而是用三台controller节点代替zookeeper，元数据保存在controller中，由controller直接进行Kafka集群管理。</li></ul><p>使用Kafka-Kraft模式的好处有以下几个：</p><ul><li>Kafka不再依赖外部框架，而是能够独立运行</li><li>controller管理集群时，不再需要从zookeeper中先读取数据，集群性能上升</li><li>由于不依赖zookeeper，集群扩展时不再受到zookeeper读写能力限制</li><li>controller不再动态选举，而是由配置文件规定。这样我们可以有针对性的加强controller节点的配置，而不是像以前一样对随机controller节点的高负载束手无策。</li></ul><h2 id="Kafka-Kraft集群部署">Kafka-Kraft集群部署</h2><p>0）集群规划</p><table><thead><tr><th>centos_02(192.168.179.131)</th><th>centos_03(192.168.179.132)</th><th>centos_04(192.168.179.133)</th></tr></thead><tbody><tr><td>kafka</td><td>kafka</td><td>kafka</td></tr></tbody></table><p>hostname也改成centos_02、centos_03、centos_04。</p><p>hosts也加上对应的映射配置。</p><p>1）在Linux上下载kafka</p><p>官方下载地址：<a href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a></p><p>2）解压kafka安装包</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 ~]# tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/</span><br></pre></td></tr></table></figure><p>3）重命名为kafka_kraft</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 module]# mv kafka_2.12-3.0.0/ kafka_kraft</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>4）在centos_02上修改配置文件<code>/opt/module/kafka_kraft/config/kraft/server.properties</code></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kraft]# vim server.properties</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The role of this server. Setting this puts us <span class="keyword">in</span> KRaft mode</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Kafka的角色(controller是用于代替zookeeper 管理kafka集群)一个kafka服务器既可以只充当controller或broker，也可以两个角色都当</span></span><br><span class="line">process.roles=broker,controller</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The node <span class="built_in">id</span> associated with this instance<span class="string">&#x27;s roles</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">节点 ID. 本文设置centos_02的node.id=2, centos_03的node.id=3, ...</span></span></span><br><span class="line">node.id=2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">The connect string for the controller quorum</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">所有的controller列表, 本文设置三个kafka服务器都充当两个角色</span></span></span><br><span class="line">controller.quorum.voters=2@centos_02:9093,3@centos_03:9093,4@centos_04:9093</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">broker对外暴露的地址</span></span></span><br><span class="line">advertised.listeners=PLAINTEXT://192.168.179.131:9092</span><br><span class="line"></span><br><span class="line">log.dirs=/opt/module/kafka_kraft/data</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>5）在centos_03、centos_04上按照上述配置修改自己的配置文件</p><p>和centos_02配置文件的主要区别如下：</p><ul><li><code>node.id</code>做出相应修改，保证唯一。且值和<code>controller.quorum.voters</code>中的值对应</li><li><code>advertised.listeners</code>做出相应修改</li></ul><p>6）初始化集群数据目录</p><blockquote><p>注：kraft模式下的kafka集群不能直接启动，需要先经过初始化。</p></blockquote><p>（1）首先生成存储目录唯一ID</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka_kraft]# bin/kafka-storage.sh random-uuid</span><br><span class="line"></span><br><span class="line">RRLygJl6RLWgvklGabUwlg</span><br></pre></td></tr></table></figure><p>（2）用该ID格式化kafka存储目录（三个节点都用相同的ID）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka_kraft]# bin/kafka-storage.sh format -t RRLygJl6RLWgvklGabUwlg -c /opt/module/kafka_kraft/config/kraft/server.properties</span><br><span class="line"></span><br><span class="line">Formatting /opt/module/kafka_kraft/data</span><br></pre></td></tr></table></figure><p>其余节点也执行上述命令即可：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_03 kafka_kraft]# bin/kafka-storage.sh format -t RRLygJl6RLWgvklGabUwlg -c /opt/module/kafka_kraft/config/kraft/server.properties</span><br><span class="line"></span><br><span class="line">[root@centos_04 kafka_kraft]# bin/kafka-storage.sh format -t RRLygJl6RLWgvklGabUwlg -c /opt/module/kafka_kraft/config/kraft/server.properties</span><br></pre></td></tr></table></figure><p>7）启动kafka集群</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka_kraft]# bin/kafka-server-start.sh -daemon config/kraft/server.properties</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>8）创建一个topic，验证是否能正常读写数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个主题first</span></span><br><span class="line">[root@centos_02 kafka_kraft]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --create --topic first --partitions 3 --replication-factor 3</span><br><span class="line"></span><br><span class="line">Created topic first.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看主题</span></span><br><span class="line">[root@centos_02 kafka_kraft]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --describe --topic first</span><br><span class="line"></span><br><span class="line">Topic: first    TopicId: ZRJ2n8ZaRG-1RsCQkjs_lg PartitionCount: 3       ReplicationFactor: 3    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: first    Partition: 0    Leader: 3       Replicas: 3,4,2 Isr: 3,4,2</span><br><span class="line">        Topic: first    Partition: 1    Leader: 4       Replicas: 4,2,3 Isr: 4,2,3</span><br><span class="line">        Topic: first    Partition: 2    Leader: 2       Replicas: 2,3,4 Isr: 2,3,4</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建生产者</span></span><br><span class="line">[root@centos_04 kafka_kraft]# bin/kafka-console-producer.sh --bootstrap-server centos_02:9092 --topic first</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建消费者</span></span><br><span class="line">[root@centos_03 kafka_kraft]# bin/kafka-console-consumer.sh --bootstrap-server centos_02:9092 --topic first</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>9）停止kafka集群</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka-Kraft </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka基础——入门</title>
      <link href="/2023/04/03/Kafka%E5%9F%BA%E7%A1%80/"/>
      <url>/2023/04/03/Kafka%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<p>全文参考<a href="https://www.bilibili.com/video/BV1vr4y1677k">尚硅谷视频</a></p><h2 id="Kafka-概述">Kafka 概述</h2><h3 id="定义">定义</h3><p><strong>Kafka 传统定义</strong>：Kafka是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。</p><p><strong>发布/订阅</strong>：消息的发布者不会将消息直接发送给特定的订阅者，而是将发布的消息分为不同的类别，订阅者只接收感兴趣的消息。</p><p><strong>Kafka 最新定义</strong>： Kafka 是一个开源的<strong>分布式事件流平台</strong>（ Event Streaming Platform），被数千家公司用于高性能数据管道、流分析、数据集成和关键任务应用。</p><h3 id="消息队列">消息队列</h3><p>目前企业中比较常见的消息队列产品主要有Kafka 、ActiveMQ、RabbitMQ、RocketMQ 等。</p><p><strong>在大数据场景主要采用Kafka 作为消息队列</strong>。在JavaEE 开发中主要采用ActiveMQ、RabbitMQ、RocketMQ。</p><h4 id="传统消息队列的应用场景">传统消息队列的应用场景</h4><p>传统的消息队列的主要应用场景包括：<strong>缓存/消峰、解耦和异步通信</strong>。</p><ul><li>缓冲/消峰：有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941394.png" alt="image-20221004102155950"></p><ul><li>解耦：允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941395.png" alt="image-20221004102209535"></p><ul><li>异步通信：允许用户把一个消息放入队列，但并不立即处理它，然后在需要的时候再去处理它们。</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941396.png" alt="image-20221004102232959"></p><h4 id="消息队列的两种模式">消息队列的两种模式</h4><ul><li>点对点模式<ul><li>消费者主动拉取数据，消息收到后清除消息</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941397.png" alt="image-20221004102414472"></p><ul><li>发布/订阅模式<ul><li>可以有多个topic主题（浏览、点赞、收藏、评论等）</li><li>消费者消费数据之后，不删除数据</li><li>每个消费者相互独立，都可以消费到数据</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941398.png" alt="image-20221004102437824"></p><h3 id="Kafka-基础架构">Kafka 基础架构</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941399.png" alt="image-20221004102705430"></p><ul><li>Producer：消息生产者，就是向Kafka broker 发消息的客户端。</li><li>Consumer：消息消费者，向Kafka broker 取消息的客户端。</li><li>Consumer Group（CG）：消费者组，由多个consumer 组成。<strong>同一个消费者组内的每个消费者负责消费不同分区的数据，一个分区只能由同一个组内的一个消费者消费；消费者组之间互不影响</strong>。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li><li>Broker：一台Kafka 服务器就是一个broker。一个集群由多个broker 组成。一个broker 可以容纳多个topic。</li><li>Topic：可以理解为一个队列，生产者和消费者面向的都是一个topic。</li><li>Partition：为了实现扩展性，一个非常大的topic 可以分布到多个broker（即服务器）上，一个topic 可以分为多个partition，<strong>每个partition 是一个有序的队列</strong>。正常来说，一个分区只对应一个Broker</li><li>Replica：副本。一个topic 的<strong>每个分区都有若干个副本</strong>，一个Leader 和若干个Follower。</li><li>Leader：每个分区多个副本的“主”，<strong>生产者发送数据的对象，以及消费者消费数据的对象都是Leader</strong>。</li><li>Follower：每个分区多个副本中的“从”，实时从Leader 中同步数据，保持和Leader 数据的同步。Leader 发生故障时，某个Follower 会成为新的Leader。</li></ul><blockquote><ul><li>在 同一个消费者组内，一个 Partition  只能被 一个消费者消费</li><li>在 同一个消费者组内，所有消费者  组合起来必定可以消费一个 Topic 下的所有 Partition</li><li>在 同一个消费组内，一个消费者 可以消费多个 Partition 的信息</li><li>在 不同消费者组内，同一个分区 可以被 多个消费者消费</li><li><strong>每个消费者组一定会完整消费一个 Topic 下的所有 Partition</strong></li><li>topic是逻辑的概念，partition是物理的概念</li><li>Kafka 的消费模式和发送模式都是以 Partition 为分界；对于一个 Topic 的并发量限制在于有多少个 Partition, 就能支撑多少的并发；</li></ul></blockquote><h2 id="Kafka-快速入门">Kafka 快速入门</h2><h3 id="安装部署">安装部署</h3><h4 id="集群规划">集群规划</h4><table><thead><tr><th>centos_02(192.168.179.131)</th><th>centos_03(192.168.179.132)</th><th>centos_04(192.168.179.133)</th></tr></thead><tbody><tr><td>zk</td><td>zk</td><td>zk</td></tr><tr><td>kafka</td><td>kafka</td><td>kafka</td></tr></tbody></table><h4 id="集群部署">集群部署</h4><blockquote><p>注：<strong>搭建Kafka集群时，需要先搭建zookeeper集群</strong></p><p>可以参考别人的教程：</p><p><a href="https://blog.csdn.net/gubeichengxuyuan/article/details/125064114">https://blog.csdn.net/gubeichengxuyuan/article/details/125064114</a></p></blockquote><ol><li>官方下载地址：<a href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a></li></ol><p>下载<a href="https://archive.apache.org/dist/kafka/3.0.0/kafka_2.12-3.0.0.tgz">kafka_2.12-3.0.0.tgz</a></p><ol start="2"><li>解压安装包</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/</span><br></pre></td></tr></table></figure><ol start="3"><li>在<code>/opt/module/</code>目录下修改解压后的文件名</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv kafka_2.12-3.0.0/ kafka</span><br></pre></td></tr></table></figure><ol start="4"><li>进入<code>/opt/module/kafka</code>目录，修改配置文件</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd config/</span><br><span class="line">vim server.properties</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section"># broker的全局唯一编号，不能重复，只能是数字</span></span><br><span class="line">broker.id=0</span><br><span class="line"><span class="section"># 处理网络请求的线程数量</span></span><br><span class="line">num.network.threads=3</span><br><span class="line"><span class="section"># 用来处理磁盘IO的线程数量</span></span><br><span class="line">num.io.threads=8</span><br><span class="line"><span class="section"># 发送套接字的缓冲区大小</span></span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line"><span class="section"># 接收套接字的缓冲区大小</span></span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line"><span class="section"># 请求套接字的缓冲区大小</span></span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line"><span class="section"># Kafka运行日志（数据）存放的路径，路径不需要提前创建，Kafka自动帮你创建，可以配置多个磁盘路径，路径与路径之间可以用&quot;, &quot;分隔</span></span><br><span class="line">log.dirs=/tmp/kafka-logs</span><br><span class="line"><span class="section"># topic在当前broker上的分区个数</span></span><br><span class="line">num.partitions=1</span><br><span class="line"><span class="section"># 用来恢复和清理data下数据的线程数量</span></span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line"><span class="section"># 每个topic创建时的副本数，默认是1个副本</span></span><br><span class="line">offsets.topic.replication.factor=1</span><br><span class="line"><span class="section"># segment 文件保留的最长时间，超时将被删除</span></span><br><span class="line">log.retention.hours=168</span><br><span class="line"><span class="section"># 每个segment文件的大小，默认最大1G</span></span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line"><span class="section"># 检查过期数据的时间，默认5分钟检查一次是否数据过期</span></span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"><span class="section"># 配置连接zookeeper集群地址（在zk根目录下创建/kafka,方便管理）</span></span><br><span class="line">zookeeper.connect=localhost:2181</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>修改以下内容：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">broker的全局唯一编号，不能重复，只能是数字</span></span><br><span class="line">broker.id=0</span><br><span class="line"></span><br><span class="line">log.dirs=/opt/module/kafka/datas</span><br><span class="line"></span><br><span class="line">zookeeper.connect=centos_02:2181,centos_03:2181,centos_04:2181/kafka</span><br></pre></td></tr></table></figure><blockquote><p>注：如果启动kafka遇到问题，可以尝试将hostname改成IP地址</p></blockquote><ol start="5"><li>三台虚拟机都按照上述配置文件修改对应的文件</li></ol><blockquote><p>注：<a href="http://broker.id">broker.id</a> 不得重复，整个集群中唯一：</p></blockquote><ol start="6"><li>配置环境变量</li></ol><p>6.1 在<code>/etc/profile.d/my_env.sh</code> 文件中增加kafka环境变量配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure><p>6.2 增加内容如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">KAFKA_HOME</span></span><br><span class="line">export KAFKA_HOME=/opt/module/kafka</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br></pre></td></tr></table></figure><p>6.3 刷新以下环境变量</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><ol start="7"><li>启动集群</li></ol><p>7.1 必须先启动zookeeper集群</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost kafka]# zookeeper-server-start.sh -daemon config/zookeeper.properties</span><br></pre></td></tr></table></figure><p>检查zookeeper是否启动成功</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ps -ef | grep zookeeper</span><br></pre></td></tr></table></figure><p>7.2 依次在三台虚拟机节点上启动Kafka</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br></pre></td></tr></table></figure><p>检查kafka是否启动成功</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure><h4 id="利用脚本管理kafka的启动和停止">利用脚本管理kafka的启动和停止</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">    for i in centos_02 centos_03 centos_04</span><br><span class="line">    do</span><br><span class="line">        echo &quot;---- start $i kafka ----&quot;</span><br><span class="line">        ssh $i &quot;/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties&quot;</span><br><span class="line">    done</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">    for i in centos_02 centos_03 centos_04</span><br><span class="line">    do</span><br><span class="line">        echo &quot;---- stop $i kafka ----&quot;</span><br><span class="line">        ssh $i &quot;/opt/module/kafka/bin/kafka-server-stop.sh&quot;</span><br><span class="line">    done</span><br><span class="line"></span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><h3 id="Kafka-命令行操作">Kafka 命令行操作</h3><h4 id="主题命令行操作">主题命令行操作</h4><ol><li>查看操作主题命令参数</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941400.png" alt="image-20221004155723600"></p><ol start="2"><li>查看当前服务器中的所有topic</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server 192.168.179.131:9092 --list</span><br></pre></td></tr></table></figure><ol start="3"><li>创建 first topic</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server 192.168.179.131:9092 --create --partitions 1 --replication-factor 3 --topic first</span><br></pre></td></tr></table></figure><p>选项说明：</p><ul><li>–topic：定义 topic 名</li><li>–replication-factor：定义副本数</li><li>–partitions：定义分区数</li></ul><ol start="4"><li>查看 first 主题的详情</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server 192.168.179.131:9092 --topic first --describe</span><br></pre></td></tr></table></figure><ol start="5"><li>修改分区数（注意：分区数只能增加，不能减少）</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server 192.168.179.131:9092 --alter --topic first --partitions 3</span><br></pre></td></tr></table></figure><ol start="6"><li>删除 topic</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server 192.168.179.131:9092 --topic first --delete</span><br></pre></td></tr></table></figure><h4 id="生产者命令行操作">生产者命令行操作</h4><ol><li>查看操作生产者命令参数</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-console-producer.sh</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941401.png" alt="image-20221004170935402"></p><ol start="2"><li>发送消息</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --bootstrap-server 192.168.179.131:9092 --topic first</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">hello world</span></span><br></pre></td></tr></table></figure><h4 id="消费者命令行操作">消费者命令行操作</h4><ol><li>查看操作消费者命令参数</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941402.png" alt="image-20221004171320180"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941403.png" alt="image-20221004171332188"></p><ol start="2"><li>消费消息</li></ol><p>2.1 消费 first 主题中的数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server 192.168.179.131:9092 --topic first</span><br></pre></td></tr></table></figure><h2 id="Kafka-生产者">Kafka 生产者</h2><h3 id="生产者消息发送流程">生产者消息发送流程</h3><h4 id="发送原理">发送原理</h4><p>在消息发送的过程中，涉及到了<strong>两个线程——main 线程和Sender 线程</strong>。在main 线程中创建了<strong>一个双端队列RecordAccumulator</strong>。main 线程将消息发送给RecordAccumulator，Sender 线程不断从RecordAccumulator 中拉取消息发送到Kafka Broker。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941404.png" alt="image-20221004200520496"></p><h4 id="生产者重要参数列表">生产者重要参数列表</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941405.png" alt="image-20221004201223154"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941406.png" alt="image-20221004201238016"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941407.png" alt="image-20221004201257108"></p><h3 id="异步发送-API">异步发送 API</h3><h4 id="普通异步发送">普通异步发送</h4><ol><li>需求：创建Kafka生产者，采用异步的方式发送到Kafka Broker</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941408.png" alt="image-20221006101544168"></p><ol start="2"><li>代码编写</li></ol><p>1）创建工程Kafka</p><p>2）导入依赖</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>3）创建包名：<code>com.atguigu.kafka.producer</code></p><p>4）编写不带回调函数的API代码</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 连接集群</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092，192.168.179.132:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 指定对应的 key 和 value （必须序列化）key.serializer value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建Kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 发送数据</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;atguigu&quot;</span> + i));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试：</p><p>1）在centos_03上开启kafka消费者</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost kafka]# bin/kafka-console-consumer.sh --bootstrap-server 192.168.179.131:9092 --topic first</span><br></pre></td></tr></table></figure><p>2）执行上述生产者的代码，观察消费者是否接收到消息</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941409.png" alt="image-20221006132757082"></p><h4 id="带回调函数的异步发送">带回调函数的异步发送</h4><p>回调函数会在 producer 收到 ack 时调用，为异步调用，该方法有两个参数，粉笔是元数据信息（RecordMetadata）和异常信息（Exception），如果 Exception 为 null, 说明消息发送成功，如果 Exception 不为 null，说明消息发送失败。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941410.png" alt="image-20221006133347796"></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerCallback</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 连接集群</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092，192.168.179.132:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 指定对应的 key 和 value （必须序列化）key.serializer value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建Kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 发送数据</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;atguigu&quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="literal">null</span>) &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;主题: &quot;</span> + metadata.topic() + <span class="string">&quot;, 分区: &quot;</span> + metadata.partition());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="同步发送API">同步发送API</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941411.png" alt="image-20221006133658777"></p><p><strong>只需在异步发送的基础上，在调用一下get()方法即可。</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerSync</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, ExecutionException &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 连接集群</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092，192.168.179.132:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 指定对应的 key 和 value （必须序列化）key.serializer value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建Kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 发送数据</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;atguigu&quot;</span> + i)).get();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="生产者分区">生产者分区</h3><h4 id="分区好处">分区好处</h4><ol><li><strong>便于合理使用存储资源</strong>。每个Partition在一个Broker上存储，可以把海量的数据按照分区切割成一块一块数据存储在多台Broker上。合理控制分区的任务，可以实现<strong>负载均衡</strong>的效果。</li><li><strong>提高并行度</strong>。生产者可以以分区为单位发送数据；消费者可以以分区为单位进行消费数据。</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941413.png" alt="image-20221006134154899"></p><h4 id="生产者发送消息的分区策略">生产者发送消息的分区策略</h4><ol><li><strong>默认的分区器 DefaultPartitioner</strong></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941414.png" alt="image-20221006135839620"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941415.png" alt="image-20221006135856390"></p><h4 id="自定义分区器">自定义分区器</h4><ol><li><p>需求：例如我们实现一个分区器，实现发送过来的数据中如果包含 atguigu，就发往0号分区，不包含 atguigu，就发往1号分区。</p></li><li><p>实现步骤</p><ol><li>定义类实现 Partitioner 接口</li><li>重写 partition() 方法</li></ol></li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPartitioner</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes, Cluster cluster)</span> &#123;</span><br><span class="line">        <span class="comment">// 获取数据 atguigu hello</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">msgValues</span> <span class="operator">=</span> value.toString();</span><br><span class="line">        <span class="type">int</span> partition;</span><br><span class="line">        <span class="keyword">if</span> (msgValues.contains(<span class="string">&quot;atguigu&quot;</span>)) &#123;</span><br><span class="line">            partition = <span class="number">0</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            partition = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>使用分区器的方法，在生产者的配置中添加分区器参数</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941416.png" alt="image-20221006141529678"></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerCallbackPartition</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 连接集群</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092，192.168.179.132:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 指定对应的 key 和 value （必须序列化）key.serializer value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关联自定义分区器</span></span><br><span class="line">        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, <span class="string">&quot;com.atguigu.kafka.producer.MyPartitioner&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建Kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 发送数据</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;atguigu&quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="literal">null</span>) &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;主题: &quot;</span> + metadata.topic() + <span class="string">&quot;, 分区: &quot;</span> + metadata.partition());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="生产经验——生产者如何提高吞吐量">生产经验——生产者如何提高吞吐量</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941417.png" alt="image-20221006141806031"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941418.png" alt="image-20221006152757611"></p><blockquote><p>因此，若要提高吞吐量：</p><ul><li>提高批次大小</li><li>提高等待时间</li><li>利用压缩</li><li>提高缓冲区大小</li></ul></blockquote><h3 id="生产经验——数据可靠性">生产经验——数据可靠性</h3><p>0）回顾发送流程</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941419.png" alt="image-20221006152831884"></p><p>1）ack应答原理</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941420.png" alt="image-20221006152905298"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941421.png" alt="image-20221006152952245"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941422.png" alt="image-20221006153117786"></p><p><strong>在代码中配置acks：</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941423.png" alt="image-20221006154022249"></p><h3 id="生产经验——数据去重">生产经验——数据去重</h3><p>要想解决生产者的数据重复问题，需要引入<strong>幂等性</strong>和<strong>事务</strong></p><h4 id="数据传递语义">数据传递语义</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941424.png" alt="image-20221006154132145"></p><h4 id="幂等性">幂等性</h4><p>默认打开</p><ol><li><strong>幂等性原理</strong></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941425.png" alt="image-20221006154319788"></p><ol start="2"><li><strong>如何使用幂等性</strong></li></ol><p>开启参数<code>enable.idempotence</code> 默认为true，false 关闭。</p><h4 id="生产者事务">生产者事务</h4><ol><li>Kafka 事务原理</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941426.png" alt="image-20221006154633410"></p><ol start="2"><li>Kafka的事务一共有如下5个API</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941427.png" alt="image-20221006155101921"></p><ol start="3"><li>代码演示（单个Producer，使用事务保证消息的仅一次发送）</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941428.png" alt="image-20221006155805664"></p><h3 id="生产经验——数据有序">生产经验——数据有序</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941429.png" alt="image-20221007092629321"></p><h3 id="生产经验——数据乱序">生产经验——数据乱序</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941430.png" alt="image-20221007093052147"></p><h2 id="Kafka-Broker">Kafka Broker</h2><h3 id="Kafka-Broker-工作流程">Kafka Broker 工作流程</h3><h4 id="Zookeeper-存储的Kafka信息">Zookeeper 存储的Kafka信息</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941431.png" alt="image-20221007094324179"></p><p>如下图可以看到，Zookeeper的服务端存储的Kafka相关信息有：</p><ul><li><code>/kafka/brokers/ids</code>：[0,1,2]；主要记录了当前Kafka有几个服务器作为broker，其中会包含服务器的hostname等信息。</li><li><code>/kafka/brokers/topics/first/partitions/0/state</code>：记录了哪个服务器是Leader，以及目前可用的服务器有哪些（ISR）。</li><li><code>/kafka/controller</code>：用于辅助选举Leader。（注：每个broker节点都有一个controller）</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941432.png" alt="image-20230325154207565"></p><blockquote><p>注：</p><ul><li><code>isr</code> 表示：<code>leader</code>和<code>follower</code>之间，通讯正常的节点。</li></ul></blockquote><h4 id="Kafka-Broker-总体工作流程">Kafka Broker 总体工作流程</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941433.png" alt="image-20221007094932531"></p><ol><li><code>broker</code>启动后，在zk中注册</li><li>哪个<code>broker</code>节点的<code>controller</code>抢先在zk中注册了，其余<code>broker</code>节点的<code>controller</code>就不会在zk中出现。</li><li>选举出来的<code>controller</code>会先监听zk中``/kafka/brokers`节点变化</li><li>选举出来的<code>controller</code>决定<code>Leader</code>的选举。选举规则如下：</li></ol><ul><li><strong>在<code>isr</code>中存活为前提</strong>。</li><li>按照<code>AR</code>中排在前面的节点会被优先选举为<code>Leader</code>。</li></ul><p>（例如，<code>ar</code>=[1,0,2]，<code>isr</code>=[1,0,2]，那么leader选举顺序会按照1，0，2的顺序轮询）</p><ol start="5"><li><code>controller</code>会将选举出来的节点信息上传到zk。</li><li>其他<code>broker</code>的<code>controller</code>从zk同步相关信息。</li><li>当生产者向<code>kafka</code>发送信息时，<code>Leader</code>先接收到信息，然后<code>Follower</code>主动跟<code>Leader</code>同步信息，然后给生产者应答消息。</li><li>如果<code>Leader</code>挂了，那<code>controller</code>能监听到节点变化</li><li><code>controller</code>再次获取zk中存储的<code>isr</code>信息</li><li>选举出新的<code>Leader</code></li><li>更新<code>Leader</code>及<code>isr</code></li></ol><blockquote><p>注：</p><ul><li><code>AR</code>表示：Kafka分区中所有的副本，包括挂掉的节点。</li></ul></blockquote><hr/><p><strong>模拟<code>Kafka</code>下线，观察<code>Zookeeper</code>中数据变化</strong></p><ol><li>先查看<code>/kafka/brokers/ids</code>路径上的节点。</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">连接到集群中任意zookeeper节点服务器</span></span><br><span class="line">[root@centos_03 kafka]# zkCli.sh -server 192.168.179.131:2181</span><br><span class="line"></span><br><span class="line">[zk: 192.168.179.131:2181(CONNECTED) 0] ls /kafka/brokers/ids</span><br><span class="line"></span><br><span class="line">[0, 1, 2]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="2"><li>查看<code>/kafka/controller</code>路径上的数据</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.179.131:2181(CONNECTED) 1] get /kafka/controller</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;brokerid&quot;:2,&quot;timestamp&quot;:&quot;1679728326055&quot;&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>查看<code>/kafka/brokers/topics/first/partitions/0/state</code>上的数据</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.179.131:2181(CONNECTED) 2] get /kafka/brokers/topics/first/partitions/0/state</span><br><span class="line"></span><br><span class="line">&#123;&quot;controller_epoch&quot;:2,&quot;leader&quot;:2,&quot;version&quot;:1,&quot;leader_epoch&quot;:0,&quot;isr&quot;:[2,1,0]&#125;</span><br></pre></td></tr></table></figure><p>可以观察到上述说明<code>Leader</code>节点的<code>broker.id</code>是2</p><ol start="4"><li>停止centos_04上的kafka</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_04 kafka]# bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure><ol start="5"><li>再次查看<code>/kafka/brokers/ids</code>路径上的节点。</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.179.131:2181(CONNECTED) 3] ls /kafka/brokers/ids</span><br><span class="line"></span><br><span class="line">[0, 1]</span><br></pre></td></tr></table></figure><ol start="6"><li>再次查看<code>/kafka/controller</code>路径上的数据</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.179.131:2181(CONNECTED) 4] get /kafka/controller</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;brokerid&quot;:1,&quot;timestamp&quot;:&quot;1679733548478&quot;&#125;</span><br></pre></td></tr></table></figure><ol start="7"><li>再次查看<code>/kafka/brokers/topics/first/partitions/0/state</code>上的数据</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.179.131:2181(CONNECTED) 5] get /kafka/brokers/topics/first/partitions/0/state</span><br><span class="line"></span><br><span class="line">&#123;&quot;controller_epoch&quot;:2,&quot;leader&quot;:1,&quot;version&quot;:1,&quot;leader_epoch&quot;:1,&quot;isr&quot;:[1,0]&#125;</span><br></pre></td></tr></table></figure><p>可以观察到上述说明<code>Leader</code>节点的<code>broker.id</code>是1</p><ol start="8"><li>启动centos_04上的kafka</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_04 kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br></pre></td></tr></table></figure><ol start="9"><li>再次观察1、2、3步骤中的内容</li></ol><h3 id="生产经验——节点服役和退役">生产经验——节点服役和退役</h3><h4 id="服役新节点">服役新节点</h4><p>有一个正在运行中的<code>kafka</code>集群，如果需要新增一个节点，那应该如何做？</p><hr/><p><strong>1）新节点的准备</strong></p><ul><li><p>关闭centos_04，并右键执行克隆操作。克隆出一个centos_05</p></li><li><p>在VMware中修改centos_05的MAC地址</p></li><li><p>开启centos_05，并修改IP地址、UUID、hostname等。</p></li><li><p>重新启动centos_04和centos_05</p></li></ul><hr/><ul><li><p>修改centos_05中的kafka中的配置文件<code>server.properties</code>的<code>broker.id</code>为3.（注：只修改<code>broker.id</code>即可）</p></li><li><p>删除centos_05中残余的<code>datas</code>和<code>logs</code>目录</p></li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_05 kafka]# rm -rf datas/ logs/</span><br></pre></td></tr></table></figure><ul><li>启动centos_02、centos_03、centos_04中的zookeeper集群与kafka集群</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zkServer.sh start</span><br><span class="line"></span><br><span class="line">bin/kafka-server-start.sh -daemon config/server.properties</span><br></pre></td></tr></table></figure><ul><li>单独启动centos_05中的kafka</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-server-start.sh -daemon config/server.properties</span><br></pre></td></tr></table></figure><p><strong>查看之前创建的topic主题情况</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --topic first --describe</span><br><span class="line"></span><br><span class="line">Topic: first    TopicId: LzWgw9oSSz682IOfozjtWg PartitionCount: 1       ReplicationFactor: 3    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: first    Partition: 0    Leader: 2       Replicas: 2,1,0 Isr: 0,2,1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>从中可以看到，副本依旧在[0, 1, 2]节点中，并没有在节点3中。</p><hr/><p><strong>2）执行负载均衡操作</strong></p><p>为了让节点3可以分担历史数据的存储，需要执行负载均衡操作。</p><ul><li>创建一个要均衡的主题</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# vim topics-to-move.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">        &quot;topics&quot;: [</span><br><span class="line">                &#123;&quot;topic&quot;: &quot;first&quot;&#125;</span><br><span class="line">        ],</span><br><span class="line">        &quot;version&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>生成一个负载均衡的计划</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server centos_02:9092 --topics-to-move-json-file topics-to-move.json --broker-list &quot;0,1,2,3&quot; --generate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Current partition replica assignment</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[2,1,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Proposed partition reassignment configuration</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[3,0,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br></pre></td></tr></table></figure><p>如果不满足要求可以重新生成</p><ul><li>创建副本存储计划（所有副本存储在<code>broker0</code>、<code>broker1</code>、<code>broker2</code>、<code>broker3</code>中）</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# vim increase-replication-factor.json</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将上述生成的计划复制下来</span></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[3,0,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br></pre></td></tr></table></figure><ul><li>执行副本存储计划</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server centos_02:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br><span class="line"></span><br><span class="line">Current partition replica assignment</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[2,1,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Save this to use as the --reassignment-json-file option during rollback</span><br><span class="line">Successfully started partition reassignment for first-0</span><br></pre></td></tr></table></figure><ul><li>验证副本存储计划是否执行成功</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server centos_02:9092 --reassignment-json-file increase-replication-factor.json --verify</span><br><span class="line"></span><br><span class="line">Status of partition reassignment:</span><br><span class="line">Reassignment of partition first-0 is complete.</span><br><span class="line"></span><br><span class="line">Clearing broker-level throttles on brokers 0,1,2,3</span><br><span class="line">Clearing topic-level throttles on topic first</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="退役旧节点">退役旧节点</h4><p>如果有个正在运行的kafka节点，需要退役，停止运行，那应该如何操作？如何将该节点的所有数据转移到其他节点？</p><hr/><p><strong>1）执行负载均衡操作</strong></p><p>先按照退役一台节点，生成执行计划，然后按照服役时操作流程执行负载均衡。</p><ul><li>创建一个要均衡的主题</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# vim topics-to-move.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">        &quot;topics&quot;: [</span><br><span class="line">                &#123;&quot;topic&quot;: &quot;first&quot;&#125;</span><br><span class="line">        ],</span><br><span class="line">        &quot;version&quot;: 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>创建执行计划</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server centos_02:9092 --topics-to-move-json-file topics-to-move.json --broker-list &quot;0,1,2&quot; --generate</span><br><span class="line"></span><br><span class="line">Current partition replica assignment</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[3,0,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Proposed partition reassignment configuration</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[1,0,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在上述中，一开始<code>first</code>主题的分区0，在[3, 0, 1]上有副本。假设需要退役节点3。在执行计划后，该主题只在[0, 1, 2]节点上有副本。</p><ul><li>创建副本存储计划</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# vim increase-replication-factor.json</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[1,0,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br></pre></td></tr></table></figure><ul><li>执行副本存储计划</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server centos_02:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br><span class="line"></span><br><span class="line">Current partition replica assignment</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[3,0,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Save this to use as the --reassignment-json-file option during rollback</span><br><span class="line">Successfully started partition reassignment for first-0</span><br></pre></td></tr></table></figure><ul><li>验证副本存储计划</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server centos_02:9092 --reassignment-json-file increase-replication-factor.json --verify</span><br><span class="line"></span><br><span class="line">Status of partition reassignment:</span><br><span class="line">Reassignment of partition first-0 is complete.</span><br><span class="line"></span><br><span class="line">Clearing broker-level throttles on brokers 0,1,2,3</span><br><span class="line">Clearing topic-level throttles on topic first</span><br></pre></td></tr></table></figure><p>2）执行停止命令（将退役节点上的kafka停止）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_05 kafka]# bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure><h3 id="Kafka-副本">Kafka 副本</h3><h4 id="副本基本信息">副本基本信息</h4><ol><li><strong>Kafka 副本作用：提高数据可靠性</strong></li><li>Kafka 默认副本1个，生产环境一般配置为2个，保证数据可靠性；太多副本会增加磁盘存储空间，增加网络上数据传输，降低效率。</li><li>Kafka中副本分为：Leader 和 Follower。<strong>Kafka 生产者只会把数据发往 Leader</strong>，然后 <strong>Follower 找 Leader 进行同步数据</strong>。</li><li>Kafka分区中的所有副本统称为<code>AR</code>（Assigner Replicas）</li></ol><p>AR = ISR + OSR</p><ul><li><p><code>ISR</code>：表示和<code>Leader</code>保持同步的<code>Follower</code>集合（也包括<code>Leader</code>）。如果<code>Follower</code>长时间未向<code>Leader</code>发送通信请求或同步数据，则该<code>Follower</code>将被踢出<code>ISR</code>。该时间阈值由<code>replica.lag.time.max.ms</code>参数设定，默认30s。Leader 发生故障之后，就会从ISR 中选举新的Leader。</p></li><li><p><code>OSR</code>：表示Follower 与Leader 副本同步时，延迟过多的副本。</p></li></ul><h4 id="Leader选举流程">Leader选举流程</h4><p>Kafka 集群中有一个<code>broker </code>的<code>Controller </code>会被选举为<code>Controller Leader</code>，<strong>负责管理集群<code>broker </code>的上下线</strong>，所有topic 的<strong>分区副本分配</strong>和**<code>Leader </code>选举**等工作。</p><p>Controller 的信息同步工作是<strong>依赖于Zookeeper 的</strong>。</p><p><strong>Leader选举流程</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941434.png" alt="image-20230325205503878"></p><ol><li><code>broker</code>启动后，在zk中注册</li><li>哪个<code>broker</code>节点的<code>controller</code>抢先在zk中注册了，其余<code>broker</code>节点的<code>controller</code>就不会在zk中出现。</li><li>选举出来的<code>controller</code>会先监听zk中``/kafka/brokers`节点变化</li><li>选举出来的<code>controller</code>决定<code>Leader</code>的选举。选举规则如下：</li></ol><ul><li><strong>在<code>isr</code>中存活为前提</strong>。</li><li>按照<code>AR</code>中排在前面的节点会被优先选举为<code>Leader</code>。（<strong>是按照<code>AR</code>中的顺序优先选举！</strong>）</li></ul><p>（例如，<code>ar</code>=[1,0,2]，<code>isr</code>=[1,0,2]，那么leader选举顺序会按照1，0，2的顺序轮询）</p><ol start="5"><li><code>controller</code>会将选举出来的节点信息上传到zk。</li><li>其他<code>broker</code>的<code>controller</code>从zk同步相关信息。</li><li>假设<code>broker1</code>中的<code>Leader</code>挂了</li><li>那<code>controller</code>能监听到节点变化</li><li><code>controller</code>再次获取zk中存储的<code>isr</code>信息</li><li>选举出新的<code>Leader</code></li><li>更新<code>Leader</code>及<code>isr</code></li></ol><hr/><p><strong>验证<code>Leader</code>的选举流程：</strong></p><p>需要使用centos_02、centos_03、centos_04、centos_05等四台虚拟机。其中在centos_02、centos_03、centos_04搭建了<code>zookeeper</code>集群，在centos_02、centos_03、centos_04、centos_05上搭建了<code>kafka</code>集群。</p><ol><li>创建一个新的topic，4个分区，4个副本</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --create --topic world1 --partitions 4 --replication-factor 4</span><br><span class="line"></span><br><span class="line">Created topic world1.</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="2"><li>查看Leader分布情况</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --describe --topic world1</span><br><span class="line"></span><br><span class="line">Topic: world1   TopicId: j4tB40K-TmKlM7Joxnoo1A PartitionCount: 4       ReplicationFactor: 4    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: world1   Partition: 0    Leader: 0       Replicas: 0,3,1,2       Isr: 0,3,1,2</span><br><span class="line">        Topic: world1   Partition: 1    Leader: 2       Replicas: 2,1,0,3       Isr: 2,1,0,3</span><br><span class="line">        Topic: world1   Partition: 2    Leader: 3       Replicas: 3,0,2,1       Isr: 3,0,2,1</span><br><span class="line">        Topic: world1   Partition: 3    Leader: 1       Replicas: 1,2,3,0       Isr: 1,2,3,0</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="3"><li>停止掉centos_05的kafka进程，并查看Leader分区情况</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在centos_05上操作</span></span><br><span class="line">[root@centos_05 kafka]# bin/kafka-server-stop.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在centos_02上操作</span></span><br><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --describe --topic world1</span><br><span class="line"></span><br><span class="line">Topic: world1   TopicId: j4tB40K-TmKlM7Joxnoo1A PartitionCount: 4       ReplicationFactor: 4    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: world1   Partition: 0    Leader: 0       Replicas: 0,3,1,2       Isr: 0,1,2</span><br><span class="line">        Topic: world1   Partition: 1    Leader: 2       Replicas: 2,1,0,3       Isr: 2,1,0</span><br><span class="line">        Topic: world1   Partition: 2    Leader: 0       Replicas: 3,0,2,1       Isr: 0,2,1</span><br><span class="line">        Topic: world1   Partition: 3    Leader: 1       Replicas: 1,2,3,0       Isr: 1,2,0</span><br></pre></td></tr></table></figure><p>可以看到所有的Leader节点都不会是3。并且，原本Leader=3的分区，按照规则从<code>AR</code>（即<code>Replicas</code>）[3,0,2,1] 中，选出了下一个Leader节点为0</p><ol start="4"><li>停止掉centos_04的kafka进程，并查看Leader分区情况</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在centos_04上操作</span></span><br><span class="line">[root@centos_04 kafka]# bin/kafka-server-stop.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在centos_02上操作</span></span><br><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --describe --topic world1</span><br><span class="line"></span><br><span class="line">Topic: world1   TopicId: j4tB40K-TmKlM7Joxnoo1A PartitionCount: 4       ReplicationFactor: 4    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: world1   Partition: 0    Leader: 0       Replicas: 0,3,1,2       Isr: 0,1</span><br><span class="line">        Topic: world1   Partition: 1    Leader: 1       Replicas: 2,1,0,3       Isr: 1,0</span><br><span class="line">        Topic: world1   Partition: 2    Leader: 0       Replicas: 3,0,2,1       Isr: 0,1</span><br><span class="line">        Topic: world1   Partition: 3    Leader: 1       Replicas: 1,2,3,0       Isr: 1,0</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以看到所有的Leader节点都不会是2或3。并且，原本Leader=2的分区，按照规则从<code>AR</code>（即<code>Replicas</code>）[2,1,0,3] 中，选出了下一个Leader节点为1</p><ol start="5"><li>启动centos_05的kafka进程，并查看Leader分区情况</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_05 kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line"></span><br><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --describe --topic world1</span><br><span class="line"></span><br><span class="line">Topic: world1   TopicId: j4tB40K-TmKlM7Joxnoo1A PartitionCount: 4       ReplicationFactor: 4    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: world1   Partition: 0    Leader: 0       Replicas: 0,3,1,2       Isr: 0,1,3</span><br><span class="line">        Topic: world1   Partition: 1    Leader: 1       Replicas: 2,1,0,3       Isr: 1,0,3</span><br><span class="line">        Topic: world1   Partition: 2    Leader: 0       Replicas: 3,0,2,1       Isr: 0,1,3</span><br><span class="line">        Topic: world1   Partition: 3    Leader: 1       Replicas: 1,2,3,0       Isr: 1,0,3</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>从中可以看到，虽然Leader节点没有变化，但是<code>Isr</code>节点有变化，新增了节点3.</p><ol start="6"><li>启动centos_04的kafka进程，并查看Leader分区情况</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_04 kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line"></span><br><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --describe --topic world1</span><br><span class="line"></span><br><span class="line">Topic: world1   TopicId: j4tB40K-TmKlM7Joxnoo1A PartitionCount: 4       ReplicationFactor: 4    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: world1   Partition: 0    Leader: 0       Replicas: 0,3,1,2       Isr: 0,1,3,2</span><br><span class="line">        Topic: world1   Partition: 1    Leader: 1       Replicas: 2,1,0,3       Isr: 1,0,3,2</span><br><span class="line">        Topic: world1   Partition: 2    Leader: 0       Replicas: 3,0,2,1       Isr: 0,1,3,2</span><br><span class="line">        Topic: world1   Partition: 3    Leader: 1       Replicas: 1,2,3,0       Isr: 1,0,3,2</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>从中可以看到，虽然Leader节点没有变化，但是<code>Isr</code>节点有变化，新增了节点2.</p><h4 id="Leader和Follower故障处理细节">Leader和Follower故障处理细节</h4><p>如果Leader或者Follower挂了，底层是如何处理的？</p><p><strong>1. Follower故障处理细节</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941435.png" alt="image-20230325212302287"></p><blockquote><p>建议看视频理解。</p><p>后续可能会专门再写篇博客理解</p></blockquote><p><strong>2. Leader故障处理细节</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941436.png" alt="image-20230325213224956"></p><h4 id="分区副本分配">分区副本分配</h4><p>如果kafka服务器只有4个节点，那么设置kafka的分区数大于服务器台数，在kafka底层如何分配存储副本呢？</p><p>1）创建16个分区，3个副本</p><p>（1）创建一个新的topic，名称为second</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --create --partitions 16 --replication-factor 3 --topic second</span><br><span class="line"></span><br><span class="line">Created topic second.</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（2）查看分区和副本情况</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --describe --topic second</span><br><span class="line"></span><br><span class="line">Topic: second   TopicId: NplREOVsQnKdkDw_mI4sOA PartitionCount: 16      ReplicationFactor: 3    Configs: se</span><br><span class="line">        Topic: second   Partition: 0    Leader: 1       Replicas: 1,0,2 Isr: 1,0,2</span><br><span class="line">        Topic: second   Partition: 1    Leader: 0       Replicas: 0,2,3 Isr: 0,2,3</span><br><span class="line">        Topic: second   Partition: 2    Leader: 2       Replicas: 2,3,1 Isr: 2,3,1</span><br><span class="line">        Topic: second   Partition: 3    Leader: 3       Replicas: 3,1,0 Isr: 3,1,0</span><br><span class="line">        Topic: second   Partition: 4    Leader: 1       Replicas: 1,2,3 Isr: 1,2,3</span><br><span class="line">        Topic: second   Partition: 5    Leader: 0       Replicas: 0,3,1 Isr: 0,3,1</span><br><span class="line">        Topic: second   Partition: 6    Leader: 2       Replicas: 2,1,0 Isr: 2,1,0</span><br><span class="line">        Topic: second   Partition: 7    Leader: 3       Replicas: 3,0,2 Isr: 3,0,2</span><br><span class="line">        Topic: second   Partition: 8    Leader: 1       Replicas: 1,3,0 Isr: 1,3,0</span><br><span class="line">        Topic: second   Partition: 9    Leader: 0       Replicas: 0,1,2 Isr: 0,1,2</span><br><span class="line">        Topic: second   Partition: 10   Leader: 2       Replicas: 2,0,3 Isr: 2,0,3</span><br><span class="line">        Topic: second   Partition: 11   Leader: 3       Replicas: 3,2,1 Isr: 3,2,1</span><br><span class="line">        Topic: second   Partition: 12   Leader: 1       Replicas: 1,0,2 Isr: 1,0,2</span><br><span class="line">        Topic: second   Partition: 13   Leader: 0       Replicas: 0,2,3 Isr: 0,2,3</span><br><span class="line">        Topic: second   Partition: 14   Leader: 2       Replicas: 2,3,1 Isr: 2,3,1</span><br><span class="line">        Topic: second   Partition: 15   Leader: 3       Replicas: 3,1,0 Isr: 3,1,0</span><br></pre></td></tr></table></figure><h4 id="生产经验——手动调整分区副本存储">生产经验——手动调整分区副本存储</h4><p>​在生产环境中，每台服务器的配置和性能不一致，但是Kafka只会根据自己的代码规则创建对应的分区副本，就会导致个别服务器存储压力较大。所有需要手动调整分区副本的存储。</p><blockquote><p>需求：创建一个新的topic，4个分区，两个副本，名称为three。将该topic的所有副本都存储到broker0和broker1两台服务器上。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941437.png" alt="image-20230328144813658"></p></blockquote><p><strong>手动调整分区副本存储的步骤如下：</strong></p><p>（1）创建一个新的topic，名称为three</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --create --partitions 4 --replication-factor 2 --topic three</span><br><span class="line"></span><br><span class="line">Created topic three.</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（2）查看分区副本资源情况</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --describe --topic three</span><br><span class="line"></span><br><span class="line">Topic: three    TopicId: Sg0i0KbqTciegwp8KhcVZw PartitionCount: 4       ReplicationFactor: 2    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: three    Partition: 0    Leader: 3       Replicas: 3,1   Isr: 3,1</span><br><span class="line">        Topic: three    Partition: 1    Leader: 1       Replicas: 1,0   Isr: 1,0</span><br><span class="line">        Topic: three    Partition: 2    Leader: 0       Replicas: 0,2   Isr: 0,2</span><br><span class="line">        Topic: three    Partition: 3    Leader: 2       Replicas: 2,3   Isr: 2,3</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（3）创建副本存储计划（所有副本都指定存储在节点0和1中）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# vim increase-replication-factor.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">&quot;version&quot;:1,</span><br><span class="line">&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1]&#125;,</span><br><span class="line">&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,1]&#125;,</span><br><span class="line">&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1,0]&#125;,</span><br><span class="line">&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[1,0]&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（4）执行副本存储计划</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server centos_02:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Current partition replica assignment</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[3,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[2,3],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Save this to use as the --reassignment-json-file option during rollback</span><br><span class="line">Successfully started partition reassignments for three-0,three-1,three-2,three-3</span><br></pre></td></tr></table></figure><p>（5）验证副本存储计划</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server centos_02:9092 --reassignment-json-file increase-replication-factor.json --verify</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Status of partition reassignment:</span><br><span class="line">Reassignment of partition three-0 is complete.</span><br><span class="line">Reassignment of partition three-1 is complete.</span><br><span class="line">Reassignment of partition three-2 is complete.</span><br><span class="line">Reassignment of partition three-3 is complete.</span><br><span class="line"></span><br><span class="line">Clearing broker-level throttles on brokers 0,1,2,3</span><br><span class="line">Clearing topic-level throttles on topic three</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（6）查看分区副本存储情况</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --describe --topic three</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Topic: three    TopicId: Sg0i0KbqTciegwp8KhcVZw PartitionCount: 4       ReplicationFactor: 2    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: three    Partition: 0    Leader: 0       Replicas: 0,1   Isr: 1,0</span><br><span class="line">        Topic: three    Partition: 1    Leader: 1       Replicas: 0,1   Isr: 1,0</span><br><span class="line">        Topic: three    Partition: 2    Leader: 0       Replicas: 1,0   Isr: 0,1</span><br><span class="line">        Topic: three    Partition: 3    Leader: 1       Replicas: 1,0   Isr: 1,0</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="生产经验——Leader-Partition负载平衡">生产经验——Leader Partition负载平衡</h4><p>​正常情况下，Kafka本身会自动把Leader Partition均匀分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些broker宕机，会导致Leader Partition过于集中在其他少部分几台broker上，这会导致少数几台broker的读写请求压力过高，其他宕机的broker重启之后都是follower partition，读写请求很低，造成集群负载不均衡。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941438.png" alt="image-20230328151350720"></p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>auto.leader.rebalance.enable</td><td>默认是true。 自动Leader Partition 平衡。生产环境中，leader 重选举的代价比较大，可能会带来性能影响，建议设置为false 关闭。</td></tr><tr><td>leader.imbalance.per.broker.percentage</td><td>默认是10%。每个broker 允许的不平衡的leader的比率。如果每个broker 超过了这个值，控制器会触发leader 的平衡。</td></tr><tr><td>leader.imbalance.check.interval.seconds</td><td>默认值300 秒。检查leader 负载是否平衡的间隔时间。</td></tr></tbody></table><h4 id="生产经验——增加副本因子">生产经验——增加副本因子</h4><p>在生产环境当中，由于某个主题的重要等级需要提升，我们考虑增加副本。副本数的增加需要先制定计划，然后根据计划执行。</p><p>1）创建topic</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --create --partitions 3 --replication-factor 1 --topic four</span><br><span class="line"></span><br><span class="line">Created topic four.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --describe --topic four      Topic: four     TopicId: v2BCz9JZR5SQ12eId6CaLg PartitionCount: 3       ReplicationFactor: 1    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: four     Partition: 0    Leader: 2       Replicas: 2     Isr: 2</span><br><span class="line">        Topic: four     Partition: 1    Leader: 3       Replicas: 3     Isr: 3</span><br><span class="line">        Topic: four     Partition: 2    Leader: 1       Replicas: 1     Isr: 1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2）手动增加副本存储</p><p>（1）创建副本存储计划（所有副本都指定存储在节点0、1、2中）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# vim increase-replication-factor.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">        &quot;version&quot;:1,</span><br><span class="line">        &quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1,2]&#125;,</span><br><span class="line">                                &#123;&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,1,2]&#125;,</span><br><span class="line">                                &#123;&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0,1,2]&#125;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（2）执行副本存储计划</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server centos_02:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Current partition replica assignment</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[2],&quot;log_dirs&quot;:[&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[3],&quot;log_dirs&quot;:[&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Save this to use as the --reassignment-json-file option during rollback</span><br><span class="line">Successfully started partition reassignments for four-0,four-1,four-2</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="文件存储">文件存储</h3><h4 id="文件存储机制">文件存储机制</h4><p><strong>1）Topic数据的存储机制</strong></p><p>Topic是逻辑上的概念，而partition是物理上的概念，<strong>每个partition对应于一个log文件</strong>，该log文件中存储的就是Producer生产的数据。<strong>Producer生产的数据会被不断追加到该log文件末端</strong>，为防止log文件过大导致数据定位效率低下，<strong>Kafka采取了分片和索引机制</strong>，<strong>将每个partition分为多个segment</strong>。<strong>每个segment包括：“.index”文件、“.log”文件和.timeindex等文件</strong>。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号，例如：first-0。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941439.png" alt="image-20230328160620180"></p><p>2）思考：Topic数据到底存储在什么位置？</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941440.png" alt="image-20230328161605121"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941441.png" alt="image-20230328161621254"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941442.png" alt="image-20230328161636566"></p><p>3）index文件和log文件详解</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941443.png" alt="image-20230328161708188"></p><h4 id="文件清理策略">文件清理策略</h4><p>Kafa中<strong>默认的日志保存时间为7天</strong>，可以通过调整如下参数修改保存时间。</p><ul><li><code>log.retention.hours</code> ：小时，默认7天。最低优先级</li><li><code>log.retention.minutes</code>：分钟。</li><li><code>log.retention.ms</code>：最高优先级毫秒。</li><li><code>log.retention.check.interval.ms</code>：负责设置检查周期，默认5分钟。</li></ul><p>那么日志一旦超过了设置的时间，怎么处理呢？<br>Kafa中提供的<strong>日志清理策略有<code>delete</code>和<code>compact</code>两种</strong>。</p><p>1）<code>delete</code>日志删除：将过期数据删除</p><ul><li><p><code>log.cleanup,policy=delete</code>： 所有数据启用删除策略</p><p>(1) <strong>基于时间：默认打开。以segment中所有记录中的最大时间戳作为该文件时间戳。</strong><br>(2) 基于大小：默认关闭。超过设置的所有日志总大小，删除最早的segment.<br>log.retention.bytes，默认等于-1，表示无穷大</p></li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941444.png" alt="image-20230328163924348"></p><p>2）<code>compact</code> 日志压缩</p><p><code>compact</code>日志压缩：对于相同<code>key</code>的不同<code>value</code>值，只保留最后一个版本</p><ul><li><code>log.cleanup,policy=compact</code>：所有数据启用压缩策略</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941445.png" alt="image-20230328185040596"></p><p>压缩后的<code>offset</code>可能是不连续的，比如上图中没有6，当从这些<code>offset</code>消费消息时，将会拿到比这个<code>offset</code>大的<code>offset</code>对应的消息，实际上会拿到<code>offset</code>为7的消息，并从这个位置开始消费。</p><p>这种策略只适合特殊场景，比如消息的<code>key</code>是用户ID，<code>vaue</code>是用户的资料，通过这种压缩策略，整个消息集里就保存了所有用户最新的资料。</p><h3 id="Kafka如何高效读写数据">Kafka如何高效读写数据</h3><p>Kafka如何高效读写数据？</p><p>答：</p><p>1）<strong>Kafka本身是分布式集群，可以采用分区技术，并行度高</strong></p><p>2）<strong>读数据采用稀疏索引，可以快速定位要消费的数据</strong></p><p>3）<strong>顺序写磁盘</strong></p><p>​Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s,而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p><p>4）<strong>页缓存+零拷贝技术</strong></p><ul><li><strong>零拷贝</strong>：Kafka的数据加工处理操作交由Kafka生产者和Kafka消费者处理。<strong>Kafka <code>Broker</code>应用层不关心存储的数据，所以就不用走应用层，传输效率高</strong>。</li><li><strong><code>PageCache</code>页缓存</strong> ：Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache。当读操作发生时，先从PageCache中查找，如果找不到，再去磁盘中读取。实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941446.png" alt="image-20230328190230682"></p><h2 id="Kafka消费者">Kafka消费者</h2><h3 id="Kafka消费方式">Kafka消费方式</h3><ul><li><p><strong>pull（拉）模式：</strong><code>consumer</code>采用从broker中主动拉取数据。<strong>Kafka采用这种方式</strong>。</p></li><li><p>**push（推）模式：**Kafka没有采用这种方式，因为由broker决定消息发送速率，很难适应所有消费者的消费速率。</p><p>如果使用push模式，则如下图所示，如果不同的消费者的消费速度不一致，那broker就无法选择合适的发送速率</p></li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941447.png" alt="image-20230330105708446"></p><p><code>pull</code>模式不足之处是：<strong>如果Kafka没有数据，消费者可能会陷入循环中，一直返回空数据</strong>。</p><h3 id="Kafka消费者工作流程">Kafka消费者工作流程</h3><h4 id="消费者总体工作流程">消费者总体工作流程</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941448.png" alt="image-20230330105849074"></p><ul><li>新版本的Kafka的<code>offset</code>存储在系统主题中，基于硬盘存储的</li><li>老版本（0.9）之前的Kafka的<code>offset</code>存储在对应的zookeeper中。</li></ul><h4 id="消费者组原理">消费者组原理</h4><p>Consumer Group（CG）：消费者组，由多个consumer组成。</p><p>形成一个消费者组的条件是：所有消费者的<code>groupid</code>相同。</p><ul><li>消费者组内 每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费。</li><li>消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941449.png" alt="image-20230330110844487"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941450.png" alt="image-20230330150854548"></p><h4 id="消费者组初始化流程">消费者组初始化流程</h4><p>每个<code>broker</code>都有一个<code>coordinator</code>组件。</p><p>组件<code>coordinator</code>的作用：辅助实现消费者组的初始化和分区的分配。</p><blockquote><p>消费者组选择哪个<code>coordinator</code>来进行后续工作？</p><p><code>coordinator</code>节点选择=<code>groupid</code>的hashcode值 % 50</p><hr/><p>上述 为什么是对 50 取余？</p><p>50是<code>__consumer_offsets</code>默认的分区数量。<code>__consumer_offsets</code>即位移主题，Kafka将consumer的位移数据作为一条条普通的Kafka消息，提交到<code>__consumer_offsets</code>中。即<code>__consumer_offsets</code>的主要作用是保存Kafka消费者的位移信息。</p></blockquote><p>例如： <code>groupid</code>的hashcode值= 1，1% 50 = 1，那么<code>__consumer_offsets</code> 主题的1号分区，在哪个broker上，就选择这个节点的<code>coordinator</code>作为这个消费者组的老大。消费者组下的所有的消费者提交offset的时候就往这个分区去提交offset。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941451.png" alt="image-20230330151421618"></p><p><strong>消费者组初始化流程：</strong></p><ol><li>所有的消费者都会主动向已选择的<code>coordinator</code>发送<code>JoinGroup</code>请求（根据<code>groupid</code>请求加入某个消费者组中）</li><li><code>coordinator</code>会从同一个消费者组中选出一个消费者作为<code>Leader</code></li><li><code>coordinator</code>会把要消费的<code>topic</code>情况发送给消费者<code>Leader</code></li><li>消费者<code>Leader</code>会负责制定消费方案（消费方案：指定每个消费者应该各自消费哪个分区）</li><li>消费者<code>Lader</code>把消费方案发送给<code>coordinator</code></li><li><code>coordinator</code>把消费方案发给各个<code>consumer</code></li><li>每个消费者都会和<code>coordinator</code>保持心跳（默认3s），一旦超时（<code>session.timeout.ms</code>=45s）该消费者会被移除，并触发再平衡；或者消费者处理消息的时间过长（<code>max.poll.interval.ms</code>=5min），也会认为该消费者自动下线，也会触发再平衡</li></ol><h4 id="消费者组详细消费流程">消费者组详细消费流程</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941452.png" alt="image-20230330162606950"></p><p><strong>消费者组详细消费流程：</strong></p><ol><li>消费者首先创建一个<code>ConsumerNetworkClient</code>（消费者网络连接客户端），主要用于跟kafka集群进行交互。</li><li>调用<code>sendFetches</code>方法，用来发送消费请求，拉去数据。（在该方法中定义<code>Fetch.min.bytes</code>、<code>Fetch.max.wait.ms</code>、<code>Fetch.max.bytes</code>等参数）</li><li>调用<code>ConsumerNetworkClient</code>的<code>send</code>方法</li><li>通过回调方法<code>onSuccess</code>把对应的数据拉取过来。拉取过来的数据会放在一个消息队列<code>completedFetches</code>中</li><li>消费者一次性从消息队列中拉取500条（默认<code>Max.poll.records</code>=500）数据</li><li>将拉取的数据反序列化</li><li>将拉取的数据进行拦截器</li><li>处理数据</li></ol><h4 id="消费者重要参数">消费者重要参数</h4><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>bootstrap.servers</td><td>向Kafka 集群建立初始连接用到的host/port 列表。</td></tr><tr><td>key.deserializer 和value.deserializer</td><td>指定接收消息的key 和value 的反序列化类型。一定要写全类名。</td></tr><tr><td><a href="http://group.id">group.id</a></td><td>标记消费者所属的消费者组。</td></tr><tr><td>enable.auto.commit</td><td>默认值为true，消费者会自动周期性地向服务器提交偏移量。</td></tr><tr><td><a href="http://auto.commit.interval.ms">auto.commit.interval.ms</a></td><td>如果设置了 enable.auto.commit 的值为true， 则该值定义了消费者偏移量向Kafka 提交的频率，默认5s。</td></tr><tr><td>auto.offset.reset</td><td>当Kafka 中没有初始偏移量或当前偏移量在服务器中不存在（如，数据被删除了），该如何处理？<br/> <code>earliest</code>：自动重置偏移量到最早的偏移量。<br/> <code>latest</code>：默认，自动重置偏移量为最新的偏移量。<br/> <code>none</code>：如果消费组原来的（previous）偏移量不存在，则向消费者抛异常。<br/> <code>anything</code>：向消费者抛异常。</td></tr><tr><td>offsets.topic.num.partitions</td><td>__consumer_offsets 的分区数，默认是50 个分区。</td></tr><tr><td><a href="http://heartbeat.interval.ms">heartbeat.interval.ms</a></td><td>Kafka 消费者和coordinator 之间的心跳时间，默认3s。该条目的值必须小于 <a href="http://session.timeout.ms">session.timeout.ms</a> ，<a href="http://xn--session-3w3kyxxoq96lrw3hqvsb.timeout.ms">也不应该高于session.timeout.ms</a> 的1/3。</td></tr><tr><td><a href="http://session.timeout.ms">session.timeout.ms</a></td><td>Kafka 消费者和coordinator 之间连接超时时间，默认45s。超过该值，该消费者被移除，消费者组执行再平衡。</td></tr><tr><td><a href="http://max.poll.interval.ms">max.poll.interval.ms</a></td><td>消费者处理消息的最大时长，默认是5分钟。超过该值，该消费者被移除，消费者组执行再平衡。</td></tr><tr><td>fetch.min.bytes</td><td>默认1个字节。消费者获取服务器端一批消息最小的字节数。</td></tr><tr><td><a href="http://fetch.max.wait.ms">fetch.max.wait.ms</a></td><td>默认500ms。如果没有从服务器端获取到一批数据的最小字节数。该时间到，仍然会返回数据。</td></tr><tr><td>fetch.max.bytes</td><td>默认Default: 52428800 (50m)。消费者获取服务器端一批消息最大的字节数。如果服务器端一批次的数据大于该值 (50m) 仍然可以拉取回来这批数据，因此，这不是一个绝对最大值。一批次的大小受message.max.bytes（broker config) or max.message.bytes (topic config) 影响。</td></tr><tr><td>max.poll.records</td><td>一次poll拉取数据返回消息的最大条数，默认是500条。</td></tr></tbody></table><h3 id="消费者API">消费者API</h3><h4 id="独立消费者案例（订阅主题）">独立消费者案例（订阅主题）</h4><p>1）需求</p><p>创建一个独立消费者，消费first主题中的数据</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941453.png" alt="image-20230331092637365"></p><p>注意：在消费者API代码中必须配置消费者组id。命令行启动消费者时，若不填写消费者组id，则会被自动填写随机的消费者组id</p><p>2）实现步骤</p><p>（1）创建包名：com.atguigu.kafka.consumer</p><p>（2）编写代码</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        <span class="comment">// 连接 bootstrap.servers</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092,192.168.179.132:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 反序列化</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// groupid</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>);</span><br><span class="line">        <span class="comment">// 1. 创建一个消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">// 2. 定义主题 first</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line">        <span class="comment">// 3. 消费数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 设置每秒拉取一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 打印拉取到的数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3）测试</p><p>（1）在IDEA中执行消费者程序</p><p>（2）在Kafka集群控制台中，创建Kafka生产者，并输入数据。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-console-producer.sh --bootstrap-server centos_02:9092 --topic first</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">hello</span></span><br></pre></td></tr></table></figure><p>（3）在IDEA控制台观察到接收到的数据。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 17, offset = 15, CreateTime = 1680231501352, serialized key size = -1, serialized value size = 5, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hello)</span><br></pre></td></tr></table></figure><blockquote><p>注：如果出现“Kafka在命令行中启动消费者可以正常消费数据，但是在通过Java编写的消费者程序中无法消费数据”这种情况，那么问题可能就出在client和服务端的连接上。</p><p>解决方案如下：</p><p>将<code>kafka/config/server.properties</code>配置文件中的<code>advertised.listeners</code>改成如下属性。其中，<code>192.168.179.131</code>是Kafka服务器的IP地址。改完重启Kafka即可。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">advertised.listeners=PLAINTEXT://192.168.179.131:9092</span><br></pre></td></tr></table></figure><p><code>advertised.listeners</code>的意思是说：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Hostname and port the broker will advertise to producers and consumers. If not <span class="built_in">set</span>,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">it uses the value <span class="keyword">for</span> <span class="string">&quot;listeners&quot;</span> <span class="keyword">if</span> configured.  Otherwise, it will use the value</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">returned from java.net.InetAddress.getCanonicalHostName().</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">advertised.listeners = PLAINTEXT://your.host.name:9092</span></span><br></pre></td></tr></table></figure><p>即，<code>Kafka</code>保证了hostname和port都会广播给生产者和消费者。如果没有配置<code>advertised.listeners</code>这个属性，则会使用<code>listeners</code>的值。如果<code>listeners</code>也没配置的话，则使用<code>java.net.InetAddress.getCanonicalHostName() </code>（这里也就是返回localhost了）</p></blockquote><h4 id="独立消费者案例（订阅分区）">独立消费者案例（订阅分区）</h4><p>让一个独立消费者，消费指定的分区</p><p>1）需求：创建一个独立消费者，消费<code>first</code>主题0号分区的数据</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941454.png" alt="image-20230331154607888"></p><p>2）实现步骤</p><p>（1）代码编写</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerPartition</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092,192.168.179.132:9092&quot;</span>);</span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>);</span><br><span class="line">        <span class="comment">// 1. 创建一个消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">// 2. 订阅主题对应的分区</span></span><br><span class="line">        ArrayList&lt;TopicPartition&gt; partitions = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        partitions.add(<span class="keyword">new</span> <span class="title class_">TopicPartition</span>(<span class="string">&quot;first&quot;</span>, <span class="number">0</span>));</span><br><span class="line">        kafkaConsumer.assign(partitions);</span><br><span class="line">        <span class="comment">// 3. 消费数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3）测试</p><p>（1）在IDEA中执行消费者程序</p><p>（2）在IDEA中执行生产者程序</p><p>生产者代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerCallbackPartition</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        <span class="comment">// 连接集群</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092，192.168.179.132:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 指定对应的 key 和 value （必须序列化）key.serializer value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        <span class="comment">// 关联自定义分区器</span></span><br><span class="line">        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, <span class="string">&quot;com.atguigu.kafka.producer.MyPartitioner&quot;</span>);</span><br><span class="line">        <span class="comment">// 1. 创建Kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">// 2. 发送数据</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>,<span class="number">0</span>, <span class="string">&quot;&quot;</span>, <span class="string">&quot;atguigu&quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="literal">null</span>) &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;主题: &quot;</span> + metadata.topic() + <span class="string">&quot;, 分区: &quot;</span> + metadata.partition());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">       <span class="comment">// 3. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>发送数据如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">主题: first, 分区: 0</span><br><span class="line">主题: first, 分区: 0</span><br><span class="line">主题: first, 分区: 0</span><br><span class="line">主题: first, 分区: 0</span><br><span class="line">主题: first, 分区: 0</span><br><span class="line">主题: first, 分区: 0</span><br><span class="line">主题: first, 分区: 0</span><br><span class="line">主题: first, 分区: 0</span><br><span class="line">主题: first, 分区: 0</span><br><span class="line">主题: first, 分区: 0</span><br></pre></td></tr></table></figure><p>（3）消费者接收到的数据如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 17, offset = 17, CreateTime = 1680250731070, serialized key size = 0, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 17, offset = 18, CreateTime = 1680250731081, serialized key size = 0, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 17, offset = 19, CreateTime = 1680250731081, serialized key size = 0, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 17, offset = 20, CreateTime = 1680250731081, serialized key size = 0, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu3)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 17, offset = 21, CreateTime = 1680250731081, serialized key size = 0, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu4)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 17, offset = 22, CreateTime = 1680250731081, serialized key size = 0, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu5)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 17, offset = 23, CreateTime = 1680250731081, serialized key size = 0, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu6)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 17, offset = 24, CreateTime = 1680250731081, serialized key size = 0, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu7)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 17, offset = 25, CreateTime = 1680250731081, serialized key size = 0, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu8)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 17, offset = 26, CreateTime = 1680250731081, serialized key size = 0, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu9)</span><br></pre></td></tr></table></figure><h4 id="消费者组案例">消费者组案例</h4><p>1）需求：测试同一个主题的分区数据，只能由同一消费者组中的 一个消费者来消费。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941455.png" alt="image-20230331163815620"></p><p>2）案例实操</p><p>（1）复制一份基础消费者的代码，在IDEA中同时启动，即可启动同一个消费者组中的三个消费者</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">public class CustomConsumer1 &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        // 0. 配置</span><br><span class="line">        Properties properties = new Properties();</span><br><span class="line">        // 连接 bootstrap.servers</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.179.131:9092,192.168.179.132:9092&quot;);</span><br><span class="line">        // 反序列化</span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        // groupid</span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;test&quot;);</span><br><span class="line">        // 1. 创建一个消费者</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;&gt;(properties);</span><br><span class="line">        // 2. 定义主题 first</span><br><span class="line">        ArrayList&lt;String&gt; topics = new ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(&quot;first&quot;);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line">        // 3. 消费数据</span><br><span class="line">        while (true) &#123;</span><br><span class="line">            // 设置每秒拉取一批数据</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));</span><br><span class="line">            // 打印拉取到的数据</span><br><span class="line">            for (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（2）启动代码中的生产者发送消息，在IDEA控制台中即可看到三个消费者在消费不同分区的数据。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">public class CustomProducerCallback &#123;</span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        // 0. 配置</span><br><span class="line">        Properties properties = new Properties();</span><br><span class="line">        // 连接集群</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.179.131:9092，192.168.179.132:9092&quot;);</span><br><span class="line">        // 指定对应的 key 和 value （必须序列化）key.serializer value.serializer</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        // 1. 创建Kafka生产者对象</span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;&gt;(properties);</span><br><span class="line">        // 2. 发送数据</span><br><span class="line">        for (int i = 0; i &lt; 500; i++) &#123;</span><br><span class="line">            kafkaProducer.send(new ProducerRecord&lt;&gt;(&quot;first&quot;, &quot;atguigu&quot; + i), new Callback() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void onCompletion(RecordMetadata metadata, Exception exception) &#123;</span><br><span class="line">                    if (exception == null) &#123;</span><br><span class="line">                        System.out.println(&quot;主题: &quot; + metadata.topic() + &quot;, 分区: &quot; + metadata.partition());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            Thread.sleep(1);</span><br><span class="line">        &#125;</span><br><span class="line">        // 3. 关闭资源</span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在生产者中会随机往<code>first</code>主题的3个分区中发送数据。观察三个消费者控制台接收到的数据可以看到，每个消费者只会消费一个分区的数据。</p><p>（3）重新发送到一个全新的主题中，由于默认创建的主题分区数为1，可以看到只能有一个消费者消费到数据。</p><h3 id="生产经验——分区的分配以及再平衡">生产经验——分区的分配以及再平衡</h3><p><strong>思考：</strong> 一个consumer group中有多个consumer组成，一个topic有多个partition组成，现在的问题是，到底由哪个consumer来消费哪个partition的数据。</p><p><strong>答</strong>：</p><p><strong>Kafka有四种主流的分区分配策略</strong>：Range、RoundRobin、Sticky、CooperativeSticky，可以通过配置参数<code>partition.assignment.strategy</code>来修改分区的分配策略。默认策略是Range + CooperativeSticky。Kafka可以同时使用多个分区分配策略。Kafka也可以自定义分区分配策略，不过用的比较少。</p><hr/><p>回顾一下消费者组的初始化流程：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941456.png" alt="image-20230331165622257"></p><p>上述步骤中，所谓的**“消费方案”**即是Kafka的分区分配策略。</p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td><a href="http://heartbeat.interval.ms">heartbeat.interval.ms</a></td><td>Kafka 消费者和coordinator 之间的心跳时间，默认3s。该条目的值必须小于 <a href="http://session.timeout.ms">session.timeout.ms</a> ，<a href="http://xn--session-3w3kyxxoq96lrw3hqvsb.timeout.ms">也不应该高于session.timeout.ms</a> 的1/3。</td></tr><tr><td><a href="http://session.timeout.ms">session.timeout.ms</a></td><td>Kafka 消费者和coordinator 之间连接超时时间，默认45s。超过该值，该消费者被移除，消费者组执行再平衡。</td></tr><tr><td><a href="http://max.poll.interval.ms">max.poll.interval.ms</a></td><td>消费者处理消息的最大时长，默认是5分钟。超过该值，该消费者被移除，消费者组执行再平衡。</td></tr><tr><td>partition.assignment.strategy</td><td>消费者分区分配策略，默认策略是 Range + CooperativeSticky。Kafka 可以同时使用多个分区分配策略。可以选择的策略包括： Range 、RoundRobin 、Sticky 、CooperativeSticky</td></tr></tbody></table><h4 id="Range-以及再平衡">Range 以及再平衡</h4><p><strong>1）Range分区策略原理</strong></p><p><strong>Range是根据每个topic来分配分区的</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941457.png" alt="image-20230331171637532"></p><p><strong>2）Range分区分配策略案例</strong></p><p>（1）修改主题 first 为7个分区</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-topics.sh --bootstrap-server centos_02:9092 --alter --topic first --partitions 7</span><br></pre></td></tr></table></figure><p><strong>注意：分区数可以增加，但是不能减少。</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941458.png" alt="image-20230402153217378"></p><p>（2）复制CustomConsumer类，创建CustomConsumer2。这样可以由三个消费者CustomConsumer、CustomConsumer1、CustomConsumer2组成消费者，组名（groupid）都为“test”，同时启动3个消费者。</p><p>（3）启动CustomProducer生产者，发送500条消费，随机发送到不同分区。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerCallback</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        <span class="comment">// 连接集群</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092，192.168.179.132:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 指定对应的 key 和 value （必须序列化）key.serializer value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        <span class="comment">// 1. 创建Kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">// 2. 发送数据</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">500</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;atguigu&quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="literal">null</span>) &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;主题: &quot;</span> + metadata.topic() + <span class="string">&quot;, 分区: &quot;</span> + metadata.partition());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            Thread.sleep(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 3. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>注：Kafka默认的分区分配策略就是Range+CooperativeSticky,所以不需要修改策略。</strong></p><p>（4）观看3个消费者分别消费哪些分区的数据。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941459.png" alt="image-20230402153715657"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941460.png" alt="image-20230402153743381"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941461.png" alt="image-20230402153813830"></p><p>假设上述消费者，</p><ul><li>消费0、1、2分区的为0号消费者。</li><li>消费3、4分区的为1号消费者。</li><li>消费5、6分区的为2号消费者。</li></ul><p><strong>3）Range分区分配再平衡案例</strong></p><p>（1）停掉0号消费者（消费0、1、2分区的消费者），快速重新发送消费观看结果（45s以内，越快越好）</p><ul><li><p>1号消费者：消费到3、4号分区数据</p></li><li><p>2号消费者：消费到5、6号分区数据</p></li><li><p>0号消费者的任务会<strong>整体分配到</strong>1号消费者或者2号消费者。</p></li></ul><blockquote><p>说明：0号消费者挂掉后，消费者组需要按照超时时间45s来判断它是否退出，所以需要等待，时间到了45s后，判断它真的退出就会把任务分配给其他消费者执行。</p></blockquote><p>（2）再次重新发送消费观看结果（45s以后）</p><ul><li><p>1号消费者：消费到0、1、2、3号分区数据。</p></li><li><p>2号消费者：消费到4、5、6号分区数据。</p></li></ul><blockquote><p>说明：消费者0已经被踢出消费者组，所以重新按照range方式分配。</p></blockquote><h4 id="RoundRobin以及再平衡">RoundRobin以及再平衡</h4><p><strong>1）RoundRobin分区策略原理</strong></p><p><strong>RoundRobin是根据所有topic来分配分区的</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941462.png" alt="image-20230402155712072"></p><p><strong>2）RoundRobin分区分配策略案例</strong></p><p>（1）依次在 CustomConsumer、CustomConsumer1、CustomConsumer2 三个消费者代码中修改分区分配策略为 RoundRobin。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 修改分区分配策略</span></span><br><span class="line">properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">&quot;org.apache.kafka.clients.consumer.RoundRobinAssignor&quot;</span>);   </span><br></pre></td></tr></table></figure><p>（2）重启3个消费者，重复发送消费的步骤，观看分区结果。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941463.png" alt="image-20230402184447295"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941464.png" alt="image-20230402184527642"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941465.png" alt="image-20230402184549195"></p><p><strong>3）RoundRobin分区分配再平衡案例</strong></p><p>（1）停止掉0号消费者，快速重新发送消息观看结果（45s以内，越快越好）。</p><p>1号消费者：消费到2、5号分区数据</p><p>2号消费者：消费到4、1号分区数据</p><p>0号消费者的任务会按照RoundRobin的方式，把数据轮询分成0、6和3号分区数据，分别由1号消费者或者2号消费者消费。</p><blockquote><p>说明：0号消费者挂掉后，消费者组需要按照超时时间45s来判断它是否退出，所以需要等待，时间到了45s后，判断它真的退出就会把任务分配给其他broker执行。</p></blockquote><p>（2）再次重新发送消息观看结果(45s以后)。</p><p>1号消费者：消费到0、2、4、6号分区数据</p><p>2号消费者：消费到1、3、5号分区数据</p><blockquote><p>说明：消费者0己经被踢出消费者组，所以重新按照RoundRobin方式分配。</p></blockquote><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941466.png" alt="image-20230402185409213"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941467.png" alt="image-20230402185504506"></p><h4 id="Sticky-以及再平衡">Sticky 以及再平衡</h4><p><strong>粘性分区定义</strong>：可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前，考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。</p><p>粘性分区是Kafka从0.11.x版本开始引入这种分配策略，<strong>首先会尽量均衡的放置分区到消费者上面</strong>，在出现同一消费者组内消费者出现问题的时候，<strong>会尽量保持原有分配的分区不变化</strong>。</p><p><strong>1）需求</strong></p><p>​设置主题为first，7个分区；准备3个消费者，采用粘性分区策略，并进行消费，观察消费分配情况。然后再停止其中一个消费者，再次观察消费分配情况。</p><p><strong>2）步骤</strong></p><p>（1）修改分区分配策略为粘性</p><p>注意：3个消费者都应该注释掉，之后重启3个消费者，如果出现报错，全部停止，等会再重启，或者修改为全新的消费者组。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 修改分区分配策略</span></span><br><span class="line">properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">&quot;org.apache.kafka.clients.consumer.StickyAssignor&quot;</span>);</span><br></pre></td></tr></table></figure><p>（2）使用同样的生产者发送500条消息。</p><p>可以看到会尽量保持分区的个数，近似划分分区。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941468.png" alt="image-20230402193849773"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941469.png" alt="image-20230402193906902"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941470.png" alt="image-20230402193924981"></p><blockquote><p>注：以上消费者消费的分区是随机分配的。可以重启并重新发送以验证它的随机性。</p></blockquote><p><strong>3）Sticky分区分配再平衡案例</strong></p><p>（1）停止掉0号消费者，快速重新发送消息观看结果（45s以内，越快越好）</p><p>1号消费者：消费1、4号分区数据</p><p>2号消费者：消费2、5号分区数据</p><p>0号消费者的任务会按照粘性规则，尽可能均衡的随机分成0和1号分区数据，分别由1号消费者或者2号消费者消费。</p><blockquote><p>说明：0号消费者挂掉后，消费者组需要按照超时时间45s来判断它是否退出，所以需要等待，时间到了45s后，判断它真的退出就会把任务分配给其他broker执行。</p></blockquote><p>（2）再次重新发送消息观看结果(45s以后)。</p><p>1号消费者：消费到2、3、5号分区数据。</p><p>2号消费者：消费到0、1、4、6号分区数据。</p><blockquote><p>说明：消费者0己经被踢出消费者组，所以重新按照粘性方式分配。</p></blockquote><h3 id="offset-位移">offset 位移</h3><h4 id="offset的默认维护位置">offset的默认维护位置</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941471.png" alt="image-20230402195027603"></p><p><code>__consumer_offsets</code>主题里面采用<code>key</code>和<code>value</code>的方式存储数据。<code>key</code>是 group.id+topic+<br>分区号，<code>value</code>就是当前offset的值。每隔一段时间，kafka内部会对这个topic进行<code>compact</code>，也就是每个 group.id+topic+分区号 就保留最新数据。</p><p><strong>1）消费offset案例</strong></p><p>（0）思想：consumeroffsets为Kafka中的topic,那就可以通过消费者进行消费。</p><p>（1）在配置文件<code>config/consumer.properties</code>中添加配置<code>exclude.internal.topics=false</code>。默认是tue，表示不能消费系统主题。为了查看该系统主题数据，所以该参数修改为false。不用重启</p><p>（2）采用命令行方式，创建一个新的topic</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server centos_02:9092 --create --topic atguigu --partitions 2 --replication-factor 2</span><br></pre></td></tr></table></figure><p>（3）启动生产者往atguigu生产数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_02 kafka]# bin/kafka-console-producer.sh --topic atguigu --bootstrap-server centos_02:9092</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">hello</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（4）启动消费者消费atguigu数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_03 kafka]# bin/kafka-console-consumer.sh --bootstrap-server centos_02:9092 --topic atguigu --group test</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>注：指定消费者组名称，可以更好地观察数据的存储位置（key 是 group.id+topic+分区号）</strong></p><p>（5）查看消费者消费主题<code>__consumer_offsets</code></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_04 kafka]# bin/kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server centos_02:9092 --consumer.config config/consumer.properties --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot; --from-beginning</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941472.png" alt="image-20230403145915979"></p><h4 id="自动提交-offset">自动提交 offset</h4><p>为了使我们能够专注于自己的业务逻辑，<strong>Kafka提供了自动提交<code>offset</code>的功能</strong>。</p><p>自动提交<code>offset</code>的相关参数：</p><ul><li><code>enable.auto.commit</code>：是否开启自动提交offset功能，默认是true</li><li><code>auto.commit.interval.ms</code>：自动提交offset的时间间隔，默认是5s</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941473.png" alt="image-20230403150118877"></p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td><code>enable.auto.commit</code></td><td>默认值为true，消费者会自动周期性地向服务器提交偏移量。</td></tr><tr><td><code>auto.commit.interval.ms</code></td><td>如果设置了enable.auto.commit的值为tue,则该值定义了消费者偏移量向Kafka提交的频率，默认5s。</td></tr></tbody></table><p><strong>1）消费者自动提交offset</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerAutoOffset</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        <span class="comment">// 连接 bootstrap.servers</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092,192.168.179.132:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 反序列化</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 修改分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">&quot;org.apache.kafka.clients.consumer.StickyAssignor&quot;</span>);</span><br><span class="line">        <span class="comment">// groupid</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test4&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 自动提交, 默认就是true</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="literal">true</span>);</span><br><span class="line">        <span class="comment">// 提交时间间隔, 单位ms</span></span><br><span class="line">        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建一个消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">// 2. 定义主题 first</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line">        <span class="comment">// 3. 消费数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 设置每秒拉取一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 打印拉取到的数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="手动提交offset">手动提交offset</h4><p>虽然自动提交offset十分简单便利，但由于其是基于时间提交的，开发人员难以把握offset提交的时机。因此kafka还提供了手动提交offset的API。</p><p>手动提交offset的方法有两种：分别是**<code>commitSync</code>（同步提交）<strong>和 <strong><code>commitAsync</code>（异步提交）</strong>。两者的相同点是：<strong>都会将本次提交的一批数据最高的偏移量提交</strong>；不同点是：<strong>同步提交阻塞当前线程</strong>，一直到提交成功，并且会自动失败重试(由不可控因素导致，也会出现提交失败)。而</strong>异步提交则没有失败重试机制，故有可能提交失败**。</p><ul><li><code>commitSync</code>（同步提交）：必须等待offset提交完毕，再去消费下一批数据。</li><li><code>commitAsync</code>（异步提交）：发送完提交offset请求后，就开始消费下一批数据了。</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941474.png" alt="image-20230403153423101"></p><p><strong>1）同步提交offset</strong></p><p>由于同步提交offset有失败重试机制，故更加可靠，但是由于一直等待提交结果，提交的效率比较低。</p><p>以下为同步提交offset的示例。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerByHandSync</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        <span class="comment">// 连接 bootstrap.servers</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092,192.168.179.132:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 反序列化</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 修改分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">&quot;org.apache.kafka.clients.consumer.StickyAssignor&quot;</span>);</span><br><span class="line">        <span class="comment">// groupid</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test5&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 手动提交</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建一个消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">// 2. 定义主题 first</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line">        <span class="comment">// 3. 消费数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 设置每秒拉取一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 打印拉取到的数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 手动提交offset, 同步提交</span></span><br><span class="line">            kafkaConsumer.commitSync();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>2）异步提交offset</strong></p><p>虽然同步提交offset更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会受到很大的影响。因此更多的情况下，会选用异步提交offset的方式。</p><p>以下为异步提交offset的示例：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerByHandAsync</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        <span class="comment">// 连接 bootstrap.servers</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092,192.168.179.132:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 反序列化</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 修改分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">&quot;org.apache.kafka.clients.consumer.StickyAssignor&quot;</span>);</span><br><span class="line">        <span class="comment">// groupid</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test5&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 手动提交</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建一个消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">// 2. 定义主题 first</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line">        <span class="comment">// 3. 消费数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 设置每秒拉取一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 打印拉取到的数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 手动提交offset, 异步提交</span></span><br><span class="line">            kafkaConsumer.commitAsync();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>在生产环境中，通常采用异步提交的方式。</p></blockquote><h4 id="指定offset消费">指定offset消费</h4><p><code>auto.offset.reset</code> = earliest | latest | none，默认是latest。</p><p>当Kafka中没有初始偏移量（消费者组第一次消费）或服务器上不再存在当前偏移量时（例如该数据已被删除），该怎么办？</p><p>（1）<code>earliest</code>：自动将偏移量重置为最早的偏移量，–from-beginning。</p><p>（2）<code>latest</code>（默认值）：自动将偏移量重置为最新偏移量。</p><p>（3）<code>none</code>：如果未找到消费者组的先前偏移量，则向消费者抛出异常。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941475.png" alt="image-20230403165208521"></p><p>（4）任意指定offset位移开始消费</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerSeek</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092,192.168.179.132:9092&quot;</span>);</span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test10&quot;</span>);</span><br><span class="line">        <span class="comment">// 1. 创造消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">// 2. 订阅主题</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取当前分配给此消费者的分区集合</span></span><br><span class="line">        Set&lt;TopicPartition&gt; assignment = kafkaConsumer.assignment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 保证分区分配方案已经制定完毕</span></span><br><span class="line">        <span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) &#123;</span><br><span class="line">            kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            assignment = kafkaConsumer.assignment();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 在对应分区中指定消费的offset</span></span><br><span class="line">        <span class="keyword">for</span> (TopicPartition topicPartition : assignment) &#123;</span><br><span class="line">            kafkaConsumer.seek(topicPartition, <span class="number">35000</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>主要添加了以下代码：</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941476.png" alt="image-20230403185616021"></p><p>打印结果如下：可以看到只消费了offset&gt;=35000的数据。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941477.png" alt="image-20230403185218668"></p><h4 id="指定时间消费">指定时间消费</h4><p>需求：在生产环境中，会遇到最近消费的几个小时数据异常，想重新按照时间消费。例如要求按照时间 消费前一天的数据，怎么处理？</p><p>操作步骤：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerForTime</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 0. 配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.179.131:9092,192.168.179.132:9092&quot;</span>);</span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test10&quot;</span>);</span><br><span class="line">        <span class="comment">// 1. 创造消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">// 2. 订阅主题</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取当前分配给此消费者的分区集合</span></span><br><span class="line">        Set&lt;TopicPartition&gt; assignment = kafkaConsumer.assignment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 保证分区分配方案已经制定完毕</span></span><br><span class="line">        <span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) &#123;</span><br><span class="line">            kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            assignment = kafkaConsumer.assignment();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 希望把时间转换为对应的offset</span></span><br><span class="line">        HashMap&lt;TopicPartition, Long&gt; topicPartitionLongHashMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        <span class="comment">// 封装对应集合</span></span><br><span class="line">        <span class="keyword">for</span> (TopicPartition topicPartition : assignment) &#123;</span><br><span class="line">            <span class="comment">// 指定时间为一天前</span></span><br><span class="line">            topicPartitionLongHashMap.put(topicPartition, System.currentTimeMillis() - <span class="number">1</span> * <span class="number">24</span> * <span class="number">3600</span> * <span class="number">1000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 通过时间获取到对应的offset</span></span><br><span class="line">        Map&lt;TopicPartition, OffsetAndTimestamp&gt; topicPartitionOffsetAndTimestampMap = kafkaConsumer.offsetsForTimes(topicPartitionLongHashMap);</span><br><span class="line">        <span class="comment">// 在对应分区中指定消费的offset</span></span><br><span class="line">        <span class="keyword">for</span> (TopicPartition topicPartition : assignment) &#123;</span><br><span class="line">            <span class="type">OffsetAndTimestamp</span> <span class="variable">offsetAndTimestamp</span> <span class="operator">=</span> topicPartitionOffsetAndTimestampMap.get(topicPartition);</span><br><span class="line">            <span class="keyword">if</span> (offsetAndTimestamp != <span class="literal">null</span>) &#123;</span><br><span class="line">                kafkaConsumer.seek(topicPartition, offsetAndTimestamp.offset());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 消费该主题数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>主要看以下代码：</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941478.png" alt="image-20230403190932257"></p><h4 id="漏消费和重复消费">漏消费和重复消费</h4><ul><li><p><strong>重复消费</strong>：已经消费了数据，但是offset没提交。可能会导致同一个数据被重复消费。</p></li><li><p><strong>漏消费</strong>：先提交offset后消费，有可能会造成数据的漏消费。</p></li></ul><p><strong>1）可能导致重复消费的场景</strong></p><ul><li><strong>自动提交offset可能引起重复消费</strong></li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941479.png" alt="image-20230403191331379"></p><p><strong>2）可能导致漏消费的场景</strong></p><ul><li><strong>消费者先提交offset后消费数据</strong>。设置offset为手动提交，当offset被提交时，数据还在内存中未落盘，此时刚好消费者线程挂掉，那么offset已经提交，但是数据未处理，导致这部分内存中的数据丢失。</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941480.png" alt="image-20230403191629056"></p><hr/><p><strong>如何做到既不漏消费也不重复消费？看下节消费者事务</strong></p><blockquote><p><strong>如果面试官问：如何做到数据的精确一次性消费？</strong></p><p>那么需要从以下方面回答：</p><ul><li>生产端 —&gt;  Kafka集群</li><li>Kafka集群  —&gt;  消费者端</li><li>消费者端  —&gt;  下游框架</li></ul><p>只有上述三个环节都不出现问题，才能做到精确一次性消费数据。</p></blockquote><h3 id="生产经验——消费者事务">生产经验——消费者事务</h3><p>如果想完成Consumer端的精准一次性消费，那么需要**<code>Kafka</code>消费端将消费过程和提交<code>offset</code>过程做原子绑定**。此时我们需要将<code>Kafka</code>的<code>offset</code>保存到支持事务的自定义介质（比如MySQL)。这部分知识会在后续项目部分涉及。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941481.png" alt="image-20230403192200304"></p><h3 id="生产经验——数据积压（消费者如何提高吞吐量）">生产经验——数据积压（消费者如何提高吞吐量）</h3><p>出现数据积压的原因可能有两种：</p><ul><li><p>如果是 Kafka 消费能力不足，则可以考虑<strong>增加Topic的分区数</strong>，并且<strong>同时提升消费组的消费者<br>数量</strong>，<strong>消费者数=分区数</strong>。（两者缺一不可）</p></li><li><p>如果是下游的数据处理不及时：<strong>提高每批次拉取的数量</strong>。批次拉取数据过少(拉取数据 / 处理时间 &lt; 生产速度)，使处理的数据小于生产的数据，也会造成数据积压。</p></li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202304031941482.png" alt="image-20230403192920675"></p><blockquote><p>大致总结 数据积压的解决办法：</p><ul><li>增加分区、增加消费者个数</li><li>生产端 -&gt; Kafka集群 有4个参数可以调节</li><li>消费端 有2个参数</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka入门 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git入门</title>
      <link href="/2023/03/20/Git/"/>
      <url>/2023/03/20/Git/</url>
      
        <content type="html"><![CDATA[<p>参考尚硅谷视频：<a href="https://www.bilibili.com/video/BV1vy4y1s7k6">https://www.bilibili.com/video/BV1vy4y1s7k6</a></p><p>推荐学习git的网站：<a href="https://learngitbranching.js.org/">https://learngitbranching.js.org/</a></p><h2 id="Git-简介">Git 简介</h2><h3 id="Git-结构">Git 结构</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953474.png" alt="image-20220629191213874"></p><h3 id="Git-和代码托管中心">Git 和代码托管中心</h3><p>代码托管中心是基于网络服务器的远程代码仓库，一般我们简单称为远程库</p><p>代码托管中心的任务：维护远程库</p><ul><li><p>局域网环境下</p><ul><li>GitLab 服务器</li></ul></li><li><p>外网环境下</p><ul><li>GitHub</li><li>码云</li></ul></li></ul><h3 id="本地库和远程库">本地库和远程库</h3><h4 id="团队内部协作">团队内部协作</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953475.png" alt="image-20220415153111217"></p><h4 id="跨团队协作">跨团队协作</h4><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953476.png" alt="image-20220415153150737"></p><h2 id="Git-常用命令">Git 常用命令</h2><table><thead><tr><th style="text-align:left">命令名称</th><th style="text-align:left">作用</th></tr></thead><tbody><tr><td style="text-align:left">git config --global <a href="http://user.name">user.name</a> 用户名</td><td style="text-align:left">设置用户签名</td></tr><tr><td style="text-align:left">git config  --global user.email 邮箱</td><td style="text-align:left">设置用户签名</td></tr><tr><td style="text-align:left">git init</td><td style="text-align:left">初始化本地库</td></tr><tr><td style="text-align:left">git status</td><td style="text-align:left">查看本地库状态</td></tr><tr><td style="text-align:left">git add 文件名</td><td style="text-align:left">添加到暂存区</td></tr><tr><td style="text-align:left">git commit -m “日志信息” 文件名</td><td style="text-align:left">提交到本地库</td></tr><tr><td style="text-align:left">git reflog</td><td style="text-align:left">查看历史记录</td></tr><tr><td style="text-align:left">git reset --hard 版本号</td><td style="text-align:left">版本穿梭</td></tr></tbody></table><h3 id="设置用户签名">设置用户签名</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git config --global user.name 用户名</span><br><span class="line">git config --global user.email 用户名</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/git_test</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git config --global user.name hugh</span></span><br><span class="line"></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/git_test</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git config --global user.email hugh@github.com</span></span><br><span class="line"></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/git_test</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> ~/.gitconfig</span></span><br><span class="line">[user]</span><br><span class="line">        name = hugh</span><br><span class="line">        email = hugh@github.com</span><br></pre></td></tr></table></figure><p>说明：</p><p>​签名的作用是区分不同操作者身份。用户的签名信息在每一个版本的提交信息中能够看到，以此确认本次提交是谁做的。<strong>Git首次安装必须设置一下用户签名，否则无法提交代码</strong>。</p><p><strong>注意：这里设置用户签名和将来登录 GitHub（或其他代码托管中心）的账号没有任何关系</strong>。</p><h3 id="初始化本地库">初始化本地库</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git init</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><p>目前我在这个路径下，准备初始化<code>git-demo</code>作为本地库</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">pwd</span></span></span><br><span class="line">/d/Git-Space/git-demo</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git init<span class="comment"># 执行 git init 命令</span></span></span><br><span class="line">Initialized empty Git repository in D:/Git-Space/git-demo/.git/</span><br><span class="line"></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ll -a</span></span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x 1 H 197121 0 Apr 15 16:01 ./</span><br><span class="line">drwxr-xr-x 1 H 197121 0 Apr 15 15:59 ../</span><br><span class="line">drwxr-xr-x 1 H 197121 0 Apr 15 16:01 .git/# 可以看到这里生成了一个.git目录</span><br></pre></td></tr></table></figure><h3 id="查看本地库状态">查看本地库状态</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><h4 id="首次查看（工作区没有任何文件）">首次查看（工作区没有任何文件）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git status</span></span><br><span class="line">On branch master</span><br><span class="line"></span><br><span class="line">No commits yet</span><br><span class="line"></span><br><span class="line">nothing to commit (create/copy files and use &quot;git add&quot; to track)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="新增文件">新增文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim hello.txt</span></span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br></pre></td></tr></table></figure><h3 id="再次查看（检测到未追踪的文件）">再次查看（检测到未追踪的文件）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git status</span></span><br><span class="line">On branch master</span><br><span class="line"></span><br><span class="line">No commits yet</span><br><span class="line"></span><br><span class="line">Untracked files:</span><br><span class="line">  (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed)</span><br><span class="line">        hello.txt</span><br><span class="line"></span><br><span class="line">nothing added to commit but untracked files present (use &quot;git add&quot; to track)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="添加暂存区">添加暂存区</h3><h4 id="将工作区的文件添加到暂存区">将工作区的文件添加到暂存区</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git add 文件名</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git add hello.txt</span></span><br><span class="line">warning: LF will be replaced by CRLF in hello.txt.</span><br><span class="line">The file will have its original line endings in your working directory</span><br></pre></td></tr></table></figure><h4 id="查看状态（检测到暂存区有新文件）">查看状态（检测到暂存区有新文件）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git status</span></span><br><span class="line">On branch master</span><br><span class="line"></span><br><span class="line">No commits yet</span><br><span class="line"></span><br><span class="line">Changes to be committed:</span><br><span class="line">  (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage)</span><br><span class="line">        new file:   hello.txt</span><br></pre></td></tr></table></figure><p>在上述也可以看到从暂存区中可以删除文件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git rm --cached &lt;file&gt;...</span><br></pre></td></tr></table></figure><h3 id="提交本地库">提交本地库</h3><h4 id="将暂存区的文件提交到本地库">将暂存区的文件提交到本地库</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git commit -m &quot;日志信息&quot; 文件名</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git commit -m <span class="string">&quot;my first commit&quot;</span> hello.txt</span></span><br><span class="line">warning: LF will be replaced by CRLF in hello.txt.</span><br><span class="line">The file will have its original line endings in your working directory</span><br><span class="line">[master (root-commit) 0edf694] my first commit</span><br><span class="line"> 1 file changed, 6 insertions(+)</span><br><span class="line"> create mode 100644 hello.txt</span><br></pre></td></tr></table></figure><p>上述信息可以看到版本号为<code>0edf694</code></p><h4 id="查看状态（没有文件需要提交）">查看状态（没有文件需要提交）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git status</span></span><br><span class="line">On branch master</span><br><span class="line">nothing to commit, working tree clean</span><br></pre></td></tr></table></figure><p>利用<code>git reflog</code>命令还可以查看到历史记录</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git reflog</span></span><br><span class="line">0edf694 (HEAD -&gt; master) HEAD@&#123;0&#125;: commit (initial): my first commit</span><br></pre></td></tr></table></figure><p>还可以利用<code>git log</code>查看详细提交记录</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">log</span></span></span><br><span class="line">commit 0edf694313bbfe56763790f96914726913d7a793 (HEAD -&gt; master)</span><br><span class="line">Author: hugh &lt;hugh@github.com&gt;</span><br><span class="line">Date:   Fri Apr 15 16:18:49 2022 +0800</span><br><span class="line"></span><br><span class="line">    my first commit</span><br></pre></td></tr></table></figure><h3 id="修改文件（hello-txt）">修改文件（hello.txt）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim hello.txt</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br></pre></td></tr></table></figure><h4 id="查看状态（检测到工作区有文件被修改）">查看状态（检测到工作区有文件被修改）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git status</span></span><br><span class="line">On branch master</span><br><span class="line">Changes not staged for commit:</span><br><span class="line">  (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)</span><br><span class="line">  (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory)</span><br><span class="line">        modified:   hello.txt</span><br><span class="line"></span><br><span class="line">no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)</span><br></pre></td></tr></table></figure><h4 id="将修改的文件再次添加到暂存区">将修改的文件再次添加到暂存区</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git add hello.txt</span></span><br><span class="line">warning: LF will be replaced by CRLF in hello.txt.</span><br><span class="line">The file will have its original line endings in your working directory</span><br></pre></td></tr></table></figure><h4 id="查看状态（工作区的修改添加到了暂存区）">查看状态（工作区的修改添加到了暂存区）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git status</span></span><br><span class="line">On branch master</span><br><span class="line">Changes to be committed:</span><br><span class="line">  (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage)</span><br><span class="line">        modified:   hello.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="提交到本地库">提交到本地库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git commit -m <span class="string">&quot;second commit&quot;</span> hello.txt</span></span><br><span class="line">warning: LF will be replaced by CRLF in hello.txt.</span><br><span class="line">The file will have its original line endings in your working directory</span><br><span class="line">[master 79817c0] second commit</span><br><span class="line"> 1 file changed, 1 insertion(+), 1 deletion(-)</span><br></pre></td></tr></table></figure><h3 id="历史版本">历史版本</h3><h4 id="查看历史版本">查看历史版本</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git reflog # 查看版本信息</span><br><span class="line">git log# 查看版本详细信息</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git reflog</span></span><br><span class="line">79817c0 (HEAD -&gt; master) HEAD@&#123;0&#125;: commit: second commit</span><br><span class="line">0edf694 HEAD@&#123;1&#125;: commit (initial): my first commit</span><br></pre></td></tr></table></figure><h4 id="版本穿梭">版本穿梭</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git reset --hard 版本号</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">首先查看当前的历史记录，可以看到当前是在 4bfa3d0 这个版本</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git reflog</span></span><br><span class="line">4bfa3d0 (HEAD -&gt; master) HEAD@&#123;0&#125;: commit: my third commit</span><br><span class="line">79817c0 HEAD@&#123;1&#125;: commit: second commit</span><br><span class="line">0edf694 HEAD@&#123;2&#125;: commit (initial): my first commit</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切换到 0edf694 版本，也就是第一次提交的版本</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git reset --hard 0edf694</span></span><br><span class="line">HEAD is now at 0edf694 my first commit</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切换完毕后，再查看历史记录，当前成功切换到了 0edf694 版本</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git reflog</span></span><br><span class="line">0edf694 (HEAD -&gt; master) HEAD@&#123;0&#125;: reset: moving to 0edf694</span><br><span class="line">4bfa3d0 HEAD@&#123;1&#125;: commit: my third commit</span><br><span class="line">79817c0 HEAD@&#123;2&#125;: commit: second commit</span><br><span class="line">0edf694 (HEAD -&gt; master) HEAD@&#123;3&#125;: commit (initial): my first commit</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">然后查看文件hello.txt，发现文件内容已经发生变化</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> hello.txt</span></span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br></pre></td></tr></table></figure><p>Git 切换版本，底层其实是移动的 HEAD 指针，具体原理如下图所示。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953477.png" alt="image-20220415165114362"></p><h2 id="Git-分支操作">Git 分支操作</h2><h3 id="什么是分支">什么是分支</h3><p>在版本控制过程中，同时推进多个任务，为每个任务，我们就可以创建每个任务的单独分支。使用分支意味着程序员可以把自己的工作从开发主线上分离开来，开发自己分支的时 候，不会影响主线分支的运行。对于初学者而言，分支可以简单理解为副本，一个分支就是一个单独的副本。（分支底层其实也是指针的引用）</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953478.png" alt="image-20220415165338990"></p><h3 id="分支的好处">分支的好处</h3><p>同时并行推进多个功能开发，提高开发效率。</p><p>各个分支在开发过程中，如果某一个分支开发失败，不会对其他分支有任何影响。失败 的分支删除重新开始即可。</p><h3 id="分支的操作">分支的操作</h3><table><thead><tr><th>命令名称</th><th>作用</th></tr></thead><tbody><tr><td>git branch 分支名</td><td>创建分支</td></tr><tr><td>git branch -v</td><td>查看分支</td></tr><tr><td>git checkout 分支名</td><td>切换分支</td></tr><tr><td>git merge 分支名</td><td>把指定的分支合并到当前分支上</td></tr></tbody></table><h4 id="查看分支">查看分支</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git branch -v</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git branch -v</span></span><br><span class="line">* master 4bfa3d0 my third commit# * 代表当前所在的分区</span><br></pre></td></tr></table></figure><h4 id="创建分支">创建分支</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git branch 分支名</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个分支 hot-fix</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git branch hot-fix</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看分支</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git branch -v</span></span><br><span class="line">  hot-fix 4bfa3d0 my third commit</span><br><span class="line">* master  4bfa3d0 my third commit</span><br></pre></td></tr></table></figure><h4 id="修改分支">修改分支</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在 master 分支上做修改</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim hello.txt</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!3333333333</span><br><span class="line">hello git! hello world!4444</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加暂存区</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git add hello.txt</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提交本地库</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git commit -m <span class="string">&quot;my forth commit&quot;</span> hello.txt</span></span><br><span class="line">[master 5e67e51] my forth commit</span><br><span class="line"> 1 file changed, 1 insertion(+)</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">查看分支，可以发现 hot-fix 分支并未做出改变，而当前 master 分支已更新为最新一次提交的版本</span></span><br><span class="line"> H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git branch -v</span></span><br><span class="line">  hot-fix 4bfa3d0 my third commit</span><br><span class="line">* master  5e67e51 my forth commit</span><br></pre></td></tr></table></figure><h4 id="切换分支">切换分支</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git checkout 分支名</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git checkout hot-fix</span></span><br><span class="line">Switched to branch &#x27;hot-fix&#x27;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切换分支后，可以发现当前分支已由 master 改成 hot-fix</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (hot-fix)</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># 查看 hot-fix 分支上的文件内容，发现与master分支上的内容不同</span></span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (hot-fix)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> hello.txt</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!</span><br><span class="line">hello git! hello world!3333333333</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在hot-fix 分支上做修改</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (hot-fix)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim hello.txt</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world!3333333333</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加暂存区</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (hot-fix)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git add hello.txt</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提交本地库</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (hot-fix)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git commit -m <span class="string">&quot;hot-fix commit&quot;</span> hello.txt</span></span><br><span class="line">[hot-fix b1578cb] hot-fix commit</span><br><span class="line"> 1 file changed, 3 insertions(+), 3 deletions(-)</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">查看分支</span></span><br><span class="line"> H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (hot-fix)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git branch -v</span></span><br><span class="line">* hot-fix b1578cb hot-fix commit</span><br><span class="line">  master  5e67e51 my forth commit</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="合并分支">合并分支</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git merge 分支名</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操 在master分支上合并hot-fix分支</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git merge hot-fix</span></span><br><span class="line">Auto-merging hello.txt</span><br><span class="line">Merge made by the &#x27;ort&#x27; strategy.</span><br><span class="line"> hello.txt | 6 +++---</span><br><span class="line"> 1 file changed, 3 insertions(+), 3 deletions(-)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">合并完成后，查看文件状态</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> hello.txt</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world!3333333333</span><br><span class="line">hello git! hello world!4444</span><br></pre></td></tr></table></figure><h4 id="产生冲突">产生冲突</h4><p>什么时候会遇到冲突？</p><blockquote><p>冲突产生的原因：</p><p>合并分支时，<strong>两个分支在同一个文件的同一个位置有两套完全不同的修改</strong>。Git 无法替 我们决定使用哪一个。必须人为决定新代码内容。</p></blockquote><p>案例实操：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先查看下当前master分支上的hello.txt</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> hello.txt</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world!3333333333</span><br><span class="line">hello git! hello world!4444</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在查看 hot-fix 分支上的hello.txt</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (hot-fix)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> hello.txt</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world!3333333333</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切换回 master 分支，修改hello.txt</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim hello.txt</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! master master</span><br><span class="line">hello git! hello world!3333333333</span><br><span class="line">hello git! hello world!4444</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加到暂存区，并提交到本地库</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git add hello.txt</span></span><br><span class="line"></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git commit -m <span class="string">&quot;master test&quot;</span> hello.txt</span></span><br><span class="line">[master 276bd41] master test</span><br><span class="line"> 1 file changed, 1 insertion(+), 1 deletion(-)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切换到hot-fix 并 修改hello.txt</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git checkout hot-fix</span></span><br><span class="line">Switched to branch &#x27;hot-fix&#x27;</span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (hot-fix)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim hello.txt</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world!555555555</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加到暂存库并提交到本地库</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (hot-fix)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git add hello.txt</span></span><br><span class="line"></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (hot-fix)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git commit -m <span class="string">&quot;hot-fix test&quot;</span> hello.txt</span></span><br><span class="line">[hot-fix 75486df] hot-fix test</span><br><span class="line"> 1 file changed, 1 insertion(+), 1 deletion(-)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切换回 master 分支</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (hot-fix)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git checkout master</span></span><br><span class="line">Switched to branch &#x27;master&#x27;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在 master 分支上合并 hot-fix 分支。（注意下面会报错！）</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git merge hot-fix</span></span><br><span class="line">Auto-merging hello.txt</span><br><span class="line">CONFLICT (content): Merge conflict in hello.txt</span><br><span class="line">Automatic merge failed; fix conflicts and then commit the result.</span><br><span class="line"></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master|MERGING)</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># 查看文件</span></span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master|MERGING)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> hello.txt</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</span><br><span class="line">hello git! hello world! master master</span><br><span class="line">hello git! hello world!3333333333</span><br><span class="line">hello git! hello world!4444</span><br><span class="line">=======</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world!555555555</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;&gt;&gt;&gt;&gt; hot-fix</span></span><br></pre></td></tr></table></figure><p>查看状态（检测到有文件有两处修改）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master|MERGING)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git status</span></span><br><span class="line">On branch master</span><br><span class="line">You have unmerged paths.</span><br><span class="line">  (fix conflicts and run &quot;git commit&quot;)</span><br><span class="line">  (use &quot;git merge --abort&quot; to abort the merge)</span><br><span class="line"></span><br><span class="line">Unmerged paths:</span><br><span class="line">  (use &quot;git add &lt;file&gt;...&quot; to mark resolution)</span><br><span class="line">        both modified:   hello.txt</span><br><span class="line"></span><br><span class="line">no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="解决冲突">解决冲突</h4><ol><li>编辑有冲突的文件，删除特殊符号，决定要使用的内容</li></ol><p>特殊符号：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD </span><br><span class="line">当前分支的代码 </span><br><span class="line">======= </span><br><span class="line">合并过来的代码 </span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;&gt;&gt;&gt; hot-fix</span></span><br></pre></td></tr></table></figure><p>手动合并代码，从而解决冲突：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打开文件</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master|MERGING)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim hello.txt</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</span><br><span class="line">hello git! hello world! master master</span><br><span class="line">hello git! hello world!3333333333</span><br><span class="line">hello git! hello world!4444</span><br><span class="line">=======</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world!555555555</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;&gt;&gt;&gt;&gt; hot-fix</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改文件, 留下两个文件中想要的内容</span></span><br><span class="line">hello git! hello world!22222222222</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! hot-fix</span><br><span class="line">hello git! hello world! master master</span><br><span class="line">hello git! hello world!4444</span><br><span class="line">hello git! hello world!555555555</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加到暂存区</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master|MERGING)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git add hello.txt</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行提交（注意：此时使用 git commit 命令时不能带文件名）</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master|MERGING)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git commit -m <span class="string">&quot;merge_hot-fix&quot;</span></span></span><br><span class="line">[master 35dfbd6] merge_hot-fix</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">发现后面的 (master|MERGING) 变为了 (master)</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"></span></span><br></pre></td></tr></table></figure><h2 id="Git-团队协作机制">Git 团队协作机制</h2><h3 id="团队内协作">团队内协作</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953479.png" alt="image-20220415193420004"></p><h3 id="跨团队协作-2">跨团队协作</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953480.png" alt="image-20220415193451917"></p><h2 id="GitHub-操作">GitHub 操作</h2><p>GitHub 网址：<a href="https://github.com/">https://github.com/</a></p><h3 id="本地git-绑定-github账号">本地git 绑定 github账号</h3><ol><li>在本地git中，输入命令</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &#x27;账号&#x27;</span><br></pre></td></tr></table></figure><p>如：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953481.png" alt="image-20220415201127429"></p><p>会生成如下密钥</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953482.png" alt="image-20220415201504020"></p><ol start="2"><li><p>按照路径找到对应的<code>id_rsa.pub</code>文件，复制里面的数据</p></li><li><p>在github中添加新的ssh密钥</p></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953483.png" alt="image-20220415201652546"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953484.png" alt="image-20220415201801995"></p><ol start="4"><li>测试是否绑定成功</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ssh -T git@github.com</span></span><br><span class="line">Hi hugh-98! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.</span><br></pre></td></tr></table></figure><h3 id="创建远程仓库">创建远程仓库</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953485.png" alt="image-20220415194614585"></p><p>注：<strong>远程仓库名最好跟本地仓库名一致！</strong></p><p>我这里使用<code>git-demo</code>这个名好了</p><p>创建完成后，会有如下指引信息！</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953486.png" alt="image-20220415195055683"></p><p><a href="https://github.com/hugh-98/git-demo.git">https://github.com/hugh-98/git-demo.git</a></p><h3 id="远程仓库操作">远程仓库操作</h3><table><thead><tr><th>命令名称</th><th>作用</th></tr></thead><tbody><tr><td>git remote -v</td><td>查看当前所有远程地址别名</td></tr><tr><td>git remote add 别名 远程地址</td><td>起别名</td></tr><tr><td>git push 别名 分支</td><td>推送本地分支上的内容到远程仓库</td></tr><tr><td>git clone 远程地址</td><td>将远程仓库的内容克隆到本地</td></tr><tr><td>git pull 远程库地址别名 远程分支名</td><td>将远程仓库对于分支最新内容拉下来后与当前本地分支直接合并</td></tr></tbody></table><h4 id="创建远程仓库别名">创建远程仓库别名</h4><p>创建远程仓库别名 是因为：远程仓库的地址太长了，记不住，所以要取一个别名</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote -v # 查看当前所有远程地址别名</span><br><span class="line">git remote add 别名 远程地址</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git remote -v</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">起别名</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git remote add git-demo https://github.com/hugh-98/git-demo.git</span></span><br><span class="line"></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git remote -v</span></span><br><span class="line">git-demo        https://github.com/hugh-98/git-demo.git (fetch)</span><br><span class="line">git-demo        https://github.com/hugh-98/git-demo.git (push)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="推送本地分支到远程仓库">推送本地分支到远程仓库</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git push 别名 分支</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git push git-demo master</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果是在本地没有登录过github账号，则会出现这个，提示需要登录github</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953487.png" alt="image-20220415200438509"></p><p>这里可以先使用 本地git绑定 github 账号，然后再在这个界面登录一下<code>Sign in with your browser</code></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">推送本地分支到远程仓库</span></span><br><span class="line">H@DESKTOP-7CK6BAS MINGW64 /d/Git-Space/git-demo (master)</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git push git-demo master</span></span><br><span class="line">warning: ----------------- SECURITY WARNING ----------------</span><br><span class="line">warning: | TLS certificate verification has been disabled! |</span><br><span class="line">warning: ---------------------------------------------------</span><br><span class="line">warning: HTTPS connections may not be secure. See https://aka.ms/gcm/tlsverify for more information.</span><br><span class="line">warning: ----------------- SECURITY WARNING ----------------</span><br><span class="line">warning: | TLS certificate verification has been disabled! |</span><br><span class="line">warning: ---------------------------------------------------</span><br><span class="line">warning: HTTPS connections may not be secure. See https://aka.ms/gcm/tlsverify for more information.</span><br><span class="line">Enumerating objects: 27, done.</span><br><span class="line">Counting objects: 100% (27/27), done.</span><br><span class="line">Delta compression using up to 16 threads</span><br><span class="line">Compressing objects: 100% (18/18), done.</span><br><span class="line">Writing objects: 100% (27/27), 2.01 KiB | 2.01 MiB/s, done.</span><br><span class="line">Total 27 (delta 8), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Resolving deltas: 100% (8/8), done.</span><br><span class="line">To https://github.com/hugh-98/git-demo.git</span><br><span class="line"> * [new branch]      master -&gt; master</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>推送成功</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953488.png" alt="image-20220415202432055"></p><h4 id="克隆远程仓库到本地">克隆远程仓库到本地</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone 远程地址</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/hugh-98/git-demo.git</span><br></pre></td></tr></table></figure><p>小结：clone 会做如下操作。1、拉取代码。2、初始化本地仓库。3、创建别名</p><h4 id="拉取远程库内容">拉取远程库内容</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git pull 远程库地址别名 远程分支名</span><br></pre></td></tr></table></figure><h4 id="邀请加入团队">邀请加入团队</h4><ol><li>选择邀请合作者</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953489.png" alt="image-20220417141018689"></p><ol start="2"><li>填入想要合作的人</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953490.png" alt="image-20220417142154294"></p><ol start="3"><li>复制地址并通过微信或者钉钉等方式发送给该用户</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953491.png" alt="image-20220417142314436"></p><ol start="4"><li>在 atguigulinghuchong 这个账号中的地址栏复制收到邀请的链接，点击接受邀请。</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953492.png" alt="image-20220417142401917"></p><ol start="5"><li>成功之后可以在 atguigulinghuchong这个账号上看到 这个账号上看到 git-Test的</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953493.png" alt="image-20220417142440636"></p><h3 id="跨团队协作-3">跨团队协作</h3><ol><li>将远程仓库的地址复制发给邀请跨团队协作的人，比如东方不败。</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953494.png" alt="image-20220417142622218"></p><ol start="2"><li>在东方不败的 GitHub 账号里的地址栏复制收到的链接，然后点击 Fork 将项目叉到自<br>己的本地仓库。</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953495.png" alt="image-20220417142707597"></p><p>叉成功后可以看到当前仓库信息。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953496.png" alt="image-20220417142724437"></p><ol start="3"><li>东方不败就可以在线编辑叉取过来的文件。</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953497.png" alt="image-20220417142753694"></p><ol start="4"><li>编辑完毕后，填写描述信息并点击左下角绿色按钮提交。</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953498.png" alt="image-20220417142902597"></p><ol start="5"><li>接下来点击上方的 接下来点击上方的 Pull请求 ，并创建一个新的请求 。</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953499.png" alt="image-20220417143536003"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953500.png" alt="image-20220417143634886"></p><ol start="6"><li>回到岳岳 GitHub 账号可以看到有一个 Pull request 请求。</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953501.png" alt="image-20220417143701473"></p><p>进入到聊天室，可以讨论代码相关内容。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953502.png" alt="image-20220417144247761"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953503.png" alt="image-20220417144253535"></p><ol start="7"><li>如果代码没有问题，可以点击 Merge pull reque 合并代码。</li></ol><h2 id="IDEA-集成-Git">IDEA 集成 Git</h2><h3 id="配置-Git-忽略文件">配置 Git 忽略文件</h3><ol><li>IDEA 特定文件</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953504.png" alt="image-20220417145325508"></p><ol start="2"><li>Maven 工程的 target 目录</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953505.png" alt="image-20220417145347825"></p><p>问题 1:为什么要忽略他们？<br>答：与项目的实际功能无关，不参与服务器上部署运行。把它们忽略掉能够屏蔽 IDE 工具之 间的差异。</p><p>问题 2：怎么忽略？<br>1）创建忽略规则文件 xxxx.ignore（前缀名随便起，建议是 git.ignore） 这个文件的存放位置原则上在哪里都可以，为了便于让~/.gitconfig 文件引用，建议也放在用<br>户家目录下</p><p>git.ignore 文件模板内容如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Compiled class file</span></span><br><span class="line">*.class</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Log file</span></span><br><span class="line">*.log</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">BlueJ files</span></span><br><span class="line">*.ctxt</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Mobile Tools <span class="keyword">for</span> Java (J2ME)</span></span><br><span class="line">.mtj.tmp/</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Package Files <span class="comment">#</span></span></span><br><span class="line">*.jar</span><br><span class="line">*.war</span><br><span class="line">*.nar</span><br><span class="line">*.ear</span><br><span class="line">*.zip</span><br><span class="line">*.tar.gz</span><br><span class="line">*.rar</span><br><span class="line"></span><br><span class="line">hs_err_pid*</span><br><span class="line"></span><br><span class="line">.classpath</span><br><span class="line">.project</span><br><span class="line">.settings</span><br><span class="line">target</span><br><span class="line">.idea</span><br><span class="line">*.iml</span><br></pre></td></tr></table></figure><h3 id="定位-Git-程序">定位 Git 程序</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953506.png" alt="image-20220417154623248"></p><h3 id="初始化本地库-2">初始化本地库</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953507.png" alt="image-20220417155730650"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953508.png" alt="image-20220417155829626"></p><h3 id="添加到暂存区">添加到暂存区</h3><p>右键点击项目 选择 Git -&gt; Add 将项目添加到暂存区</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953509.png" alt="image-20220417160044266"></p><h3 id="提交到本地库-2">提交到本地库</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953510.png" alt="image-20220417161255698"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953511.png" alt="image-20220417161329736"></p><p>提交后，可以在 IDEA 最下面看到</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953512.png" alt="image-20220417161523434"></p><h3 id="切换版本">切换版本</h3><p>在 IDEA 的最下面可以查看版本信息</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953513.png" alt="image-20220417163738481"></p><p>右键可以选择要切换的版本</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953514.png" alt="image-20220417163831408"></p><p>切换后，如下所示。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953515.png" alt="image-20220417164015159"></p><h3 id="创建分支-2">创建分支</h3><ol><li>创建分支</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953516.png" alt="image-20220417165204359"></p><ol start="2"><li>填写分支名</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953517.png" alt="image-20220417165344143"></p><ol start="3"><li>切换回 master 分支</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953518.png" alt="image-20220417165709960"></p><h3 id="合并分支-2">合并分支</h3><h4 id="正常合并（无冲突）">正常合并（无冲突）</h4><ol><li>假设 master 分支中，只有如下内容</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953519.png" alt="image-20220417170144663"></p><ol start="2"><li>假设 hot-fix 分支中，只有如下内容</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953520.png" alt="image-20220417170216253"></p><ol start="3"><li>将 hot-fix 分支 合并到 master。<ol><li>先切换到 master 分支</li><li>找到 hot-fix ，点击右键，找到 Merge Selected into Current</li></ol></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953521.png" alt="image-20220417170409567"></p><ol start="4"><li>合并成功</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953522.png" alt="image-20220417170529502"></p><h4 id="非正常合并（存在冲突）">非正常合并（存在冲突）</h4><ol><li>假设 master 分支上的内容如下，</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953523.png" alt="image-20220417170914439"></p><ol start="2"><li>假设 hot-fix 分支上的内容如下</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953524.png" alt="image-20220417170812934"></p><ol start="3"><li>可以看到目前各个已提交节点的状态</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953525.png" alt="image-20220417171101134"></p><ol start="4"><li>尝试将 hot-fix 分支 合并到 master 分支上。会发现合并时会出现以下提示框。点击 <code>Merge</code> ，可以手动选择合并 冲突的代码。</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953526.png" alt="image-20220417171228840"></p><ol start="5"><li>上述 点击 <code>Merge</code> 按钮后，会出现以下界面</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953527.png" alt="image-20220417171802896"></p><ol start="6"><li>假设，我保留 hot-fix 这行代码，去除 master 的那行代码，弄好后，点击 <code>Apply</code>按钮，则会自动合并两个分支。</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953528.png" alt="image-20220417171958510"></p><h2 id="IDEA-集成-GitHub">IDEA 集成 GitHub</h2><h3 id="设置-GitHub-账号">设置 GitHub 账号</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953529.png" alt="image-20220417191332198"></p><h3 id="分享工程到-GitHub">分享工程到 GitHub</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953530.png" alt="image-20220417191717446"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953531.png" alt="image-20220417191812431"></p><h3 id="push-pull">push &amp; pull</h3><p>右键点击项目，可以将当前分支的内容 push 到 GitHub 的远程仓库中，也可以把最新的远程库代码pull到本地库。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953532.png" alt="image-20220417193538177"></p><h3 id="clone-克隆远程库到本地">clone 克隆远程库到本地</h3><ol><li>打开IDEA，点击 <code>Gt from CVS</code></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953533.png" alt="image-20220417201059181"></p><ol start="2"><li></li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201953534.png" alt="image-20220417201353827"></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Shell编程</title>
      <link href="/2023/03/15/Shell%E7%BC%96%E7%A8%8B/"/>
      <url>/2023/03/15/Shell%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="Shell-概述">Shell 概述</h2><p>Shell是一个命令行解释器，它接收应用程序/用户命令，然后调用操作系统内核。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201657000.png" alt="image-20230315205036877"></p><ol><li>Linux提供的Shell解释器有：</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# cat /etc/shells</span><br><span class="line">/bin/sh</span><br><span class="line">/bin/bash</span><br><span class="line">/usr/bin/sh</span><br><span class="line">/usr/bin/bash</span><br></pre></td></tr></table></figure><ol start="2"><li>bash和sh的关系</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201657002.png" alt="image-20230315205526110"></p><ol start="3"><li>centos默认的解析器是 bash</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# echo $SHELL</span><br><span class="line">/bin/bash</span><br></pre></td></tr></table></figure><h2 id="Shell-脚本入门">Shell 脚本入门</h2><ol><li>脚本格式</li></ol><p>脚本需要以<code>#!/bin/bash</code>开头（指定解析器的意思）</p><ol start="2"><li>制作第一个Shell脚本：<a href="http://helloworld.sh">helloworld.sh</a></li></ol><ul><li>需求：创建一个Shell脚本，输出helloworld</li><li>案例</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# touch helloworld.sh</span><br><span class="line">[root@centos_01 ~]# vim helloworld.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">echo &quot;helloworld&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>脚本的常用的执行方式：</li></ul><p>1）采用bash或sh+脚本的相对路径或绝对路径（可以不用赋予脚本+x权限）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# bash helloworld.sh</span><br><span class="line">helloworld</span><br></pre></td></tr></table></figure><p>2）采用输入脚本的绝对路径或相对路径执行脚本（<strong>必须具有可执行权限+x</strong>）</p><p>一、首先要赋予<code>helloworld.sh</code>脚本的+x权限</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod +x helloworld.sh</span><br></pre></td></tr></table></figure><p>二、执行脚本</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">相对路径</span></span><br><span class="line">[root@centos_01 scripts]# ./helloworld.sh</span><br><span class="line">helloworld</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">绝对路径</span></span><br><span class="line">[root@centos_01 scripts]# /root/scripts/helloworld.sh</span><br><span class="line">helloworld</span><br></pre></td></tr></table></figure><h2 id="变量">变量</h2><h3 id="系统预定义变量">系统预定义变量</h3><ol><li><p>常用系统变量</p><p><code>$HOME</code>、<code>$PWD</code>、<code>$SHELL</code>、<code>$USER</code>等</p></li><li><p>案例实操</p></li></ol><ul><li>查看系统变量的值</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# echo $HOME</span><br><span class="line">/root</span><br></pre></td></tr></table></figure><ul><li>显示当前Shell中所有变量：set</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# set</span><br><span class="line">BASH=/bin/bash</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><h3 id="自定义变量">自定义变量</h3><ol><li>基本语法</li></ol><ul><li><p>定义变量：变量名=变量值。（注意：<code>=</code>号前后不能有空格）</p></li><li><p>撤销变量：unset 变量名</p></li><li><p>声明静态变量：readonly 变量。（注意：不能unset）</p></li></ul><ol start="2"><li>变量定义规则</li></ol><ul><li><p>变量名称可以由字母、数字和下划线组成，但是不能以数字开头。<strong>环境变量名建议大写</strong></p></li><li><p>等号两侧不能有空格</p></li><li><p>在<code>bash</code>中，变量默认类型都是字符串类型，无法直接进行数值运算</p></li><li><p>变量的值如果有空格，需要使用双引号或单引号括起来</p></li></ul><ol start="3"><li>例子</li></ol><ul><li>定义变量A</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# A=5</span><br><span class="line">[root@centos_01 scripts]# echo $A</span><br><span class="line">5</span><br></pre></td></tr></table></figure><ul><li>给变量A重新赋值</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# A=8</span><br><span class="line">[root@centos_01 scripts]# echo $A</span><br><span class="line">8</span><br></pre></td></tr></table></figure><ul><li>撤销变量A</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# unset A</span><br><span class="line">[root@centos_01 scripts]# echo $A</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>声明静态的变量B=2，不能unset</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# readonly B=2</span><br><span class="line">[root@centos_01 scripts]# echo $B</span><br><span class="line">2</span><br><span class="line"></span><br><span class="line">[root@centos_01 scripts]# B=9</span><br><span class="line">-bash: B: readonly variable</span><br><span class="line"></span><br><span class="line">[root@centos_01 scripts]# unset $B</span><br><span class="line">-bash: unset: `2&#x27;: not a valid identifier</span><br></pre></td></tr></table></figure><ul><li>在bash中，变量默认类型都是字符串类型，无法直接进行数值运算</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# C=1+2</span><br><span class="line">[root@centos_01 scripts]# echo $C</span><br><span class="line">1+2</span><br></pre></td></tr></table></figure><ul><li>变量的值如果有空格，需要使用双引号或单引号括起来</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# D=Hello World</span><br><span class="line">-bash: World: command not found</span><br><span class="line"></span><br><span class="line">[root@centos_01 scripts]# D=&quot;Hello World&quot;</span><br><span class="line">[root@centos_01 scripts]# echo $D</span><br><span class="line">Hello World</span><br></pre></td></tr></table></figure><ul><li>可把变量提升为全局环境变量，可供其他Shell程序使用</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# export D</span><br><span class="line">[root@centos_01 scripts]# vim helloworld.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">echo &quot;helloworld&quot;</span><br><span class="line">echo $D</span><br><span class="line">[root@centos_01 scripts]# bash helloworld.sh</span><br><span class="line">helloworld</span><br><span class="line">Hello World</span><br></pre></td></tr></table></figure><h3 id="特殊变量">特殊变量</h3><h4 id="n"><code>$n</code></h4><ol><li>基本语法</li></ol><p><code>$n</code>：n为数字，<code>$0</code>代表该脚本名称，<code>$1</code>-<code>$9</code>代表第一到第九个参数，十以上的参数需要使用大括号包含，如<code>$&#123;10&#125;</code></p><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# touch parameter.sh</span><br><span class="line">[root@centos_01 scripts]# vim parameter.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">echo &#x27;=======================$n==============&#x27;</span><br><span class="line">echo $0</span><br><span class="line">echo $1</span><br><span class="line">echo $2</span><br><span class="line"></span><br><span class="line">[root@centos_01 scripts]# chmod 777 parameter.sh</span><br><span class="line">[root@centos_01 scripts]# ./parameter.sh cls xz</span><br><span class="line">=======================$n==============</span><br><span class="line">./parameter.sh</span><br><span class="line">cls</span><br><span class="line">xz</span><br></pre></td></tr></table></figure><h4 id=""><code>$#</code></h4><ol><li>基本语法</li></ol><p><code>$#</code>：获取所有输入参数个数，常用于循环，判断参数的个数是否正确以及加强脚本的健壮性</p><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# vim parameter.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">echo &#x27;=======================$n==============&#x27;</span><br><span class="line">echo $0</span><br><span class="line">echo $1</span><br><span class="line">echo $2</span><br><span class="line">echo &#x27;=======================$#==============&#x27;</span><br><span class="line">echo $#</span><br><span class="line">[root@centos_01 scripts]# ./parameter.sh cls xz</span><br><span class="line">=======================$n==============</span><br><span class="line">./parameter.sh</span><br><span class="line">cls</span><br><span class="line">xz</span><br><span class="line">=======================$#==============</span><br><span class="line">2</span><br></pre></td></tr></table></figure><h4 id="、"><code>$*</code>、<code>$@</code></h4><ol><li>基本语法</li></ol><ul><li><code>$*</code>：这个变量代表命令行中所有的参数，<code>$*</code>把所有的参数看成一个整体</li><li><code>$@</code>：这个变量也代表命令行中所有的参数，不过 <code>$@</code>把每个参数区别对待</li></ul><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# vim parameter.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">echo &#x27;=======================$n==============&#x27;</span><br><span class="line">echo $0</span><br><span class="line">echo $1</span><br><span class="line">echo $2</span><br><span class="line">echo &#x27;=======================$#==============&#x27;</span><br><span class="line">echo $#</span><br><span class="line">echo &#x27;=======================$*=============&#x27;</span><br><span class="line">echo $*</span><br><span class="line">echo &#x27;======================$@=============&#x27;</span><br><span class="line">echo $@</span><br><span class="line">[root@centos_01 scripts]# ./parameter.sh a b c d e f g</span><br><span class="line">=======================$n==============</span><br><span class="line">./parameter.sh</span><br><span class="line">a</span><br><span class="line">b</span><br><span class="line">=======================$#==============</span><br><span class="line">7</span><br><span class="line">=======================$*=============</span><br><span class="line">a b c d e f g</span><br><span class="line">======================$@=============</span><br><span class="line">a b c d e f g</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="-2"><code>$?</code></h4><ol><li>基本语法</li></ol><p><code>$?</code>：最后一次执行的命令的返回状态。如果这个变量的值为0，证明上一个命令正确执行；如果这个变量的值为非0（具体是哪个数，由命令自己来决定），则证明上一个命令执行不正确了。</p><blockquote><p>Shell 中 0 表示真，非0表示假</p></blockquote><ol start="2"><li>案例实操</li></ol><p>判断helloworld.sh脚本是否正确执行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# ./helloword.sh</span><br><span class="line">hello world</span><br><span class="line">[root@centos_01 scripts]# echo $?</span><br><span class="line">0</span><br></pre></td></tr></table></figure><h3 id="单引号与双引号的区别">单引号与双引号的区别</h3><p>定义字符串变量有三种方式，分别是双引号、单引号与无引号。如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# str1=&quot;testString&quot;# 双引号 定义变量</span><br><span class="line">[root@centos_01 scripts]# str2=&#x27;testString&#x27;# 单引号 定义变量</span><br><span class="line">[root@centos_01 scripts]# str3=testString# 无引号 定义变量</span><br><span class="line"></span><br><span class="line">[root@centos_01 scripts]# set | grep str   # 从中可以看到目前定义的都是一样的</span><br><span class="line">str1=testString</span><br><span class="line">str2=testString</span><br><span class="line">str3=testString</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="单引号">单引号</h4><p>单引号定义字符串所见即所得，即将单引号内的内容原样输出，或者描述为单引号里面看到的是什么就会输出什么。单引号是全引用，被单引号括起的内容不管是常量还是变量都不会发生替换。</p><blockquote><p>简单来说：在单引号中的内容 就是一个字符串</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# echo &#x27;$str1&#x27;</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">str1</span></span><br></pre></td></tr></table></figure><h4 id="双引号">双引号</h4><p>双引号引用的内容，所见非所得。<strong>如果内容中有命令、变量等，会先把变量、命令解析出结果，然后在输出最终内容</strong>。双引号是部分引用，被双引号括起的内容常量还是常量，变量则会发生替换，替换成变量内容。</p><blockquote><p>简单来说：在双引号中的内容，如果含有一些变量等信息，则会替换成变量内容，然后再输出</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# echo &quot;$str1&quot;</span><br><span class="line">testString</span><br></pre></td></tr></table></figure><h4 id="无引号">无引号</h4><p>不使用引号定义字符串时，字符串不能包含空白字符（如Space或Tab），需要该加引号，一般连续的字符串，数字，路径等可以不加引号。如果内容中有命令、变量等，会先把变量、命令解析出结果，然后在输出最终内容。</p><blockquote><p>简单来说：在无引号中的内容，不能包含空白字符。若内容中有变量等信息，也可以替换成变量内容，然后再输出。</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# echo $str1</span><br><span class="line">testString</span><br></pre></td></tr></table></figure><h2 id="运算符">运算符</h2><ol><li>基本语法</li></ol><p><code>$((运算式))</code> 或 <code>$[运算式]</code></p><ol start="2"><li>案例实操</li></ol><ul><li>计算（2+3）*4 的值</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# S=$[(2+3)*4]</span><br><span class="line">[root@centos_01 scripts]# echo $S</span><br><span class="line">20</span><br></pre></td></tr></table></figure><ul><li>加法器</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# vim add.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">A=$1</span><br><span class="line">B=$2</span><br><span class="line">echo $[A+B]</span><br><span class="line">[root@centos_01 scripts]# bash add.sh 2 3</span><br><span class="line">5</span><br></pre></td></tr></table></figure><h2 id="条件判断">条件判断</h2><ol><li>基本语法</li></ol><ul><li><code>test</code> 条件表达式</li><li>[ 条件表达式 ]（<strong>注意表达式前后要有空格</strong>）</li><li>也可以使用 ((条件表达式))。在其中，小于可以使用<code>&lt;</code>符号代替</li></ul><ol start="2"><li>常用判断条件</li></ol><ul><li>两个整数之间比较</li></ul><table><thead><tr><th>判断条件</th></tr></thead><tbody><tr><td><code>-eq</code> 等于（equal）</td></tr><tr><td><code>-ne</code> 不等于（not equal）</td></tr><tr><td><code>-lt</code> 小于（less than）</td></tr><tr><td><code>-le</code> 小于等于（less equal）</td></tr><tr><td><code>-gt</code> 大于（greater than）</td></tr><tr><td><code>-ge</code>大于等于（greater equal）</td></tr></tbody></table><ul><li>按照文件权限进行判断</li></ul><p><code>-r</code> 有读的权限（read）</p><p><code>-w</code> 有写的权限（write）</p><p><code>-x</code>有执行的权限（execute）</p><ul><li>按照文件类型进行判断</li></ul><p><code>-e</code>：文件存在（existence）</p><p><code>-f</code>：文件存在并且是一个常规的文件（file）</p><p><code>-d</code>：文件存在并且是一个目录（directory）</p><ol start="3"><li>案例实操</li></ol><ul><li>检测23是否大于等于22</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# test 23 -ge 22</span><br><span class="line">[root@centos_01 scripts]# echo $?</span><br><span class="line">0# 0 说明之前测试通过即为true，1说明之前测试没通过即为false</span><br><span class="line">[root@centos_01 scripts]# test 22 -ge 23</span><br><span class="line">[root@centos_01 scripts]# echo $?</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line">[root@centos_01 scripts]# [ 23 -ge 22 ]</span><br><span class="line">[root@centos_01 scripts]# echo $?</span><br><span class="line">0</span><br></pre></td></tr></table></figure><ul><li>检测<code>helloworld.sh</code>是否具有写权限</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# [ -w ./helloword.sh ]</span><br><span class="line">[root@centos_01 scripts]# echo $?</span><br><span class="line">0</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><code>/root/cls.txt</code>是否存在</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# [ -e /root/cls.txt ]</span><br><span class="line">[root@centos_01 scripts]# echo $?</span><br><span class="line">1</span><br></pre></td></tr></table></figure><ul><li>检测<code>环境变量A</code>的值是否为hello</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# A=hello# 新建一个环境变量为A，赋值为hello</span><br><span class="line">[root@centos_01 scripts]# echo $A</span><br><span class="line">hello</span><br><span class="line">[root@centos_01 scripts]# [ $A = hello ]# 注意空格</span><br><span class="line">[root@centos_01 scripts]# echo $?</span><br><span class="line">0</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>多条件判断（<code>&amp;&amp;</code>表示前一条命令执行成功后，才执行后一条命令；<code>||</code>表示上一条命令执行失败后，才执行下一条命令）</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# [ 23 -ge 22 ] &amp;&amp; echo OK || echo notOK</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">[root@centos_01 scripts]# [ 23 -le 22 ] &amp;&amp; echo OK || echo notOK</span><br><span class="line">notOK</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="流程控制">流程控制</h2><h3 id="if-判断">if 判断</h3><ol><li>基本语法</li></ol><ul><li>单分支</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">if [ 条件判断式 ];then</span><br><span class="line">程序</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">if [ 条件判断式 ]</span><br><span class="line">then</span><br><span class="line">程序</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ul><li>多分支</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">if [ 条件判断式 ]</span><br><span class="line">then</span><br><span class="line">程序</span><br><span class="line">elif [ 条件判断式 ]</span><br><span class="line">then</span><br><span class="line">程序</span><br><span class="line">else</span><br><span class="line">程序</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><blockquote><p>注：</p><ul><li>[ 条件判断式 ] 中括号和条件判断式之间必须有空格</li><li>if后面要有空格</li><li>以上使用的<code>[]</code>可以换成<code>(())</code>两个小括号，这样更方便。若使用<code>(())</code>，则条件判断式中的<code>-eq</code>等符号，可以换成<code>==</code>等符号</li></ul></blockquote><ol start="2"><li>案例</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# touch if.sh</span><br><span class="line">[root@centos_01 scripts]# vim if.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">if [ $1 -eq 1 ]</span><br><span class="line">then</span><br><span class="line">        echo &quot;this parameter is equal to 1&quot;</span><br><span class="line">elif [ $1 -ge 2 ]</span><br><span class="line">then</span><br><span class="line">        echo &quot;this parameter is greater equal 2&quot;</span><br><span class="line">fi</span><br><span class="line">[root@centos_01 scripts]# bash if.sh 3</span><br><span class="line">this parameter is greater equal 2</span><br><span class="line">[root@centos_01 scripts]# bash if.sh 1</span><br><span class="line">this parameter is equal to 1</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="case-语句">case 语句</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">case $变量名 in</span><br><span class="line">&quot;值1&quot;)</span><br><span class="line">如果变量的值等于值1，则执行程序1</span><br><span class="line">;;</span><br><span class="line">&quot;值2&quot;)</span><br><span class="line">如果变量的值等于值2，则执行程序2</span><br><span class="line">;;</span><br><span class="line">...省略其他分支...</span><br><span class="line">*)</span><br><span class="line">如果变量的值都不是以上的值，则执行此程序</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><blockquote><p>注：</p><ul><li>case 行尾必须为单词“in”，每一个模式匹配必须以右括号“）”结束</li><li>双分号“;;”表示命令序列结束，相当于java 中的break。</li><li>最后的“*）”表示默认模式，相当于java 中的default</li></ul></blockquote><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# touch case.sh</span><br><span class="line">[root@centos_01 scripts]# vim case.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">&quot;1&quot;)</span><br><span class="line">        echo &quot;this parameter == 1&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;2&quot;)</span><br><span class="line">        echo &quot;this parameter == 2&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;3&quot;)</span><br><span class="line">        echo &quot;this parameter == 3&quot;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">        echo &quot;this parameter &gt; 3&quot;</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line">[root@centos_01 scripts]# bash case.sh 2</span><br><span class="line">this parameter == 2</span><br><span class="line">[root@centos_01 scripts]# bash case.sh 3</span><br><span class="line">this parameter == 3</span><br><span class="line">[root@centos_01 scripts]# bash case.sh 4</span><br><span class="line">this parameter &gt; 3</span><br></pre></td></tr></table></figure><h3 id="for-循环">for 循环</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for (( 初始值;循环控制条件;变量变化))</span><br><span class="line">do</span><br><span class="line">程序</span><br><span class="line">done</span><br></pre></td></tr></table></figure><ol start="2"><li>案例</li></ol><ul><li>从1加到100</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# touch for1.sh</span><br><span class="line">[root@centos_01 scripts]# vim for1.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">sum=0</span><br><span class="line">for ((i=0;i&lt;=100;i++))# 注：这里使用双小括号了，所以可以使用&lt;=符号</span><br><span class="line">do</span><br><span class="line">        sum=$[$sum+$i]</span><br><span class="line">done</span><br><span class="line">echo $sum</span><br><span class="line">[root@centos_01 scripts]# bash for1.sh</span><br><span class="line">5050</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">也可以如下</span></span><br><span class="line">[root@centos_01 scripts]# for i in &#123;1..100&#125;; do sum=$[$sum+$i]; done; echo $sum</span><br><span class="line">5050</span><br></pre></td></tr></table></figure><ol start="3"><li>基本语法2</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for 变量 in 值1 值2 值3 ...</span><br><span class="line">do</span><br><span class="line">程序</span><br><span class="line">done</span><br></pre></td></tr></table></figure><ol start="4"><li>案例</li></ol><ul><li>打印所有输入参数</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# touch for2.sh</span><br><span class="line">[root@centos_01 scripts]# vim for2.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打印数字</span></span><br><span class="line"></span><br><span class="line">for i in cls mly wls</span><br><span class="line">do</span><br><span class="line">        echo &quot;bang zhang love $i&quot;</span><br><span class="line">done</span><br><span class="line">[root@centos_01 scripts]# bash for2.sh</span><br><span class="line">bang zhang love cls</span><br><span class="line">bang zhang love mly</span><br><span class="line">bang zhang love wls</span><br></pre></td></tr></table></figure><ul><li>比较<code>$*</code> 和 <code>$@</code> 的区别</li></ul><p><code>$*</code>和​<code>$@</code>都表示传递给函数或脚本的所有参数，不被双引号“”包含时，都以​<code>$1</code> <code>$2</code> …<code>$n</code><br>的形式输出所有参数。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# vim for3.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">echo &#x27;===============$*================&#x27;</span><br><span class="line">for i in $*</span><br><span class="line">do</span><br><span class="line">        echo &quot;ban zhang love $i&quot;</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">echo &#x27;==============$@================&#x27;</span><br><span class="line">for j in $@</span><br><span class="line">do</span><br><span class="line">        echo &quot;ban zhang love $j&quot;</span><br><span class="line">done</span><br><span class="line">[root@centos_01 scripts]# bash for3.sh cls mly wls</span><br><span class="line">===============$*================</span><br><span class="line">ban zhang love cls</span><br><span class="line">ban zhang love mly</span><br><span class="line">ban zhang love wls</span><br><span class="line">==============$@================</span><br><span class="line">ban zhang love cls</span><br><span class="line">ban zhang love mly</span><br><span class="line">ban zhang love wls</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>当它们被双引号“”包含时，<code>$*</code>会将所有的参数作为一个整体，以“​<code>$1</code> ​<code>$2</code> …<code>$n</code>”的形式输<br>出所有参数；<code>$@</code>会将各个参数分开，以“​<code>$1</code>” “​<code>$2</code>”…“​<code>$n</code>”的形式输出所有参数。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# vim for4.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">echo &#x27;=================$*===========&#x27;</span><br><span class="line">for i in &quot;$*&quot;</span><br><span class="line">do</span><br><span class="line">        echo &quot;ban zhang love $i&quot;</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">echo &#x27;================$@===========&#x27;</span><br><span class="line">for j in &quot;$@&quot;</span><br><span class="line">do</span><br><span class="line">        echo &quot;bang zhang love $j&quot;</span><br><span class="line">done</span><br><span class="line">[root@centos_01 scripts]# bash for4.sh cls mly wls</span><br><span class="line">=================$*===========</span><br><span class="line">ban zhang love cls mly wls</span><br><span class="line">================$@===========</span><br><span class="line">bang zhang love cls</span><br><span class="line">bang zhang love mly</span><br><span class="line">bang zhang love wls</span><br></pre></td></tr></table></figure><h3 id="while-循环">while 循环</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">while [ 条件判断式 ]</span><br><span class="line">do</span><br><span class="line">程序</span><br><span class="line">done</span><br></pre></td></tr></table></figure><ol start="2"><li>案例</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# vim while.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">sum=0</span><br><span class="line">i=1</span><br><span class="line">while [ $i -le 100 ]</span><br><span class="line">do</span><br><span class="line">        sum=$[$sum+$i]</span><br><span class="line">        i=$[$i+1]</span><br><span class="line">done</span><br><span class="line">echo $sum</span><br><span class="line">[root@centos_01 scripts]# bash while.sh</span><br><span class="line">5050</span><br></pre></td></tr></table></figure><h3 id="read-读取控制台输入">read 读取控制台输入</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">read 选项 参数</span><br></pre></td></tr></table></figure><ul><li><p>选项：</p><p><code>-p</code>：指定读取值时的提示符</p><p><code>-t</code>：指定读取值时等待的时间（秒），超时退出。如果<code>-t</code>不加，则表示一直等待</p></li><li><p>参数：</p><p>变量：指定读取值的变量名</p></li></ul><ol start="2"><li>案例</li></ol><p>提示7秒内，读取控制台输入的名称</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# vim read.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">read -t 7 -p &quot;Enter your name in 7 seconds: &quot; NN</span><br><span class="line">echo $NN</span><br><span class="line">[root@centos_01 scripts]# bash read.sh</span><br><span class="line">Enter your name in 7 seconds: hello world</span><br><span class="line">hello world</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="函数">函数</h2><h3 id="系统函数">系统函数</h3><h4 id="basename">basename</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">basename [string/pathname] [suffix] # 功能描述：basename 命令会删掉所有的前缀包括最后一个（‘/’）字符，然后将字符串显示出来</span><br></pre></td></tr></table></figure><p><strong>basename 可以理解为取路径里的文件名称</strong></p><p>选项：</p><p>suffix 为后缀，如果suffix 被指定了，basename 会将pathname 或string 中的suffix 去掉。</p><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# basename /root/ifcfg-ens33.bk</span><br><span class="line">ifcfg-ens33.bk</span><br><span class="line">[root@centos_01 ~]# basename /root/ifcfg-ens33.bk  .bk</span><br><span class="line">ifcfg-ens33</span><br></pre></td></tr></table></figure><h4 id="dirname">dirname</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">dirname 文件绝对路径# 从给定的包含绝对路径或相对路径的文件名中去除文件名（非目录的部分），然后返回剩下的路径（目录的部分））</span><br></pre></td></tr></table></figure><p><strong>dirname 可以理解为取文件路径的绝对路径或相对路径名称</strong></p><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# dirname /root/ifcfg-ens33.bk</span><br><span class="line">/root</span><br><span class="line">[root@centos_01 ~]# dirname ./ifcfg-ens33.bk</span><br><span class="line">.</span><br></pre></td></tr></table></figure><h3 id="自定义函数">自定义函数</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[ function ] funname[()]</span><br><span class="line">&#123;</span><br><span class="line">Action;</span><br><span class="line">[return int;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>注意事项</li></ol><ul><li><p>上述<code>[]</code>括号，表示可选项</p></li><li><p>必须在调用函数地方之前，先声明函数，shell 脚本是逐行运行。不会像其它语言一<br>样先编译。</p></li><li><p>函数返回值，只能通过<code>$?</code>系统变量获得，可以显示加：return 返回，如果不加，将<br>以最后一条命令运行结果，作为返回值。return 后跟数值n(0-255)。<strong>注：return只能返回数值型的结果，且结果范围在[0,255]之间</strong></p></li></ul><ol start="3"><li>案例实操</li></ol><p>计算两个输入参数的和</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# vim fun.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">function sum()</span><br><span class="line">&#123;</span><br><span class="line">        s=0</span><br><span class="line">        s=$[$1+$2]</span><br><span class="line">        echo &quot;$s&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">read -p &quot;Please input the number1: &quot; n1</span><br><span class="line">read -p &quot;Please input the number2: &quot; n2</span><br><span class="line">sum $n1 $n2</span><br><span class="line">[root@centos_01 ~]# bash fun.sh</span><br><span class="line">Please input the number1: 2</span><br><span class="line">Please input the number2: 5</span><br><span class="line">7</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>第二个例子</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# vim fun.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">function sum()</span><br><span class="line">&#123;</span><br><span class="line">        s=0</span><br><span class="line">        s=$[$1+$2]</span><br><span class="line">        return $s</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">read -p &quot;Please input the number1: &quot; n1</span><br><span class="line">read -p &quot;Please input the number2: &quot; n2</span><br><span class="line"></span><br><span class="line">sum $n1 $n2</span><br><span class="line">echo &quot;sum = &quot;$?</span><br><span class="line">[root@centos_01 scripts]# bash fun.sh</span><br><span class="line">Please input the number1: 1</span><br><span class="line">Please input the number2: 2</span><br><span class="line">sum = 3</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="调用系统函数">调用系统函数</h3><p>在一个脚本中调用系统函数<code>date</code>的示例：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# vim cmd_test.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">filename=&quot;$1&quot;_log_$(date +%s)</span><br><span class="line">echo $filename</span><br><span class="line">[root@centos_01 scripts]# bash cmd_test.sh mysql</span><br><span class="line">mysql_log_1679136612</span><br></pre></td></tr></table></figure><p>其中，<code>date +%s</code>即是系统函数</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# date +%s</span><br><span class="line">1679136655</span><br></pre></td></tr></table></figure><h2 id="正则表达式入门">正则表达式入门</h2><p>正则表达式使用单个字符串来描述、匹配一系列符合某个语法规则的字符串。在很多文<br>本编辑器里，正则表达式通常被用来检索、替换那些符合某个模式的文本。在Linux 中，<code>grep</code>，<code>sed</code>，<code>awk</code> 等文本处理工具都支持通过正则表达式进行模式匹配。</p><h3 id="常规匹配">常规匹配</h3><p>纯文本匹配：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# cat /etc/passwd | grep root</span><br><span class="line">root:x:0:0:root:/root:/bin/bash</span><br><span class="line">operator:x:11:0:operator:/root:/sbin/nologin</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>会匹配所有包含<code>root</code>的行</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201657003.png" alt="image-20230318202014082"></p><h3 id="常用特殊字符">常用特殊字符</h3><h4 id="特殊字符：">特殊字符：<code>^</code></h4><p><code>^</code>匹配一行的开头，如：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# cat /etc/passwd | grep ^a</span><br><span class="line">adm:x:3:4:adm:/var/adm:/sbin/nologin</span><br></pre></td></tr></table></figure><p>会匹配所有以<code>a</code>开头的行</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201657004.png" alt="image-20230318202001335"></p><h4 id="特殊字符：-2">特殊字符：<code>$</code></h4><p><code>$</code>匹配一行的结束，如：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# cat /etc/passwd | grep t$</span><br><span class="line">halt:x:7:0:halt:/sbin:/sbin/halt</span><br></pre></td></tr></table></figure><p>会匹配所有以<code>t</code>结尾的行</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201657005.png" alt="image-20230318201945683"></p><h4 id="特殊字符：-3">特殊字符：<code>.</code></h4><p><code>.</code>匹配一个任意字符：如：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# cat /etc/passwd | grep r..t</span><br><span class="line">root:x:0:0:root:/root:/bin/bash</span><br><span class="line">operator:x:11:0:operator:/root:/sbin/nologin</span><br><span class="line">ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201657006.png" alt="image-20230318201927881"></p><h4 id="特殊字符：-4">特殊字符：<code>*</code></h4><p><code>*</code>不单独使用，它和上一个字符连用，表示匹配上一个字符0次或多次。如：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# cat /etc/passwd | grep r*t</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201657007.png" alt="image-20230318201913591"></p><h4 id="字符区间（中括号）：">字符区间（中括号）：<code>[]</code></h4><p><code>[]</code>表示匹配某个范围内的一个字符。如：</p><p>[6,8]——匹配6或8</p><p>[0-9]——匹配一个0-9的数字</p><p>[0-9]*——匹配任意长度的数字字符串</p><p>[a-z]——匹配一个a-z之间的字符</p><p>[a-z]*——匹配任意长度的字母字符串</p><p>[a-c, e-f]——匹配a-c或者e-f之间的任意字符</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# cat /etc/passwd | grep r[a,b,c]*t</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303201657008.png" alt="image-20230318202323842"></p><h4 id="特殊字符：-5">特殊字符：<code>\</code></h4><p><code>\</code>表示转义，并不会单独使用。由于所有特殊字符都有其特定匹配模式，当我们想匹配<br>某一特殊字符本身时（例如，我想找出所有包含’$’ 的行），就会碰到困难。此时我们就要<br>将转义字符和特殊字符连用，来表示特殊字符本身，例如</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# cat /etc/passwd | grep &#x27;a\$b&#x27;</span><br></pre></td></tr></table></figure><p>就会匹配所有包含<code>a$b</code> 的行。注意需要使用单引号将表达式引起来。</p><h2 id="文本处理工具">文本处理工具</h2><h3 id="cut">cut</h3><p>cut 的工作就是“剪”，具体的说就是在文件中负责剪切数据用的。cut 命令从文件的每<br>一行剪切字节、字符和字段并将这些字节、字符和字段输出。</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cut [选项参数] filename</span><br></pre></td></tr></table></figure><p>说明：默认分隔符是制表符</p><ol start="2"><li>选项参数</li></ol><table><thead><tr><th>选项参数</th><th>功能</th></tr></thead><tbody><tr><td>-f</td><td>列号，提取第几列</td></tr><tr><td>-d</td><td>分隔符，按照指定分隔符分割列，默认是制表符<code>\t</code></td></tr><tr><td>-c</td><td>按字符进行切割，后加<code>n</code>表示取第几列。比如<code>-c 1</code></td></tr></tbody></table><ol start="3"><li>案例</li></ol><p>（1）先准备一些数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# touch cut.txt</span><br><span class="line">[root@centos_01 ~]# vim cut.txt</span><br><span class="line">dong shen</span><br><span class="line">guan zhen</span><br><span class="line">wo  wo</span><br><span class="line">lai lai</span><br><span class="line">le le</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（2）切割cut.txt第一列</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# cut -d &quot; &quot; -f 1 cut.txt</span><br><span class="line">dong</span><br><span class="line">guan</span><br><span class="line">wo</span><br><span class="line">lai</span><br><span class="line">le</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（3）切割cut.txt第二、三列</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# cut -d &quot; &quot; -f 2,3 cut.txt</span><br><span class="line">shen</span><br><span class="line">zhen</span><br><span class="line"> wo</span><br><span class="line">lai</span><br><span class="line">le</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（4）在cut.txt中切割出guan</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# cat cut.txt | grep guan | cut -d &quot; &quot; -f 1</span><br><span class="line">guan</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（5）选取系统<code>PATH</code>变量值，切割出第二个<code>:</code>开始后的所有路径</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# echo $PATH</span><br><span class="line">/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin</span><br><span class="line">[root@centos_01 ~]# echo $PATH | cut -d &quot;:&quot; -f 3</span><br><span class="line">/usr/sbin</span><br><span class="line">[root@centos_01 ~]# echo $PATH | cut -d &quot;:&quot; -f 3-</span><br><span class="line">/usr/sbin:/usr/bin:/root/bin</span><br></pre></td></tr></table></figure><p>（6）切割<code>ifconfig</code>后打印的IP地址</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# ifconfig ens33</span><br><span class="line">ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 192.168.179.130  netmask 255.255.255.0  broadcast 192.168.179.255</span><br><span class="line">        inet6 fe80::c757:d7e1:da2f:cd02  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether 00:0c:29:76:4f:1f  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 919843  bytes 60566561 (57.7 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 1664702  bytes 191447146 (182.5 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">[root@centos_01 ~]# ifconfig ens33 | grep netmask | cut -d &quot; &quot; -f 10</span><br><span class="line">192.168.179.130</span><br></pre></td></tr></table></figure><h3 id="awk">awk</h3><p>一个强大的文本分析工具，<strong>把文件逐行的读入</strong>，以空格为默认分隔符将每行切片，切开<br>的部分再进行分析处理。</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">awk [选项参数] &#x27;/pattern1/&#123;action1&#125; /pattern2/&#123;action2&#125;...&#x27; filename</span><br></pre></td></tr></table></figure><ul><li><code>pattern</code>：表示<code>awk</code>在数据中查找的内容，就是匹配模式</li><li><code>action</code>：在找到匹配内容时所执行的一系列命令</li></ul><ol start="2"><li>选项参数</li></ol><table><thead><tr><th>选项参数</th><th>功能</th></tr></thead><tbody><tr><td>-F</td><td>指定输入文件分隔符</td></tr><tr><td>-v</td><td>赋值一个用户定义变量</td></tr></tbody></table><ol start="3"><li>案例实操</li></ol><p>（1）数据准备</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# cp /etc/passwd ./</span><br><span class="line">[root@centos_01 ~]# cat passwd</span><br><span class="line">root:x:0:0:root:/root:/bin/bash</span><br></pre></td></tr></table></figure><p>（2）搜索passwd文件以root关键字开头的所有行，并输出该行的第7列</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# awk -F : &#x27;/^root/&#123;print $7&#125;&#x27; passwd</span><br><span class="line">/bin/bash</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（3）搜索passwd文件以root关键字开头的所有行，并输出该行的第1列和第7列，中间以“,”号分割</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# awk -F : &#x27;/^root/&#123;print $1&quot;, &quot;$7&#125;&#x27; passwd</span><br><span class="line">root, /bin/bash</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>注意：只有匹配了pattern的行才会执行action</p><p>（4）只显示/etc/passwd的第一列和第七列，以逗号分割，且在所有行前面添加列名“user，shell”，在最后一行添加“dahaige, /bin/zuishuai”</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# awk -F : &#x27;BEGIN&#123;print &quot;user, shell&quot;&#125; &#123;print $1&quot;, &quot;$7&#125;END&#123;print &quot;dahaige,/bin/zuishuai&quot;&#125;&#x27; passwd</span><br><span class="line">user, shell</span><br><span class="line">root, /bin/bash</span><br><span class="line">bin, /sbin/nologin</span><br><span class="line">... ...</span><br><span class="line">chrony, /sbin/nologin</span><br><span class="line">dahaige,/bin/zuishuai</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>注意：BEGIN 在所有数据读取行之前执行；END 在所有数据执行之后执行。</p><p>（5）蒋passwd文件中的用户id增加数值1并输出</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# awk -v i=1 -F : &#x27;&#123;print $3+i&#125;&#x27; passwd</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td></tr></table></figure><h2 id="综合应用案例">综合应用案例</h2><h3 id="归档文件">归档文件</h3><p>实际生产应用中，往往需要对重要数据进行归档备份。<br>需求：实现一个每天对指定目录归档备份的脚本，输入一个目录名称（末尾不带/），<br>将目录下所有文件按天归档保存，并将归档日期附加在归档文件名上，放在<code>/root/archive</code> 下。<br>这里用到了归档命令：<code>tar</code><br>后面可以加上-c 选项表示归档，加上-z 选项表示同时进行压缩，得到的文件后缀名<br>为<code>.tar.gz</code>。</p><p>脚本实现如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">首先判断输入参数的个数是否为1</span></span><br><span class="line">if [ $# -ne 1 ]</span><br><span class="line">then</span><br><span class="line">        echo &quot; 参数个数错误!应该输入一个参数，作为归档目录名&quot;</span><br><span class="line">        exit</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从参数中获取目录名称</span></span><br><span class="line">if [ -d $1 ]</span><br><span class="line">then</span><br><span class="line">        echo</span><br><span class="line">else</span><br><span class="line">        echo</span><br><span class="line">        echo &quot;目录不存在!&quot;</span><br><span class="line">        echo</span><br><span class="line">        exit</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">DIR_NAME=$(basename $1)</span><br><span class="line">DIR_PATH=$(cd $(dirname $1); pwd)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取当前日期</span></span><br><span class="line">DATE=$(date +%y%m%d)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">定义生成的归档文件名称</span></span><br><span class="line">FILE=archive_$&#123;DIR_NAME&#125;_$DATE.tar.gz</span><br><span class="line">DEST=/root/archive/$FILE</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">开始归档目录文件</span></span><br><span class="line">echo &quot;开始归档...&quot;</span><br><span class="line">echo</span><br><span class="line"></span><br><span class="line">tar -czf $DEST $DIR_PATH/$DIR_NAME</span><br><span class="line"></span><br><span class="line">if [ $? -eq 0 ]</span><br><span class="line">then</span><br><span class="line">        echo</span><br><span class="line">        echo &quot;归档成功!&quot;</span><br><span class="line">        echo &quot;归档文件为: $DEST&quot;</span><br><span class="line">else</span><br><span class="line">        echo</span><br><span class="line">        echo &quot;归档出现问题!&quot;</span><br><span class="line">        echo</span><br><span class="line">fi</span><br><span class="line">exit</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>执行脚本：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 scripts]# ./archive.sh</span><br><span class="line"> 参数个数错误!应该输入一个参数，作为归档目录名</span><br><span class="line"> [root@centos_01 scripts]# ./archive.sh .</span><br><span class="line"></span><br><span class="line">开始归档...</span><br><span class="line"></span><br><span class="line">tar: Removing leading `/&#x27; from member names</span><br><span class="line">tar (child): /root/archive/archive_._230318.tar.gz: Cannot open: No such file or directory</span><br><span class="line">tar (child): Error is not recoverable: exiting now</span><br><span class="line">tar: Child returned status 2</span><br><span class="line">tar: Error is not recoverable: exiting now</span><br><span class="line"></span><br><span class="line">归档出现问题!</span><br><span class="line"></span><br><span class="line">[root@centos_01 scripts]# mkdir /root/archive</span><br><span class="line">[root@centos_01 scripts]# ./archive.sh .</span><br><span class="line"></span><br><span class="line">开始归档...</span><br><span class="line"></span><br><span class="line">tar: Removing leading `/&#x27; from member names</span><br><span class="line"></span><br><span class="line">归档成功!</span><br><span class="line">归档文件为: /root/archive/archive_._230318.tar.gz</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Shell编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux基础（二）常用命令</title>
      <link href="/2023/03/11/Linux%E5%9F%BA%E7%A1%80%EF%BC%88%E4%BA%8C%EF%BC%89%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2023/03/11/Linux%E5%9F%BA%E7%A1%80%EF%BC%88%E4%BA%8C%EF%BC%89%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="帮助命令">帮助命令</h2><h3 id="man-获得帮助信息">man 获得帮助信息</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">man [命令或配置文件]# 获得帮助信息</span><br></pre></td></tr></table></figure><ol start="2"><li>显示说明</li></ol><table><thead><tr><th>信息</th><th>功能</th></tr></thead><tbody><tr><td>NAME</td><td>命令的名称和单行描述</td></tr><tr><td>SYNOPSIS</td><td>怎样使用命令</td></tr><tr><td>DESCRIPTION</td><td>命令功能的深入讨论</td></tr><tr><td>EXAMPLES</td><td>怎样使用命令的例子</td></tr><tr><td>SEE ALSO</td><td>相关主题</td></tr></tbody></table><ol start="3"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">man ls</span><br></pre></td></tr></table></figure><h3 id="help获得shell内置命令的帮助信息">help获得shell内置命令的帮助信息</h3><p>一部分基础功能的系统命令是直接内嵌在shell 中的，系统加载启动之后会随着shell一起加载，常驻系统内存中。这部分命令被称为“内置（built-in）命令”；相应的其它命令被称为“外部命令”。</p><blockquote><p>如何查看一个命令是内置（built-in）命令还是外部命令：</p><p>可以使用以下命令来验证：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">type [命令]</span><br></pre></td></tr></table></figure><p>如：</p><ol><li>表示内置：<img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912334.png" alt="image-20230311215328555"></li><li>表示外部：<img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912335.png" alt="image-20230311215402838"></li></ol></blockquote><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">help [命令]# 获得shell内置命令的帮助信息</span><br></pre></td></tr></table></figure><ol start="2"><li>案例实操</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">help cd</span><br></pre></td></tr></table></figure><h3 id="常用快捷键">常用快捷键</h3><table><thead><tr><th>常用快捷键</th><th>功能</th></tr></thead><tbody><tr><td>ctrl + c</td><td>停止进程</td></tr><tr><td>ctrl+l</td><td>清屏，等同于clear；彻底清屏是：reset</td></tr><tr><td>善于用tab键</td><td>提示(更重要的是可以防止敲错)</td></tr><tr><td>上下键</td><td>查找执行过的命令</td></tr></tbody></table><h2 id="文件目录类">文件目录类</h2><h3 id="pwd显示当前工作目录的绝对路径">pwd显示当前工作目录的绝对路径</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pwd# 显示当前工作目录的绝对路径</span><br></pre></td></tr></table></figure><ol start="2"><li>例子</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos_01 ~]# pwd</span><br><span class="line">/root</span><br></pre></td></tr></table></figure><h3 id="ls-列出目录的内容">ls 列出目录的内容</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls [选项] [目录或文件]</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-a</td><td>全部的文件，连同隐藏档( 开头为. 的文件) 一起列出来(常用)</td></tr><tr><td>-l</td><td>长数据串列出，包含文件的属性与权限等等数据；(常用)等价于“ll”</td></tr></tbody></table><h3 id="cd-切换目录">cd 切换目录</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd [参数]</span><br></pre></td></tr></table></figure><ol start="2"><li>参数说明</li></ol><table><thead><tr><th>参数</th><th>功能</th></tr></thead><tbody><tr><td>cd 绝对路径/相对路径</td><td>切换路径</td></tr><tr><td>cd ~</td><td>回到自己的家目录</td></tr><tr><td>cd -</td><td>回到上一次所在目录</td></tr><tr><td>cd …</td><td>回到当前目录的上一级目录</td></tr><tr><td>cd -P</td><td>跳转到实际物理路径，而非快捷方式路径</td></tr></tbody></table><h3 id="mkdir-创建一个新目录">mkdir 创建一个新目录</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir [选项] [要创建的目录]</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-p</td><td>创建多层目录</td></tr></tbody></table><h3 id="rmdir-删除一个空的目录">rmdir 删除一个空的目录</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rmdir [选项] [要删除空的目录]</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-p</td><td>删除目录及父目录（如：‘rmdir -p a/b/c’ == ‘rmdir a/b/c a/b a’）</td></tr></tbody></table><h3 id="touch-创建空文件">touch 创建空文件</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">touch [文件名]</span><br></pre></td></tr></table></figure><h3 id="cp-复制文件或目录">cp 复制文件或目录</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp [选项] source dest# 复制source文件到dest</span><br></pre></td></tr></table></figure><ol start="2"><li>选项</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-r</td><td>递归复制整个文件夹</td></tr></tbody></table><ol start="3"><li>参数说明</li></ol><table><thead><tr><th>参数</th><th>功能</th></tr></thead><tbody><tr><td>source</td><td>源文件</td></tr><tr><td>dest</td><td>目标文件</td></tr></tbody></table><h3 id="rm-删除文件或目录">rm 删除文件或目录</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rm [选项] [目录或文件]</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-r</td><td>递归删除目录中所有内容</td></tr><tr><td>-f</td><td>强制执行删除操作，而不提示用于进行确认</td></tr><tr><td>-v</td><td>显示指令的详细执行过程</td></tr></tbody></table><h3 id="mv-移动文件与目录或重命名">mv 移动文件与目录或重命名</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv oldNameFile newNameFile# 重命名</span><br><span class="line">mv /temp/movefile /targetFolder# 移动文件</span><br></pre></td></tr></table></figure><h3 id="cat-查看文件内容">cat 查看文件内容</h3><p>查看文件内容，从第一行开始显示。</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat [选项] 要查看的文件</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能描述</th></tr></thead><tbody><tr><td>-n</td><td>显示所有行的行号，包括空行</td></tr></tbody></table><p>一般用来查看比较小的文件</p><h3 id="more-文件内容分屏查看器">more 文件内容分屏查看器</h3><p>more 指令是一个基于VI 编辑器的文本过滤器，它以全屏幕的方式按页显示文本文件<br>的内容。more 指令中内置了若干快捷键，详见操作说明。</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">more 要查看的文件</span><br></pre></td></tr></table></figure><ol start="2"><li>操作说明</li></ol><table><thead><tr><th>操作</th><th>功能说明</th></tr></thead><tbody><tr><td>&quot;space&quot;键</td><td>向下翻一页</td></tr><tr><td>&quot;Enter&quot;键</td><td>向下翻一行</td></tr><tr><td>q</td><td>立即离开more，不再显示该文件内容</td></tr><tr><td>Ctrl + f</td><td>向下滚动一屏</td></tr><tr><td>Ctrl + b</td><td>返回上一屏</td></tr><tr><td>=</td><td>输出当前行的行号</td></tr><tr><td>:f</td><td>输出文件名和当前行的行号</td></tr></tbody></table><h3 id="less-分屏显示文件内容">less 分屏显示文件内容</h3><p>less 指令用来分屏查看文件内容，它的功能与more 指令类似，但是比more 指令更加<br>强大，支持各种显示终端。less 指令在显示文件内容时，并不是一次将整个文件加载之后<br>才显示，而是根据显示需要加载内容，对于显示大型文件具有较高的效率。</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">less 要查看的文件</span><br></pre></td></tr></table></figure><ol start="2"><li>操作说明</li></ol><table><thead><tr><th>操作</th><th>功能说明</th></tr></thead><tbody><tr><td>&quot;Space&quot;键</td><td>向下翻动一页</td></tr><tr><td>[pagedown]键</td><td>向下翻动一页</td></tr><tr><td>[pageup]键</td><td>向上翻动一页</td></tr><tr><td>/字符串</td><td>向下搜寻[字符串]的功能; n: 向下查找；N：向上查找</td></tr><tr><td>?字符串</td><td>向上搜寻[字符串]的功能；n: 向上查找；N：向下查找</td></tr><tr><td>q</td><td>离开less</td></tr></tbody></table><h3 id="echo">echo</h3><p>echo 输出内容到控制台</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo [选项] [输出内容到控制台]</span><br></pre></td></tr></table></figure><ol start="2"><li>选项</li></ol><table><thead><tr><th>操作</th><th>作用</th></tr></thead><tbody><tr><td>-e</td><td>支持反斜线控制的字符转换</td></tr></tbody></table><table><thead><tr><th>控制字符</th><th>作用</th></tr></thead><tbody><tr><td><code>\\</code></td><td>输出<code>\</code>本身</td></tr><tr><td><code>\n</code></td><td>换行符</td></tr><tr><td><code>\t</code></td><td>制表符</td></tr></tbody></table><ol start="3"><li>例子</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912337.png" alt="image-20230312134540671"></p><h3 id="输出重定向-和-追加">&gt; 输出重定向 和 &gt;&gt; 追加</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls -l &gt; a.txt# 将列表的内容写入文件a.txt中（覆盖写）</span><br><span class="line"></span><br><span class="line">ls -al &gt;&gt; a.txt# 将列表的内容追加到文件a.txt的末尾</span><br><span class="line"></span><br><span class="line">cat a.txt &gt; b.txt# 将文件a.txt的内容覆盖到文件b.txt</span><br><span class="line"></span><br><span class="line">echo &quot;内容&quot; &gt;&gt; a.txt# 将echo要打印的内容写入a.txt</span><br></pre></td></tr></table></figure><ol start="2"><li>例子</li></ol><ul><li>将<code>ls</code>查看的信息写入文件中</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls -l &gt; a.txt</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912338.png" alt="image-20230312135026479"></p><h3 id="head-显示文件头部内容">head 显示文件头部内容</h3><p>head 用于显示文件的开头部分内容，默认情况下head 指令显示文件的前10 行内容。</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">head 文件# 查看文件头10行内容</span><br><span class="line"></span><br><span class="line">head -n 5 文件# 查看文件头5行内容</span><br></pre></td></tr></table></figure><h3 id="tail输出文件尾部内容">tail输出文件尾部内容</h3><p>tail 用于输出文件中尾部的内容，默认情况下tail 指令显示文件的后10 行内容。</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tail 文件# 查看文件尾部10行内容</span><br><span class="line"></span><br><span class="line">tail -n 5 文件# 查看文件尾部5行内容</span><br><span class="line"></span><br><span class="line">tail -f 文件# 实时追踪该文档的所有更新，监控文件变化</span><br></pre></td></tr></table></figure><h3 id="history-查看已经执行过的历史命令">history 查看已经执行过的历史命令</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">history</span><br></pre></td></tr></table></figure><h2 id="搜索查找类">搜索查找类</h2><h3 id="find-查找文件或目录">find 查找文件或目录</h3><p>find 指令将从指定目录向下递归地遍历其各个子目录，将满足条件的文件显示在终端。</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find [搜索范围] [选项]</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-name &lt;文件名&gt;</td><td>按照指定的文件名查找模式查找文件</td></tr><tr><td>-user &lt;用户名&gt;</td><td>查找属于指定用户名所有文件</td></tr><tr><td>-size &lt;文件大小&gt;</td><td>按照指定的文件大小查找文件,单位为:<br />b —— 块（512 字节）<br />c —— 字节<br />w —— 字（2 字节）<br />k —— 千字节<br />M —— 兆字节<br />G —— 吉字节</td></tr></tbody></table><ol start="3"><li>案例</li></ol><ul><li>根据文件名查找：在<code>/root</code>目录下查找所有后缀是<code>.txt</code>的文件</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find /root -name &quot;*.txt&quot;</span><br></pre></td></tr></table></figure><ul><li>按文件大小：在/home目录下查找大于200m的文件（+n 大于-n小于n等于）</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find /home -size +204800</span><br></pre></td></tr></table></figure><h3 id="locate-快速定位文件路径">locate 快速定位文件路径</h3><p>locate 指令利用事先建立的系统中所有文件名称及路径的locate 数据库实现快速定位给<br>定的文件。Locate 指令无需遍历整个文件系统，查询速度较快。为了保证查询结果的准确<br>度，管理员必须定期更新locate 时刻。</p><p>该命令不是默认安装在Linux中的，所以需要下载：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install mlocate</span><br></pre></td></tr></table></figure><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">locate 搜索文件</span><br></pre></td></tr></table></figure><ol start="2"><li><p>说明：由于locate 指令基于数据库进行查询，所以第一次运行前，必须使用<code>updatedb </code>指令创建locate 数据库。</p></li><li><p>例子</p></li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">updatedb</span><br><span class="line">locate root</span><br></pre></td></tr></table></figure><h3 id="grep-过滤查找及-管道符">grep 过滤查找及<code>|</code>管道符</h3><p>管道符，<code>|</code>，表示将前一个命令的处理结果输出传递给后面的命令处理</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">grep [选项] [查找内容/源文件]</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-n</td><td>显示匹配行及行号</td></tr></tbody></table><ol start="3"><li>例子</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls | grep -n a.txt</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912339.png" alt="image-20230312155508124"></p><h2 id="压缩和解压类">压缩和解压类</h2><h3 id="gzip-gunzip">gzip/gunzip</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gzip 文件# 压缩文件，将文件压缩为*.gz文件</span><br><span class="line"></span><br><span class="line">gunzip 文件.gz# 将*.gz文件解压缩</span><br></pre></td></tr></table></figure><blockquote><p>注：</p><ul><li>只能压缩文件，不能压缩目录</li><li>不保留原来的文件</li><li>可以同时压缩/解压缩多个文件</li></ul></blockquote><h3 id="zip-unzip">zip/unzip</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zip [选项] XXX.zip 将要压缩的内容# 可以将文件和目录压缩</span><br><span class="line"></span><br><span class="line">unzip [选项] XXX.zip# 解压缩</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>zip 选项</th><th>功能</th></tr></thead><tbody><tr><td>-r</td><td>压缩目录</td></tr></tbody></table><table><thead><tr><th>unzip 选项</th><th>功能</th></tr></thead><tbody><tr><td>-d &lt;目录&gt;</td><td>指定解压后的文件的存放目录</td></tr></tbody></table><blockquote><p>注：</p><p>zip压缩命令在windows/linux都通用，可以压缩目录且保留源文件</p></blockquote><h3 id="tar">tar</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar [选项] XXX.tar.gz &lt;要打包的内容&gt;# 可以打包内容/解包</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-c</td><td>产生.tar 打包文件</td></tr><tr><td>-v</td><td>显示详细信息</td></tr><tr><td>-f</td><td>指定压缩后的文件名</td></tr><tr><td>-z</td><td>打包同时压缩</td></tr><tr><td>-x</td><td>解包.tar 文件</td></tr><tr><td>-C</td><td>解压到指定目录</td></tr></tbody></table><ol start="3"><li>例子</li></ol><ul><li>压缩多个文件</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912340.png" alt="image-20230312160643921"></p><ul><li>压缩目录</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912341.png" alt="image-20230312160657539"></p><ul><li>解压到当前目录</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912342.png" alt="image-20230312160715451"></p><ul><li>解压到指定目录</li></ul><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912343.png" alt="image-20230312160731027"></p><blockquote><p>一般遇到<code>.tar.gz</code>的需使用<code>tar</code>命令</p><ul><li><code>tar -zcvf</code> 用于压缩</li><li><code>tar -zxvf</code> 用于解压</li></ul></blockquote><h2 id="磁盘查看和分区类">磁盘查看和分区类</h2><h3 id="du-查看文件和目录占用的磁盘空间">du 查看文件和目录占用的磁盘空间</h3><p><code>du</code> 全称为 <code>disk usage</code>磁盘占用情况</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">du 目录/文件# 显示目录下每个子目录的磁盘使用情况</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-h</td><td>以人们较易阅读的GBytes, MBytes, KBytes 等格式自行显示；</td></tr><tr><td>-a</td><td>不仅查看子目录大小，还要包括文件</td></tr><tr><td>-c</td><td>显示所有的文件和子目录大小后，显示总和</td></tr><tr><td>-s</td><td>只显示总和</td></tr><tr><td>–max-depth=n</td><td>指定统计子目录的深度为第n 层</td></tr></tbody></table><h3 id="df-查看磁盘空间使用情况">df 查看磁盘空间使用情况</h3><p><code>df</code>全称为<code>disk free</code> 空余磁盘</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">df [选项]#列出文件系统的整体磁盘使用量，检查文件系统的磁盘空间占用情况</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-h</td><td>以人们较易阅读的GBytes, MBytes, KBytes 等格式自行显示</td></tr></tbody></table><h3 id="lsblk-查看设备挂载情况">lsblk 查看设备挂载情况</h3><p><code>lsblk</code>全称为<code>list block</code></p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsblk# 查看设备挂载情况</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-f</td><td>查看详细的设备挂载情况，显示文件系统信息</td></tr></tbody></table><h3 id="fdisk-分区">fdisk 分区</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">fdisk -l# 查看磁盘分区详情</span><br><span class="line">fdisk 硬盘设备名# 对新增磁盘继续分区操作</span><br></pre></td></tr></table></figure><blockquote><p>注：该命令必须在root用户下才能使用</p></blockquote><h2 id="进程管理类">进程管理类</h2><h3 id="ps-查看当前系统进程状态">ps 查看当前系统进程状态</h3><p><code>ps</code>全称<code>process status</code> 进程状态</p><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ps aux# 查看系统中所有进程</span><br><span class="line"></span><br><span class="line">ps -ef# 查看系统中所有进程，还能显示父进程的PID</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>a</td><td>列出带有终端的所有用户的进程</td></tr><tr><td>x</td><td>列出当前用户的所有进程，包括没有终端的进程</td></tr><tr><td>u</td><td>面向用户友好的显示风格</td></tr><tr><td>-e</td><td>列出所有进程</td></tr><tr><td>-u</td><td>列出某个用户关联的所有进程</td></tr><tr><td>-f</td><td>显示完整格式的进程列表</td></tr></tbody></table><ol start="3"><li>功能说明</li></ol><p>（1）<code>ps aux</code> 显示信息说明</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912344.png" alt="image-20230313104047564"></p><ul><li><p><code>USER</code>：该进程是由哪个用户产生的</p></li><li><p><code>PID</code>：进程的ID号</p></li><li><p><code>%CPU</code>：该进程占用CPU资源的百分比</p></li><li><p><code>%MEM</code>：该进程占用物理内存的百分比</p></li><li><p><code>VSZ</code>：该进程占用的虚拟内存的大小，单位KB</p></li><li><p><code>RSS</code>：该进程占用的实际物理内存的大小，单位KB</p></li><li><p><code>TTY</code>：该进程是在哪个终端中运行的。对于centos来说，tty1是图形化终端，tty2-tty6是本地的字符界面终端，pts/0-255代表虚拟终端</p></li><li><p><code>STAT</code>：进程状态。常见的状态有：<code>D</code>不可中断；<code>R</code>运行状态；<code>S</code>睡眠状态；<code>T</code>暂停状态；<code>Z</code>僵尸状态；<code>s</code>包含子进程；<code>l</code>多线程；<code>+</code>前台显示；<code>&lt;</code>高优先级；<code>N</code>低优先级</p></li><li><p><code>START</code>：该进程的启动时间</p></li><li><p><code>TIME</code>：该进程占用CPU的运算时间，注意不是系统时间</p></li><li><p><code>COMMAND</code>：产生此进程的命令名</p></li></ul><p>（2）<code>ps -ef</code> 显示信息说明</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912345.png" alt="image-20230313105517747"></p><ul><li><p><code>PPID</code>：父进程ID</p></li><li><p><code>C</code>：CPU用于计算执行优先级的因子。数值越大，表明进程是CPU密集型运算，执行优先级会降低；数值越小，表明进程是I/O密集型运算，执行优先级会提高</p></li><li><p><code>CMD</code>：启动进程所用的命令和参数</p></li></ul><h3 id="kill-终止进程">kill 终止进程</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kill [选项] 进程号# 通过进程号杀死进程</span><br><span class="line">killall 进程名称 # 通过进程名称杀死进程，也支持通配符，这在系统因负载过大而变得很慢时很有用</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-9</td><td>表示强迫进程立即停止</td></tr></tbody></table><h3 id="pstree-查看进程树">pstree 查看进程树</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pstree [选项]</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-p</td><td>显示进程的PID</td></tr><tr><td>-u</td><td>显示进程的所属用户</td></tr></tbody></table><h3 id="top-实时监控系统进程状态">top 实时监控系统进程状态</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">top [选项]</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-d n</td><td>n为数字；指定top命令每隔n秒更新。默认是3秒</td></tr><tr><td>-i</td><td>使top不显示任何闲置或者僵死进程</td></tr><tr><td>-p</td><td>通过指定监控进程ID来仅仅监控某个进程的状态</td></tr></tbody></table><ol start="3"><li>操作说明</li></ol><table><thead><tr><th>操作</th><th>功能</th></tr></thead><tbody><tr><td>P</td><td>以CPU 使用率排序，默认就是此项</td></tr><tr><td>M</td><td>以内存的使用率排序</td></tr><tr><td>N</td><td>以PID 排序</td></tr><tr><td>q</td><td>退出top</td></tr></tbody></table><ol start="4"><li>查询结果字段解释</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912346.png" alt="image-20230313204616770"></p><table><thead><tr><th>第一行内容（任务队列信息）</th><th>说明</th></tr></thead><tbody><tr><td>20:46:30</td><td>系统当前时间</td></tr><tr><td>up 1 day, 14:27</td><td>系统已运行时间；本结果表示本机已运行1天14小时27分钟</td></tr><tr><td>1 user</td><td>当前登录了一个用户</td></tr><tr><td>load average: 0.04, 0.03, 0.05</td><td>系统在之前1 分钟，5 分钟，15 分钟的平均负载。一般认为小于1 时，负载较小。如果大于1，系统已经超出负荷。</td></tr></tbody></table><table><thead><tr><th>第二行内容（进程信息）</th><th>说明</th></tr></thead><tbody><tr><td>Tasks: 139 total</td><td>系统中的进程总数</td></tr><tr><td>1 running</td><td>正在运行的进程数</td></tr><tr><td>138 sleeping</td><td>睡眠的进程</td></tr><tr><td>0 stopped</td><td>正在停止的进程</td></tr><tr><td>0 zombie</td><td>僵尸进程。如果不是0，需要手工检查僵尸进程</td></tr></tbody></table><table><thead><tr><th>第三行内容（CPU信息）</th><th>说明</th></tr></thead><tbody><tr><td>%Cpu(s):  0.0 us</td><td>用户模式占用的CPU百分比</td></tr><tr><td>0.2 sy</td><td>系统模式占用的CPU百分比</td></tr><tr><td>0.0 ni</td><td>改变过优先级的用户进程占用的CPU 百分比</td></tr><tr><td>99.8 id</td><td>空闲CPU 的CPU 百分比</td></tr><tr><td>0.0 wa</td><td>等待输入/输出的进程的占用CPU 百分比</td></tr><tr><td>0.0 hi</td><td>硬中断请求服务占用的CPU 百分比</td></tr><tr><td>0.0 si</td><td>软中断请求服务占用的CPU 百分比</td></tr><tr><td>0.0 st</td><td>st（Steal time）虚拟时间百分比。就是当有虚拟机时，虚拟CPU 等待实际CPU 的时间百分比。</td></tr></tbody></table><table><thead><tr><th>第四行内容（物理内存信息）</th><th>说明</th></tr></thead><tbody><tr><td>KiB Mem :  3861300 total</td><td>物理内存的总量，单位KB</td></tr><tr><td>2705072 free</td><td>空闲的物理内存数量</td></tr><tr><td>441528 used</td><td>已经使用的物理内存数量</td></tr><tr><td>714700 buff/cache</td><td>作为缓冲的内存数量</td></tr></tbody></table><table><thead><tr><th>第五行内容（交换分区swap信息）</th><th>说明</th></tr></thead><tbody><tr><td>KiB Swap:  4063228 total</td><td>交换分区（虚拟内存）的总大小</td></tr><tr><td>4063228 free</td><td>空闲交换分区的大小</td></tr><tr><td>0 used</td><td>已经使用的交互分区的大小</td></tr><tr><td>3120088 avail Mem</td><td>作为缓存的交互分区的大小</td></tr></tbody></table><h3 id="netstat-显示网络状态和端口占用信息">netstat 显示网络状态和端口占用信息</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">netstat -anp | grep 进程号# 查看该进程网络信息</span><br><span class="line"></span><br><span class="line">netstat -nlp | grep 端口号# 查看网络端口号占用情况</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-a</td><td>显示所有正在监听（listen）和未监听的套接字（socket）</td></tr><tr><td>-n</td><td>拒绝显示别名，能显示数字的全部转化成数字</td></tr><tr><td>-l</td><td>仅列出在监听的服务状态</td></tr><tr><td>-p</td><td>表示显示哪个进程在调用</td></tr></tbody></table><h3 id="crontab-系统定时任务">crontab 系统定时任务</h3><h4 id="crontab-服务管理">crontab 服务管理</h4><ol><li>重新启动<code>crond</code>服务</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl restart crond</span><br></pre></td></tr></table></figure><h4 id="crontab-定时任务设置">crontab 定时任务设置</h4><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">crontab [选项]</span><br></pre></td></tr></table></figure><ol start="2"><li>选项说明</li></ol><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-e</td><td>编辑crontab定时任务</td></tr><tr><td>-l</td><td>查询crontab任务</td></tr><tr><td>-r</td><td>删除当前用户所有的crontab任务</td></tr></tbody></table><ol start="3"><li>参数说明</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">crontab -e# 会创建一个crontab定时任务，并使用vim编辑</span><br></pre></td></tr></table></figure><p>在vim中可以写入如下内容：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">* * * * * 执行的任务</span><br></pre></td></tr></table></figure><blockquote><p>注：这个其实和Spring的定时任务差不多</p></blockquote><p><code>*</code>的含义如下：</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912347.png" alt="image-20230315203947263"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912348.png" alt="image-20230315204021560"></p><p><strong>例子：</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912349.png" alt="image-20230315204052144"></p><ol start="4"><li>案例</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">*/1 * * * * echo &quot;hello, world&quot; &gt;&gt; /root/hello.txt</span><br></pre></td></tr></table></figure><p>如，上面命令的意思是：每隔1分钟，将&quot;hello, world&quot; 追加到 /root/hello.txt 文件中。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303160912350.png" alt="image-20230315204519279"></p><h3 id="nohup-命令">nohup 命令</h3><p>nohup 英文全称为 no hang up（不挂起），用于在系统后台不挂断地运行命令，退出终端不会影响程序的运行。</p><p><strong>nohup</strong> 命令，在默认情况下（非重定向时），会输出一个名叫 nohup.out 的文件到当前目录下，如果当前目录的nohup.out 文件不可写，输出重定向到 <strong>$HOME/nohup.out</strong> 文件中。</p><p>语法格式：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup Command [ Arg … ] [　&amp; ]</span><br></pre></td></tr></table></figure><p>参数说明：</p><ul><li>Command：要执行的命令</li><li>Arg：一些参数，可以指定输出文件</li><li>&amp;：让命令在后台执行，终端退出后命令仍旧执行。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux基础（一）</title>
      <link href="/2023/03/07/Linux%E5%9F%BA%E7%A1%80/"/>
      <url>/2023/03/07/Linux%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>本文使用的是CentOS7.9，使用VMware安装虚拟机。</p><p>如何安装虚拟机可以在网上搜教程，就不再讲解了。</p><h2 id="Linux文件与目录结构">Linux文件与目录结构</h2><p><strong>Linux系统中一切皆是文件</strong></p><p>Linux目录结构如下，都是树形结构。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303111935513.png" alt=""></p><blockquote><p>有几个特性：</p><ul><li>文件名大小写敏感。如：MAIL，Mail，mail可以是同级目录下的不同文件</li><li>以<code>.</code>开头的文件为隐藏文件</li><li>路径的分割符为<code>/</code>。（与Windows下不同，Windows的分割符是<code>\</code>）</li><li>文件名最长255个字节</li><li>包括路径在内的文件名称最长4095字节</li></ul></blockquote><p><strong>目录作用说明：</strong></p><ul><li><code>/</code>：根目录</li><li><code>/bin</code>：是Binary的缩写，该目录存放着普通用户使用的命令</li><li><code>/sbin</code>：管理员使用的命令</li><li><code>/home</code>：存放普通用户的主目录。在Linux中每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。</li><li><code>/root</code>：管理员的用户主目录</li><li><code>/lib</code>：系统开机所需要的最基本的动态链接共享库</li><li><code>/lost+found</code>：一般为空。当系统非法关机后，这里才存放一些文件</li><li><code>/etc</code>：所有的系统管理所需要的配置文件和子目录</li><li><code>/usr</code>：非常重要的系统文件。类似于windows下的program files目录</li><li><code>/boot</code>：这里存放的是启动Linux时使用的一些核心文件。</li><li><code>/proc</code>：这个目录是一个虚拟的目录，它是系统内存的映射。可以通过直接访问这个目录来获取系统信息。</li><li><code>/srv</code>：service缩写。该目录存放一些服务启动之后需要提取的数据</li><li><code>sys</code>：这是 Linux2.6 内核的一个很大的变化。该目录下安装了 2.6 内核中新出现的一个文件系统 sysfs 。sysfs 文件系统集成了下面3种文件系统的信息：针对进程信息的 proc 文件系统、针对设备的 devfs 文件系统以及针对伪终端的 devpts 文件系统。</li><li><code>/tmp</code>：用于存放一些临时文件</li><li><code>/dev</code>：是设备（device）的缩写。用于存放Linux的外部设备。把所有的硬件用文件的形式存储。</li><li><code>/media</code>（CentOS6）：linux 系统会自动识别一些设备，例如U盘、光驱等等，当识别后，Linux 会把识别的设备挂载到这个目录下。CentOS7迁移到<code>/run/media</code></li><li><code>/mnt</code>：系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在 /mnt/ 上，然后进入该目录就可以查看光驱里的内容了。</li><li><code>/opt</code>：opt 是 optional(可选) 的缩写，这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。</li><li><code>var</code>：var 是 variable(变量) 的缩写，这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。</li></ul><h2 id="vi-vim编辑器">vi/vim编辑器</h2><h3 id="基本概念">基本概念</h3><ul><li><p><code>vi</code>是Unix操作系统和类Unix操作系统中最通用的文本编辑器</p></li><li><p><code>vim</code>编辑器是从VI发展出来的一个性能更加强大的文本编辑器。可以主动的以字体颜色辨别语法的正确性，方便程序设计。<code>vim</code>与<code>vi</code>编辑器完全兼容</p></li></ul><p><code>vi</code>/<code>vim</code>常用的三种模式分别是：<strong>一般模式</strong>，<strong>编辑模式</strong>，<strong>命令模式</strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303111935514.png" alt=""></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303111935516.gif" alt=""></p><h3 id="一般模式（默认）">一般模式（默认）</h3><p>刚启动<code>vim</code>就会进入一般模式。此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。可以【删除】、【复制】、【粘贴】</p><p>其中常用语法如下：</p><table><thead><tr><th>语法</th><th>功能描述</th></tr></thead><tbody><tr><td>yy</td><td>复制光标当前一行**（常用）**</td></tr><tr><td>nyy</td><td>n 为数字。复制光标所在（含）的向下 n 行，例如 20yy 则是复制 20 行**（常用）**</td></tr><tr><td>p, P</td><td>p为将已复制的数据在光标下一行贴上；P 则为贴在游标上一行；<strong>（常用）</strong></td></tr><tr><td>np</td><td>n 为数字。将复制的内容粘贴n次</td></tr><tr><td>u</td><td>撤销上一步</td></tr><tr><td>dd</td><td>剪切游标所在的那一整行**(常用)**</td></tr><tr><td>ndd</td><td>n 为数字。剪切光标（含）后n行</td></tr><tr><td>y$</td><td>复制光标所在的那个字符到该行行尾的所有数据</td></tr><tr><td>yw</td><td>复制当前光标所在的那个字符到单词结束的所有数据</td></tr><tr><td>dw</td><td>剪切当前光标所在的那个字符到单词结束的所有数据</td></tr><tr><td>$</td><td>将光标移动到当前行的行尾</td></tr><tr><td>^</td><td>将光标移动到当前行的行头</td></tr><tr><td>G</td><td>移动到最后一行</td></tr><tr><td>nG</td><td>移动到这个文件的第n行**(常用)**(可配合 :set nu)</td></tr><tr><td></td><td></td></tr></tbody></table><h3 id="编辑模式">编辑模式</h3><p>在一般模式下，按下【i, I, o, O, a, A】等任何一个字母，才会进入编辑模式</p><p>若要从编辑模式切换回一般模式，则按【Esc】按键即可</p><p>常用语法</p><table><thead><tr><th>按键</th><th>功能</th></tr></thead><tbody><tr><td>i</td><td>当前光标前</td></tr><tr><td>a</td><td>当前光标后</td></tr><tr><td>o</td><td>当前光标行的下一行</td></tr><tr><td>I</td><td>当前光标所在行的行头</td></tr><tr><td>A</td><td>当前光标所在行的行尾</td></tr><tr><td>O</td><td>当前光标行的上一行</td></tr></tbody></table><blockquote><p>建议：</p><p>命令太多了，建议只使用一个【i】就够用了</p></blockquote><h3 id="指令模式">指令模式</h3><p>在一般模式中，输入【<code>:</code>，<code>/</code>，<code>?</code>】任何一个按钮，就可以将光标移动到最底下的那行，进入指令模式。</p><p>常用语法</p><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>:w</td><td>保存</td></tr><tr><td>:q</td><td>退出</td></tr><tr><td>:!</td><td>强制执行</td></tr><tr><td>/要查找的词</td><td>n查找下一个，N往上查找</td></tr><tr><td>?要查找的词</td><td>往上查找</td></tr><tr><td>:noh</td><td>取消高亮显示</td></tr><tr><td>:set nu</td><td>显示行号</td></tr><tr><td>:set nonu</td><td>关闭行号</td></tr><tr><td>:%s/old/new/g</td><td>替换内容 /g 替换匹配到的所有内容</td></tr><tr><td>:%s/word1/word2/gc</td><td>寻找 word1 字符串，并将该字符串取代为 word2 ！且在取代前显示提示字符给用户确认 (confirm) 是否需要取代！(常用)</td></tr><tr><td>:n1,n2s/word1/word2/g</td><td>n1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2 ！举例来说，在 100 到 200 行之间搜寻 vbird 并取代为 VBIRD 则：<br/>『:100,200s/vbird/VBIRD/g』。(常用)</td></tr></tbody></table><h2 id="网络配置">网络配置</h2><h3 id="查看网络IP和网关">查看网络IP和网关</h3><ol><li>查看IP地址</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ifconfig</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303111935517.png" alt=""></p><ol start="2"><li>查看网关地址</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ip route</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303111935518.png" alt=""></p><h3 id="配置网络IP地址">配置网络IP地址</h3><h4 id="修改IP地址成静态地址">修改IP地址成静态地址</h4><ol><li>查看IP配置文件</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303111935519.png" alt=""></p><ol start="2"><li>将其修改为静态IP地址</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303111935520.png" alt=""></p><p>上述修改的DNS2，应该为DNS1</p><h4 id="重启网络">重启网络</h4><p>在修改IP地址后，需要重启网络：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service network restart</span><br></pre></td></tr></table></figure><h4 id="修改IP地址后可能会遇到的问题">修改IP地址后可能会遇到的问题</h4><ul><li><p>物理机能ping通虚拟机，但是虚拟机ping不通物理机。一般都是因为物理机的防火墙问题，把防火墙关闭就行。</p></li><li><p>虚拟机能ping通物理机，但是虚拟机ping不通外网。一般都是DNS设置有问题</p></li><li><p>虚拟机ping <code>www.baidu.com</code> 显示域名未知等信息，一般查看GATEWAY和DNS设置是否正确</p></li><li><p>如果以上全部设置完还是不行，需要关闭<code>NetworkManager</code>服务</p></li></ul> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl stop NetworkManager # 关闭</span><br><span class="line">systemctl disable NetworkManager # 禁用</span><br></pre></td></tr></table></figure><ul><li>如果检查发现<code>systemctl status network</code> 有问题，需要检查 ifcfg-ens33</li></ul><h3 id="配置主机名">配置主机名</h3><h4 id="修改主机名称">修改主机名称</h4><ol><li>查看当前服务器的主机名称</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hostname</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303111935521.png" alt=""></p><ol start="2"><li>如果感觉主机名不合适，可以修改。通过编辑<code>/etc/hostname</code>文件</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/hostname</span><br></pre></td></tr></table></figure><ol start="3"><li>修改后，重启生效</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">shutdown -r now</span><br></pre></td></tr></table></figure><p>or</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure><ol start="4"><li>如果不想重启，则执行以下命令</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hostnamectl set-hostname [新主机名]</span><br></pre></td></tr></table></figure><h4 id="修改hosts映射文件">修改hosts映射文件</h4><p>1）修改<code>Linux</code>的主机映射文件（hosts文件）</p><p>（1）打开<code>/etc/hosts</code></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/hosts</span><br></pre></td></tr></table></figure><p>（2）添加如下内容</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303111935522.png" alt=""></p><ol start="2"><li>重启设备</li></ol><h2 id="系统管理">系统管理</h2><h3 id="Linux中的进程和服务">Linux中的进程和服务</h3><ul><li><p>计算机中，一个正在执行的程序或命令，被叫做“进程”（process）</p></li><li><p>启动之后一直存在、常驻内存的进程，一般被称作“服务”（service）</p></li></ul><h3 id="service服务管理（centos6）">service服务管理（centos6）</h3><ol><li>对某个服务进行 启动/停止/重启/查看状态</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service 服务名 start|stop|restart|status</span><br></pre></td></tr></table></figure><ol start="2"><li>查看Linux所有服务的运行状态</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service --status-all</span><br></pre></td></tr></table></figure><ol start="3"><li>列出所有服务</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chkconfig --list</span><br></pre></td></tr></table></figure><ol start="4"><li>查看所有服务</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /etc/init.d</span><br><span class="line">ls -al</span><br></pre></td></tr></table></figure><h3 id="chkconfig-设置后台服务的自启配置（centos6）">chkconfig 设置后台服务的自启配置（centos6）</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chkconfig # 查看所有服务的自启配置</span><br><span class="line">chkconfig 服务名 off# 关掉指定服务的自动启动</span><br><span class="line">chkconfig 服务名 on# 开启指定服务的自动启动</span><br><span class="line">chkconfig 服务名 --list# 查看服务开机启动状态</span><br></pre></td></tr></table></figure><h3 id="systemctl-centos7的服务管理">systemctl (centos7的服务管理)</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl start|stop|restart|status 服务名</span><br></pre></td></tr></table></figure><ol start="2"><li>查看服务的方法：</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/lib/systemd/system</span><br><span class="line">ls -al</span><br></pre></td></tr></table></figure><h3 id="systemctl-设置后台服务的自启配置（centos7）">systemctl 设置后台服务的自启配置（centos7）</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl list-unit-files# 查看服务开机启动状态</span><br><span class="line">systemctl disable 服务名# 关掉指定服务的自启动</span><br><span class="line">systemctl enable 服务名# 开启指定服务的自启动</span><br></pre></td></tr></table></figure><h3 id="关机重启命令">关机重启命令</h3><ol><li>基本语法</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sync# 将数据由内存同步到硬盘中</span><br><span class="line">halt# 停机，关闭系统，但不断电</span><br><span class="line">poweroff# 关机，断电</span><br><span class="line">reboot# 重启，等同于 shutdown -r now</span><br><span class="line">shutdown</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> 基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo博客教程(三)图片存储</title>
      <link href="/2023/03/06/Hexo%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B-%E4%B8%89-%E5%9B%BE%E7%89%87%E5%AD%98%E5%82%A8/"/>
      <url>/2023/03/06/Hexo%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B-%E4%B8%89-%E5%9B%BE%E7%89%87%E5%AD%98%E5%82%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在Hexo博客远程发布时，如何存储并显示文章中的图片是一个问题。本文使用GitHub+PicGo来存储并显示图片，并使用Typora来写博客。</p><h2 id="环境安装">环境安装</h2><h3 id="安装Git">安装Git</h3><p>安装Git后还需要绑定自己的GitHub账号，可参考<a href="https://hugh-98.github.io/2023/03/05/Hexo%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B%E4%B8%80/">这篇博客</a></p><h3 id="安装PicGo">安装PicGo</h3><p>GitHub地址：<a href="https://github.com/Molunerfinn/PicGo">https://github.com/Molunerfinn/PicGo</a></p><p>安装较为简单，直接略过了</p><h3 id="安装Typora">安装Typora</h3><p><a href="https://typoraio.cn/">官网</a>现在的版本需要购买。也可以在网上找0.x的版本，免费。</p><h2 id="GitHub图床部署">GitHub图床部署</h2><h3 id="GitHub新建仓库">GitHub新建仓库</h3><p>在GitHub上新建一个仓库，自定义名字</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061950057.png" alt="image-20230306193643724"></p><h3 id="GitHub创建token">GitHub创建token</h3><ol><li>在GitHub的setting中，找到<code>Developer settings</code>选项</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061950058.png" alt="image-20230306193923052"></p><ol start="2"><li>创建一个新的token</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061950059.png" alt="image-20230306194020418"></p><ol start="3"><li>创建时候的选项</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061950060.png" alt="image-20230306194133670"></p><ol start="4"><li>生成后，复制该token</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061950061.png" alt="image-20230306194246910"></p><h3 id="PicGo设置">PicGo设置</h3><ol><li>打开安装的PicGo软件</li><li>在图床设置中，按照要求填写仓库名、分支名、token等等，即可。</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061950062.png" alt="image-20230306194404448"></p><h3 id="Typora设置">Typora设置</h3><p>Typora推荐用来写博客，使用Markdown非常方便。</p><p>为了能够在Typora中使用PicGo上传图片到GitHub上，可以对Typora进行设置。</p><ol><li>主要在偏好设置中设置图像。并可以验证图片是否可以正常上传</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061950063.png" alt="image-20230306194633693"></p><ol start="2"><li>在Typora中写博客时插入图片后，可以一键上传博客中所有图片</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061950064.png" alt="image-20230306194836662"></p><h2 id="目前存在的问题">目前存在的问题</h2><p>目前，使用GitHub作为图床，由于在中国大陆访问GitHub比较艰难，因此会出现图片显示不了的问题，需要科学上网后才会显示图片。</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
          <category> Hexo博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> GitHub </tag>
            
            <tag> PicGo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo博客教程(二)Hexo主题推荐</title>
      <link href="/2023/03/06/Hexo%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B%E4%BA%8C/"/>
      <url>/2023/03/06/Hexo%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>Hexo博客默认的页面感觉太单调了，为了更好地美化个人博客，我们可以自己选择喜欢的主题。</p><p>Hexo推荐的主题有很多，都可以在<a href="https://hexo.io/themes/">官方网站</a>上查看。</p><p>本文主要讲一下推荐的主题，以及目前本人正在使用的主题。</p><h2 id="推荐主题">推荐主题</h2><h3 id="Butterfly">Butterfly</h3><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061608546.png" alt="image-20230306102321551"  /><p>官网：<a href="https://butterfly.js.org/">https://butterfly.js.org/</a></p><p>GitHub地址：<a href="https://github.com/jerryc127/hexo-theme-butterfly">https://github.com/jerryc127/hexo-theme-butterfly</a></p><h3 id="NexT">NexT</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061608547.png" alt="image-20230306102721008"></p><p>官网：<a href="https://theme-next.js.org/">https://theme-next.js.org/</a></p><p>GitHub地址：<a href="https://github.com/next-theme/hexo-theme-next">https://github.com/next-theme/hexo-theme-next</a></p><h3 id="Icarus">Icarus</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061608548.png" alt="image-20230306103633570"></p><p>官网：<a href="https://ppoffice.github.io/hexo-theme-icarus/">https://ppoffice.github.io/hexo-theme-icarus/</a></p><p>GitHub地址：<a href="https://github.com/ppoffice/hexo-theme-icarus">https://github.com/ppoffice/hexo-theme-icarus</a></p><h3 id="Fluid">Fluid</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061608549.png" alt="image-20230306104439103"></p><p>官网：<a href="https://hexo.fluid-dev.com/">https://hexo.fluid-dev.com/</a></p><p>GitHub地址：<a href="https://github.com/fluid-dev/hexo-theme-fluid">https://github.com/fluid-dev/hexo-theme-fluid</a></p><h3 id="Volantis">Volantis</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061608550.png" alt="image-20230306104813452"></p><p>官网：<a href="https://volantis.js.org/">https://volantis.js.org/</a></p><p>GitHub地址：<a href="https://github.com/volantis-x/hexo-theme-volantis">https://github.com/volantis-x/hexo-theme-volantis</a></p><h3 id="Snippet">Snippet</h3><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303061608551.png" alt="image-20230306105139544"></p><p>官网：<a href="https://www.91h5.cc/?rf=gh-demo">https://www.91h5.cc/?rf=gh-demo</a></p><p>GitHub地址：<a href="https://github.com/shenliyang/hexo-theme-snippet">https://github.com/shenliyang/hexo-theme-snippet</a></p><h2 id="本文使用的主题Butterfly介绍">本文使用的主题Butterfly介绍</h2><p>本博客使用主题：<a href="https://github.com/jerryc127/hexo-theme-butterfly">butterfly</a></p><p>关于如何配置可以直接看官网即可，讲的非常详细了。</p><blockquote><p>注意：使用该主题后，以后若需改动配置，则只需要在<code>_config.butterfly.yml</code>进行配置，可以不用在<code> _config.yml</code>中配置。</p></blockquote><p>在butterfly中，本文已配置如下第三方的功能：</p><ul><li><a href="https://github.com/PaicHyperionDev/hexo-generator-search">本地搜索</a></li><li><a href="https://tongji.baidu.com/web/welcome/login">百度分析统计</a></li><li>KaTeX</li><li>字数统计</li></ul>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
          <category> Hexo博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo博客教程(一)搭建Hexo博客</title>
      <link href="/2023/03/05/Hexo%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B%E4%B8%80/"/>
      <url>/2023/03/05/Hexo%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B%E4%B8%80/</url>
      
        <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>首先，本文目标是搭建一个完全免费的个人博客。</p><p>当然，免费也有一定的缺点，就是GitHub经常需要科学上网才能进入，不太方便。也有人用Gitee，没有科学上网的人也可以搜索网上的相关教程。</p><p><strong>本文主要使用框架：</strong></p><ul><li>Hexo</li><li>Github</li></ul><p>笔者使用的是Windows10系统，所以只讲该系统下的安装与使用。并且，本文在安装软件时直接使用科学上网下载安装，对于无法科学上网的人来说可能会存在一些问题，建议查看<a href="https://hexo.io/zh-cn/docs/index.html">Hexo官方文档</a></p><p>也可以参考这位<a href="https://www.bilibili.com/video/BV1Yb411a7ty">up主的视频</a></p><h2 id="环境安装">环境安装</h2><p>这一步其实也可以参考<a href="https://hexo.io/zh-cn/docs/index.html">Hexo官方文档</a></p><h3 id="安装Git">安装Git</h3><h4 id="去官网安装Git">去官网安装<a href="https://git-scm.com/download/win">Git</a></h4><p>一般现在都是64位的Windows系统，所以直接下载安装即可。（不会就搜教程）</p><h4 id="让Git与自己的GitHub账号绑定">让Git与自己的GitHub账号绑定</h4><ol><li>安装完成后即可在右击鼠标，打开Git Bash。或者在Windows的搜索框中搜索Git，即可看到</li></ol><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303052208949.png" alt="image-20230305204033056" style="zoom: 80%;" /><ol start="2"><li>设置用户名与邮箱</li></ol><p>在Git Bash中输入以下命令：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git config --global user.name &quot;你的GitHub用户名&quot;</span><br><span class="line">git config --global user.email &quot;你的GitHub注册邮箱&quot;</span><br></pre></td></tr></table></figure><ol start="3"><li>生成ssh密钥文件</li></ol><p>在Git Bash中输入以下命令：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;你的GitHub注册邮箱&quot;</span><br></pre></td></tr></table></figure><p>输入上述命令后，会有几个需要确认的问题，直接三个回车键即可。</p><ol start="4"><li>找到生成的密钥文件</li></ol><p>可以在Git Bash中输入以下命令：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd ~/.ssh# 进入密钥文件所在文件夹</span><br><span class="line">cat id_rsa.pub# 打印出公钥，将打印出的内容全部复制</span><br></pre></td></tr></table></figure><ol start="5"><li>登录GitHub账号，在GitHub Setting中添加SSH Keys</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303052208951.png" alt="image-20230305205503008"></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303052208952.png" alt="image-20230305205606025"></p><ol start="6"><li>测试是否绑定账号成功</li></ol><p>在Git Bash中输入以下命令：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure><p>如果出现以下信息，即表示成功</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Hi xxx! You&#x27;ve successfully authenticated, xxx.</span><br></pre></td></tr></table></figure><h3 id="安装Node-js">安装Node.js</h3><p>Hexo基于Node.js，所以需要安装Node.js</p><p>在<a href="https://nodejs.org/zh-cn/download/">Node.js官网</a>上下载Node.js即可</p><p>下载并安装完成后，可以在命令行中输入以下命令检测是否安装成功：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure><p>如果成功，则会显示Node.js的版本号</p><p>后面还需要使用npm，但是由于Node.js已经自带npm，所以不需要额外安装。可以使用以下命令检测电脑中是否有npm：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm -v</span><br></pre></td></tr></table></figure><h3 id="安装Hexo">安装Hexo</h3><ol><li>在电脑中创建一个文件夹。Hexo框架以及以后发布的博客都存储在该文件夹中。</li><li>在该文件夹中，打开命令行，使用npm安装Hexo</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure><ol start="3"><li>初始化博客。同目录下，输入：</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure><hr/><p>通过以上命令即可将Hexo安装在本地。</p><p>下面就可以使用Hexo了。</p><h2 id="Hexo本地使用">Hexo本地使用</h2><h3 id="常用命令">常用命令</h3><p><strong>注：以下命令均在Hexo的安装目录下执行</strong></p><h3 id="创建博客">创建博客</h3><p>输入以下命令：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo new &quot;博客名&quot;</span><br></pre></td></tr></table></figure><blockquote><p>注：</p><ol><li><p>创建的博客在Hexo安装路径下的<code>./source/_posts/</code>文件夹下。</p><p>也可以自己手动在该路径下创建文章，但是手动创建的文章不会自动加前言。</p><p><strong>所以，还是推荐使用命令创建新的博客</strong></p></li><li><p>生成的博客名后面默认有<code>.md</code>的后缀，所以最好学会写markdown形式的博客。（推荐使用<code>Typora</code>书写）</p></li></ol></blockquote><h3 id="生成静态文件">生成静态文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo generate</span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure><h3 id="本地部署Hexo">本地部署Hexo</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure><h3 id="本地部署流程">本地部署流程</h3><p>如果我们只是想将博客部署在本地电脑，则根据上述的命令，按照以下流程完成即可：</p><ol><li>创建博客</li><li>生成静态文件</li><li>本地部署Hexo</li></ol><p>部署后，最后在 <a href="http://localhost:4000">http://localhost:4000</a> 即可访问</p><h2 id="Hexo部署在GitHub">Hexo部署在GitHub</h2><p>如果要将Hexo部署在Github上，则还需接下来的操作。</p><h3 id="GitHub新建仓库">GitHub新建仓库</h3><ol><li>在GitHub上新建一个仓库</li></ol><p><strong>注意：这里仓库名一定要是<code>用户名.github.io</code></strong></p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303052208953.png" alt="image-20230305213100961"></p><ol start="2"><li>创建成功后，将仓库的ssh链接复制下来</li></ol><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303052208954.png" alt="image-20230305213618837"></p><h3 id="修改配置文件">修改配置文件</h3><p>Hexo的配置内容都在安装路径下的<code>_config.yml</code>文件</p><p>在配置文件中，找到<code>deploy</code>的相关内容，将<code>type</code>填入<code>git</code>，<code>repo</code>填入上述复制的ssh链接，<code>branch</code>填入仓库对应的分支名。（注：现在默认分支应该是main吧，最好看清楚自己仓库的分支）</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303052208955.png" alt="image-20230305213657883"></p><h3 id="远程部署">远程部署</h3><p>上述步骤都完成后，可以使用以下命令进行远程部署：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo deploy</span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure><blockquote><p>注：</p><p>在部署前，如果有改动，则需要先用以下命令：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br></pre></td></tr></table></figure><p>然后，再使用远程部署的命令</p></blockquote><p>以后每次写出新文章就需要远程部署一次。</p><blockquote><p>建议每次远程部署前，先在本地部署预览一下，查看是否有问题，没问题在发布到GitHub上。</p></blockquote><h2 id="出现过的问题">出现过的问题</h2><h3 id="ssh端口不管用">ssh端口不管用</h3><p>在远程部署的时候，我使用的是github仓库链接是ssh的，所以需要22端口。有一次部署我发现，出现以下错误。从中可以看出，是因为无法读取远程仓库导致的。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303052226746.png" alt="image-20230305222433073"></p><p>排查问题的方法很简单，在Git Bash中使用以下命令，检测是否可以链接github</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure><p>我当时就出现如下报错。所以可以肯定，是22端口无法使用导致的。</p><p><img src="https://raw.githubusercontent.com/hugh-98/PicGo/main/img/202303052226321.png" alt="image-20230305222554789"></p><p>究其原因，我发现是学校校园网将22端口屏蔽了，所以无法使用。只要换个网络即可。</p><h3 id="图片无法显示">图片无法显示</h3><p>目前依旧存在的问题：</p><p>由于我博客中主题的图片与文章中的图片都存在Github上，导致如果不使用科学上网，图片将无法显示。。。</p><p>难道这就是免费的缺点吗！呜呜呜呜</p><p>不知道怎么解决！！！求评论区大佬教教</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
          <category> Hexo博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> GitHub </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
